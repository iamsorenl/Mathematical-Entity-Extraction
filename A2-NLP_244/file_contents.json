{"(mmd) Complex Manifolds - Differential Analysis on Complex Manifolds - Wells.mmd-nilay-nilay-p195-196-FacebookAI_roberta-base.json": "_Proof of Theorem 4.7:_ It is clear from the definition of \\(d^{*}\\) and \\(\\boldsymbol{\\Delta}\\) that \\(\\boldsymbol{\\Delta}\\) commutes with \\(d\\) and \\(*\\). So we have to see that \\(L\\boldsymbol{\\Delta}-\\boldsymbol{\\Delta}L\\) vanishes. We have\n\n\\[\\boldsymbol{\\Delta}L-L\\boldsymbol{\\Delta} =dd^{*}L+d^{*}dL-Ldd^{*}-Ld^{*}d\\] \\[=dd^{*}L+d^{*}Ld-dLd^{*}-Ld^{*}d\\] \\[=-d[L,d^{*}]-[L,d^{*}]d,\\]\n\nand substituting, from Theorem 4.8, we obtain\n\n\\[\\boldsymbol{\\Delta}L-L\\boldsymbol{\\Delta}=-dd_{c}-d_{c}d.\\]\n\nIt follows from (4.1) that \\(dd_{c}=-d_{c}d\\), since \\(\\partial\\tilde{\\partial}+\\tilde{\\partial}\\partial=0\\); thus we obtain \\(\\boldsymbol{\\Delta}L-L\\boldsymbol{\\Delta}=0\\).\n\nTo prove the relationship between \\(\\boldsymbol{\\Delta}\\) and the other Laplacians, we write, using Corollary 4.9,\n\n\\[\\boldsymbol{\\Delta} =dd^{*}+d^{*}d=d[L^{*},d_{c}]+[L^{*},d_{c}]d\\] \\[=dL^{*}d_{c}-dd_{c}L^{*}+L^{*}d_{c}d-d_{c}L^{*}d.\\]\n\nNote that all the information about the metric in the operator \\(\\boldsymbol{\\Delta}\\) is contained in the operator \\(L^{*}\\), since \\(d\\) and \\(d_{c}\\) depend only on the differentiable and complex structure, respectively. Multiply on the left by \\(J^{-1}\\) and on the right by \\(J\\); we obtain\n\n\\[\\boldsymbol{\\Delta}_{c}=-d_{c}L^{*}d+d_{c}dL^{*}-L^{*}dd_{c}+dL^{*}d_{c}.\\]\n\nBut since \\(d_{c}d=-dd_{c}\\), we have that \\(\\boldsymbol{\\Delta}=\\boldsymbol{\\Delta}_{c}\\), in a trivial manner.\n\nWe now write (noting that \\(2\\partial=d+id_{c}\\), etc.)\n\n\\[4(\\partial\\partial^{*}+\\partial^{*}\\partial) =(d+id_{c})\\left(d^{*}-id_{c}^{*}\\right)\\] \\[\\quad+\\left(d^{*}-id_{c}^{*}\\right)\\left(d+id_{c}\\right)\\] \\[=(dd^{*}+d^{*}d)+\\left(d_{c}d_{c}^{*}+d_{c}^{*}d_{c}\\right)\\] \\[\\quad+i\\left(d_{c}d^{*}+d^{*}d_{c}\\right)-i\\left(dd_{c}^{*}+d_{c }^{*}d\\right).\\]By (4.6) in Corollary 4.10, we see that the last two parentheses vanish. We also have\n\n\\[\\boldsymbol{\\Delta}_{c} =J^{-1}\\boldsymbol{\\Delta}J=J^{-1}dd^{*}J+J^{-1}d^{*}dJ\\] \\[=d_{c}d_{c}^{*}+d_{c}^{*}d_{c}.\\]\n\nTherefore we have\n\n\\[4\\square =\\boldsymbol{\\Delta}+\\boldsymbol{\\Delta}_{c}+0\\] \\[=2\\boldsymbol{\\Delta}.\\]\n\nThus, \\(2\\square=\\boldsymbol{\\Delta}\\). The other assertion is proved in a similar manner. The fact that \\(\\boldsymbol{\\Delta}\\) is of bidegree (0, 0) follows now trivially from the fact that \\(\\square\\) is of bidegree (0, 0). Similarly, since \\(\\boldsymbol{\\Delta}\\) is a real operator, \\(\\square\\) and \\(\\overline{\\square}\\) must also be real operators.\n\nQ.E.D.\n\nCorollary 4.11:On a Kahler manifold, the operator \\(\\boldsymbol{\\Delta}\\) commutes with \\(J\\), \\(L^{*}\\), \\(d\\), \\(\\partial\\), \\(\\partial^{*}\\), and \\(d^{*}\\).\n\nSince \\(L^{*}\\) commutes with \\(\\boldsymbol{\\Delta}\\) on a Kahler manifold, we have an analogue to Theorem 3.12. On a Kahler manifold \\(X\\), \\(\\boldsymbol{\\Delta}\\)-harmonic differential forms are the same as, by Theorem 4.7, \\(\\square\\)-harmonic or \\(\\overline{\\square}\\)-harmonic forms, and shall say simply _harmonic forms_ on \\(X\\), to be denoted by \\(\\mathcal{H}^{r}(X)\\) and \\(\\mathcal{H}^{p,q}(X)\\) as before. We shall denote by \\(\\mathcal{H}^{r}_{0}(X)\\) and \\(\\mathcal{H}^{p,q}_{0}(X)\\) the _primitive harmonic r-forms_ and \\((p,q)\\)_-forms_, respectively; i.e., \\(\\mathcal{H}^{r}_{0}(X)\\) is the kernel of the mapping \\(L^{*}\\): \\(\\mathcal{H}^{r}(X)\\to\\mathcal{H}^{r-2}(X)\\) and \\(\\mathcal{H}^{p,q}_{0}(X)\\) is the kernel of the mapping \\(L^{*}\\): \\(\\mathcal{H}^{p,q}(X)\\to\\mathcal{H}^{p-1,q-1}(X)\\). These maps are well defined since \\(L^{*}\\) commutes with \\(\\boldsymbol{\\Delta}\\).\n\nCorollary 4.12:On a compact Kahler manifold \\(X\\) there are direct sum decompositions:\n\n\\[\\mathcal{H}^{r}(X) =\\sum_{s\\geq(r-n)^{+}}L^{s}\\mathcal{H}^{r-2s}_{0}(X)\\] \\[\\mathcal{H}^{p,q}(X) =\\sum_{s\\geq(p+q-n)^{+}}L^{s}\\mathcal{H}^{p-s,q-s}_{0}(X).\\]\n\nThis result follows immediately from the primitive decomposition theorem (Theorem 3.12) and the fact that \\(\\boldsymbol{\\Delta}\\) commutes with \\(L\\) and \\(L^{*}\\).\n\nOur last corollary to the Lefschetz decomposition theorem is the following result, also due to Lefschetz.\n\nCorollary 4.13:Let \\(X\\) be a compact Kahler manifold, then\n\n\\[L^{n-p}=e(\\boldsymbol{\\Omega}^{n-p})\\text{: }H^{p}(X,\\boldsymbol{\\mathrm{C}}) \\longrightarrow H^{2n-p}(X,\\boldsymbol{\\mathrm{C}})\\]\n\nis an isomorphism, where \\(\\boldsymbol{\\Omega}\\) is the Kahler form on \\(X\\).\n\n_Remark:_ This implies the Poincare duality theorem (Theorem 2.5) in this context, and is referred to in algebraic geometry as the \"strong Lefschetz theorem\" (cf., Grothendieck [1]).\n\n_Proof:_ This is an immediate consequence of part (c) of the Lefschetz decomposition theorem (Theorem 3.12), where we represent the cohomology groups by harmonic forms as in Corollary 4.12.\n\nQ.E.D.\n\n_Remark:_ The basic result of this section is Theorem 4.7, and we shall develop its consequences in the next section. The derivation of this result was based on Theorem 4.8 and its corollaries, and this depended in turn on the representation theory of Sec. 3. However, the statement of Theorem 4.7 does not involve the representation theory, and there are alternative methods of deriving Theorem 4.8 (from which then follows Theorem 4.7) which do not involve this concept. One basic approach is the following one. Suppose that\n\n\\[\\mathbf{\\Omega}=\\frac{i}{2}\\sum h_{\\mu v}(z)dz_{\\mu}\\wedge d\\bar{z}_{v}\\]\n\nis the fundamental form on a Kahler manifold for \\(z\\) near \\(0\\) in some appropriate coordinate system. By a linear change of coordinates, one can obtain easily that the matrix \\(h(z)=[h_{\\mu v}(z)]\\) is the identity at \\(z=0\\)\n\n\\[h_{\\mu v}(0)=\\delta_{\\mu v}\\]\n\nor\n\n\\[h(z)=I+O(|z|).\\]\n\nBy using the fact that \\(d\\mathbf{\\Omega}=0\\), one finds easily that the coefficient matrix satisfies the differential equations\n\n\\[\\begin{array}{l}\\frac{\\partial h_{\\mu v}}{\\partial z_{\\lambda}}(z)=\\frac{ \\partial h_{\\lambda v}}{\\partial z_{\\mu}}(z),\\qquad\\mu,v,\\lambda\\ \\ =\\ 1,\\ldots,n\\\\ \\frac{\\partial h_{\\mu v}}{\\partial\\bar{z}_{\\lambda}}(z)=\\frac{\\partial h_{\\mu \\lambda}}{\\partial\\bar{z}_{v}}(z),\\qquad\\mu,v,\\lambda\\ \\ =\\ 1,\\ldots,n.\\end{array}\\]\n\nBy making a new (quadratic) change of variables of the form\n\n\\[\\bar{z}_{\\mu}=z_{\\mu}+\\frac{1}{2}\\sum_{\\alpha,\\beta}A^{\\mu}_{\\alpha\\beta}z_{ \\alpha}z_{\\beta},\\]\n\nwhere \\([A^{\\mu}_{\\alpha\\beta}]\\) is a symmetric (in \\(\\alpha,\\beta\\)) complex matrix (for fixed \\(\\mu\\)), one can choose the coefficients \\(A^{\\mu}_{\\alpha\\beta}\\) [by using the differential equations (4.7)] so that\n\n\\[A^{\\mu}_{\\alpha\\beta}=-\\frac{\\partial h_{\\beta\\mu}}{\\partial z_{\\alpha}}(0),\\]\n\nand it will follow that\n\n\\[h(z)=I+O(|z|^{2});\\]\n\ni.e., all the linear terms in the Taylor expansion of \\(h\\) at \\(0\\) vanish. Such a coordinate system is called a _geodesic coordinate system_. At the point \\(0\\), one can derive Theorem 4.8 by ignoring the higher-order terms, since in the commutator only first-order derivations of \\(L\\) and \\(L^{*}\\) will appear. Then one is reduced to proving the commutator relations in \\(\\mathbf{C}^{n}\\) with the canonical Kahler metric as in Example 4.3. This is not difficult but will involve a sort", "(mmd) Number Theory - Number Theory - An Introduction to Mathematics - Coppel.mmd-nilay-laurel-p64-65-FacebookAI_roberta-base.json": "A mapping \\(f:R\\to R^{\\prime}\\) of a ring \\(R\\) into a ring \\(R^{\\prime}\\) is said to be a (ring) _isomorphism_ if it is both bijective and a homomorphism. The inverse mapping \\(f^{-1}\\colon R^{\\prime}\\to R\\) is then also an isomorphism. (An _automorphism_ of a ring \\(R\\) is an isomorphism of \\(R\\) with itself.)\n\nThus we have shown that, if \\(f:R\\to R^{\\prime}\\) is a homomorphism of a ring \\(R\\) into a ring \\(R^{\\prime}\\), with kernel \\(N\\), then the quotient ring \\(R/N\\) is isomorphic to \\(f(R)\\).\n\nAn ideal \\(M\\) of a ring \\(R\\) is said to be _maximal_ if \\(M\\neq R\\) and if there are no ideals \\(S\\) such that \\(M\\subset S\\subset R\\).\n\nLet \\(M\\) be an ideal of the ring \\(R\\). If \\(S\\) is an ideal of \\(R\\) which contains \\(M\\), then the set \\(S^{\\prime}\\) of all cosets \\(M+a\\) with \\(a\\in S\\) is an ideal of \\(R/M\\). Conversely, if \\(S^{\\prime}\\) is an ideal of \\(R/M\\), then the set \\(S\\) of all \\(a\\in R\\) such that \\(M+a\\in S^{\\prime}\\) is an ideal of \\(R\\) which contains \\(M\\). It follows that \\(M\\) is a maximal ideal of \\(R\\) if and only if \\(R/M\\) is simple. Hence an ideal \\(M\\) of a commutative ring \\(R\\) is maximal if and only if the quotient ring \\(R/M\\) is a field.\n\nTo conclude, we mention a simple way of creating new rings from given ones. Let \\(R\\), \\(R^{\\prime}\\) be rings and let \\(R\\times R^{\\prime}\\) be the set of all ordered pairs \\((a,a^{\\prime})\\) with \\(a\\in R\\) and \\(a^{\\prime}\\in R^{\\prime}\\). As we saw in the previous section, \\(R\\times R^{\\prime}\\) acquires the structure of a (commutative) group under addition if we define the sum \\((a,a^{\\prime})+(b,b^{\\prime})\\) of \\((a,a^{\\prime})\\) and \\((b,b^{\\prime})\\) to be \\((a+b,a^{\\prime}+b^{\\prime})\\). If we define their product \\((a,a^{\\prime})\\cdot(b,b^{\\prime})\\) to be \\((ab,a^{\\prime}b^{\\prime})\\), then \\(R\\times R^{\\prime}\\) becomes a ring, with \\((0,0^{\\prime})\\) as identity element for addition and \\((1,1^{\\prime})\\) as identity element for multiplication. The ring thus constructed is called the _direct sum_ of \\(R\\) and \\(R^{\\prime}\\), and is denoted by \\(R\\oplus R^{\\prime}\\).\n\n## 9 Vector Spaces and Associative Algebras\n\nAlthough we assume some knowledge of linear algebra, it may be useful to place the basic definitions and results in the context of the preceding sections. A set \\(V\\) is said to be a _vector space_ over a division ring \\(D\\) if it is a commutative group under an operation \\(+\\) (addition) and there exists a map \\(\\varphi:D\\times V\\to V\\) (multiplication by a scalar) such that, if \\(\\varphi(a,v)\\) is denoted by \\(av\\) then, for all \\(a\\), \\(\\beta\\in D\\) and all \\(v\\), \\(w\\in V\\),\n\n1. \\(a(v+w)=av+aw\\),\n2. \\((a+\\beta)v=av+\\beta v\\),\n3. \\((a\\beta)v=a(\\beta v)\\),\n4. \\(1v=v\\),\n\nwhere \\(1\\) is the identity element for multiplication in \\(D\\). The elements of \\(V\\) will be called _vectors_ and the elements of \\(D\\)_scalars_.\n\nFor example, for any positive integer \\(n\\), the set \\(D^{n}\\) of all \\(n\\)-tuples of elements of the division ring \\(D\\) is a vector space over \\(D\\) if addition and multiplication by a scalar are defined by\n\n\\[(a_{1},\\ldots,a_{n})+(\\beta_{1},\\ldots,\\beta_{n}) =(a_{1}+\\beta_{1},\\ldots,a_{n}+\\beta_{n}),\\] \\[\\alpha(a_{1},\\ldots,a_{n}) =(a\\alpha_{1},\\ldots,a\\alpha_{n}).\\]\n\nThe special cases \\(D=\\mathbb{R}\\) and \\(D=\\mathbb{C}\\) have many applications.\n\nAs another example, the set \\(\\mathcal{C}(I)\\) of all continuous functions \\(f:I\\to\\mathbb{R}\\), where \\(I\\) is an interval of the real line, is a vector space over the field \\(\\mathbb{R}\\) of real numbers if addition and multiplication by a scalar are defined, for every \\(t\\in I\\), by\n\n\\[(f+g)(t) = f(t)+g(t),\\] \\[(af)(t) = af(t).\\]\n\nLet \\(V\\) be an arbitrary vector space over a division ring \\(D\\). If \\(O\\) is the identity element of \\(V\\) with respect to addition, then\n\n\\[a\\,O=O\\quad\\text{for every }a\\in D,\\]\n\nsince \\(a\\,O=a(O+O)=a\\,O+a\\,O\\). Similarly, if \\(0\\) is the identity element of \\(D\\) with respect to addition, then\n\n\\[0b=O\\quad\\text{for every }b\\in V,\\]\n\nsince \\(0b=(0+0)b=0b+0b\\). Furthermore,\n\n\\[(-a)b=-(a\\,b)\\quad\\text{for all }a\\in D\\text{ and }b\\in V,\\]\n\nsince \\(O=0b=(a+(-a))b=a\\,b+(-a)b\\), and\n\n\\[a\\,b\\neq O\\quad\\text{if }a\\neq 0\\text{ and }b\\neq O,\\]\n\nsince \\(a^{-1}(a\\,b)=(a^{-1}a)b=1\\,b=b\\).\n\nFrom now on we will denote the zero elements of \\(D\\) and \\(V\\) by the same symbol \\(0\\). This is easier on the eye and in practice is not confusing.\n\nA subset \\(U\\) of a vector space \\(V\\) is said to be a _subspace_ of \\(V\\) if it is a vector space under the same operations as \\(V\\) itself. It is easily seen that a nonempty subset \\(U\\) is a subspace of \\(V\\) if (and only if) it is closed under addition and multiplication by a scalar. For then, if \\(u\\in U\\), also \\(-u=(-1)u\\in U\\), and so \\(U\\) is an additive subgroup of \\(V\\). The other requirements for a vector space are simply inherited from \\(V\\).\n\nFor example, if \\(1\\leq m<n\\), the set of all \\((a_{1},\\ldots,a_{n})\\in D^{n}\\) with \\(a_{1}=\\cdots=a_{m}=0\\) is a subspace of \\(D^{n}\\). Also, the set \\(\\mathcal{C}^{1}(I)\\) of all continuously differentiable functions \\(f:I\\to\\mathbb{R}\\) is a subspace of \\(\\mathcal{C}(I)\\). Two obvious subspaces of any vector space \\(V\\) are \\(V\\) itself and the subset \\(\\{0\\}\\) which contains only the zero vector.\n\nIf \\(U_{1}\\) and \\(U_{2}\\) are subspaces of a vector space \\(V\\), then their _intersection_\\(U_{1}\\cap U_{2}\\), which necessarily contains \\(0\\), is again a subspace of \\(V\\). The _sum_\\(U_{1}+U_{2}\\), consisting of all vectors \\(u_{1}+u_{2}\\) with \\(u_{1}\\in U_{1}\\) and \\(u_{2}\\in U_{2}\\), is also a subspace of \\(V\\). Evidently \\(U_{1}+U_{2}\\) contains \\(U_{1}\\) and \\(U_{2}\\) and is contained in every subspace of \\(V\\) which contains both \\(U_{1}\\) and \\(U_{2}\\). If \\(U_{1}\\cap U_{2}=\\{0\\}\\), the sum \\(U_{1}+U_{2}\\) is said to be _direct_, and is denoted by \\(U_{1}\\oplus U_{2}\\), since it may be identified with the set of all ordered pairs \\((u_{1},u_{2})\\), where \\(u_{1}\\in U_{1}\\) and \\(u_{2}\\in U_{2}\\).\n\nLet \\(V\\) be an arbitrary vector space over a division ring \\(D\\) and let \\(\\{v_{1},\\ldots,v_{m}\\}\\) be a finite subset of \\(V\\). A vector \\(v\\) in \\(V\\) is said to be a _linear combination_ of \\(v_{1},\\ldots,v_{m}\\) if\n\n\\[v=a_{1}v_{1}+\\cdots+a_{m}v_{m}\\]for some \\(a_{1},\\ldots,a_{m}\\in D\\).", "(mmd) A Term of Commutative Algebra - Altman.mmd-victoriacochran-victoria-p133-134-FacebookAI_roberta-base.json": "Moreover, \\(R^{\\prime}\\) is Noetherian by **(16.16)**. So by the first paragraph, \\(\\mathfrak{p}^{\\prime}\\) contains some \\(\\mathfrak{q}^{\\prime}\\in\\operatorname{Ass}_{R^{\\prime}}(M)\\). Let \\(\\kappa\\colon R\\twoheadrightarrow R^{\\prime}\\) be the quotient map. Set \\(\\mathfrak{q}:=\\kappa^{-1}\\mathfrak{q}^{\\prime}\\). Thus \\(\\mathfrak{p}\\supset\\mathfrak{q}\\), and **(17.4)** yields \\(\\mathfrak{q}\\in\\operatorname{Ass}(M)\\), as desired.\n\nFinally, \\(\\mathfrak{q}\\in\\operatorname{Supp}(M)\\) by **(17.13)**. Thus \\(\\mathfrak{p}=\\mathfrak{q}\\in\\operatorname{Ass}(M)\\) if \\(\\mathfrak{p}\\) is minimal. \n\n**Theorem (17.15)**.: _Let \\(M\\) be a Noetherian module. Then_\n\n\\[\\operatorname{nil}(M)=\\bigcap_{\\mathfrak{p}\\in\\operatorname{Ass}(M)} \\mathfrak{p}.\\]\n\n**Proof:** Since \\(M\\) is finitely generated, \\(\\operatorname{nil}(M)=\\bigcap_{\\mathfrak{p}\\in\\operatorname{Supp}(M)} \\mathfrak{p}\\) by **(13.6)**. Since \\(M\\) is Noetherian, given \\(\\mathfrak{p}\\in\\operatorname{Supp}(M)\\), there is \\(\\mathfrak{q}\\in\\operatorname{Ass}(M)\\) with \\(\\mathfrak{q}\\subset\\mathfrak{p}\\) by **(17.14)**. The assertion follows. \n\n**Lemma (17.16)**.: _Let \\(R\\) be a ring, \\(M\\) a nonzero Noetherian module. Then there exists a finite chain of submodules_\n\n\\[0=M_{0}\\subset M_{1}\\subset\\cdots\\subset M_{n-1}\\subset M_{n}=M\\]\n\n_with \\(M_{i}/M_{i-1}\\simeq R/\\mathfrak{p}_{i}\\) for some prime \\(\\mathfrak{p}_{i}\\) for \\(i=1,\\ldots,n\\). For any such chain,_\n\n\\[\\operatorname{Ass}(M)\\subset\\{\\mathfrak{p}_{1},\\ldots,\\mathfrak{p}_{n}\\} \\subset\\operatorname{Supp}(M).\\] **(17.16.1)**__\n\n**Proof:** There are submodules \\(N\\) of \\(M\\) having such a chain, as \\(0\\) does. So there's a maximal such \\(N\\) by **(16.11)**. Suppose \\(N\\neq M\\). Then \\(\\operatorname{Ass}(M/N)\\neq 0\\) by **(17.12)**. So there's a submodule \\(N^{\\prime}\\supsetneqq N\\) with \\(N^{\\prime}/N\\stackrel{{\\sim}}{{\\longrightarrow}}R/\\mathfrak{p}\\) for some \\(\\mathfrak{p}\\), contradicting maximality. Thus \\(N=M\\).\n\nThe first inclusion of **(17.16.1)** follows by induction from **(17.6)** and **(17.5)**(2). Now, \\(\\mathfrak{p}_{i}\\in\\operatorname{Supp}(R/\\mathfrak{p}_{i})\\) by **(13.4)**(3) with \\(M:=R/\\mathfrak{p}_{i}\\). Thus **(13.4)**(1) yields **(17.16.1)**. \n\n**Theorem (17.17)**.: _Let \\(M\\) be a Noetherian module. Then \\(\\operatorname{Ass}(M)\\) is finite._\n\n**Proof:** The assertion follows directly from **(17.16)**. \n\n**Proposition (17.18)**.: _Let \\(R\\) be a ring, \\(M\\) and \\(N\\) modules. Assume that \\(M\\) is Noetherian. Then \\(\\operatorname{Ass}(\\operatorname{Hom}(M,\\,N))=\\operatorname{Supp}(M)\\bigcap \\operatorname{Ass}(N)\\)._\n\n**Proof:** Set \\(\\mathfrak{a}:=\\operatorname{Ann}(M)\\) and \\(N^{\\prime}:=\\{\\,n\\in N\\mid\\mathfrak{a}n=0\\,\\}\\). Then \\(\\operatorname{Hom}(M,N^{\\prime})\\) lies in \\(\\operatorname{Hom}(M,N)\\). Conversely, given \\(\\alpha\\colon M\\to N\\) and \\(m\\in M\\), plainly \\(\\mathfrak{a}(\\alpha(m))=0\\); so \\(\\alpha(M)\\subset N^{\\prime}\\). Thus \\(\\operatorname{Hom}(M,\\,N)=\\operatorname{Hom}(M,\\,N^{\\prime})\\).\n\nLet's see that \\(\\operatorname{Supp}(M)\\bigcap\\operatorname{Ass}(N)=\\operatorname{Ass}(N^{ \\prime})\\) by double inclusion. First, given \\(\\mathfrak{p}\\in\\operatorname{Supp}(M)\\bigcap\\operatorname{Ass}(N)\\), say \\(\\mathfrak{p}=\\operatorname{Ann}(n)\\) for \\(n\\in N\\). But \\(\\operatorname{Supp}(M)\\subset\\mathbf{V}(\\mathfrak{a})\\) by **(13.4)**(3); so \\(\\mathfrak{p}\\supset\\mathfrak{a}\\). Hence \\(\\mathfrak{a}n=0\\). So \\(n\\in N^{\\prime}\\). Thus \\(\\mathfrak{p}\\in\\operatorname{Ass}(N^{\\prime})\\).\n\nConversely, given \\(\\mathfrak{p}\\in\\operatorname{Ass}(N^{\\prime})\\), say \\(\\mathfrak{p}=\\operatorname{Ann}(n)\\) for \\(n\\in N^{\\prime}\\). Then \\(\\mathfrak{a}n=0\\). So \\(\\mathfrak{p}\\supset\\mathfrak{a}\\). But \\(\\operatorname{Supp}(M)=\\mathbf{V}(\\mathfrak{a})\\) by **(13.4)**(3) as \\(M\\) is Noetherian. So \\(\\mathfrak{p}\\in\\operatorname{Supp}(M)\\). But \\(n\\in N^{\\prime}\\subset N\\). Thus \\(\\mathfrak{p}\\in\\operatorname{Ass}(N)\\). Thus \\(\\operatorname{Supp}(M)\\bigcap\\operatorname{Ass}(N)=\\operatorname{Ass}(N^{ \\prime})\\).\n\nThus we have to prove\n\n\\[\\operatorname{Ass}(\\operatorname{Hom}(M,\\,N^{\\prime}))=\\operatorname{Ass}(N^{ \\prime}).\\] **(17.18.1)**\n\nSet \\(R^{\\prime}:=R/\\mathfrak{a}\\). Plainly \\(\\operatorname{Hom}_{R^{\\prime}}(M,\\,N^{\\prime})=\\operatorname{Hom}_{R}(M,\\,N^{ \\prime})\\). Let \\(\\kappa\\colon R\\twoheadrightarrow R^{\\prime}\\) be the quotient map. Owing to **(17.4)**, \\(\\mathfrak{p}^{\\prime}\\mapsto\\kappa^{-1}(\\mathfrak{p}^{\\prime})\\) sets up two bijections: one from \\(\\operatorname{Ass}_{R^{\\prime}}(\\operatorname{Hom}_{R^{\\prime}}(M,N^{ \\prime}))\\) to \\(\\operatorname{Ass}_{R}(\\operatorname{Hom}_{R}(M,N^{\\prime}))\\), and one from \\(\\operatorname{Ass}_{R^{\\prime}}(N^{\\prime})\\) to \\(\\operatorname{Ass}_{R}(N^{\\prime})\\). Thus we may replace \\(R\\) by \\(R^{\\prime}\\). Then by **(16.16)**, \\(R\\) is Noetherian.\n\nGiven \\(\\mathfrak{p}\\in\\operatorname{Ass}(\\operatorname{Hom}(M,\\,N^{\\prime}))\\), there's an \\(R\\)-injection \\(R/\\mathfrak{p}\\hookrightarrow\\operatorname{Hom}(M,\\,N^{\\prime})\\) by **(17.3)**. Set \\(k(\\mathfrak{p}):=\\operatorname{Frac}(R/\\mathfrak{p})\\). Then \\(k(\\mathfrak{p})=(R/\\mathfrak{p})_{\\mathfrak{p}}\\) by **(12.16)**. But, \\(R\\) is Noetherian, so \\(M\\) is finitely presented by **(16.15)**; so by **(12.19)**,\n\n\\[\\operatorname{Hom}_{R}(M,\\,N^{\\prime})_{\\mathfrak{p}}=\\operatorname{Hom}_{R_{ \\mathfrak{p}}}(M_{\\mathfrak{p}},\\,N^{\\prime}_{\\mathfrak{p}}).\\]\n\nHence, by exactness, localizing yields an injection \\(\\varphi\\colon k(\\mathfrak{p})\\hookrightarrow\\operatorname{Hom}_{R_{ \\mathfrak{p}}}(M_{\\mathfrak{p}},\\,N^{\\prime}_{\\mathfrak{p}})\\).\n\nFor any \\(m\\in M_{\\mathfrak{p}}\\) with \\(\\varphi(1)(m)\\neq 0\\), the map \\(k(\\mathfrak{p})\\to N^{\\prime}_{\\mathfrak{p}}\\) given by \\(x\\mapsto\\varphi(x)(m)\\) is nonzero, so an injection. But \\(k(\\mathfrak{p})=R_{\\mathfrak{p}}/\\mathfrak{p}R_{\\mathfrak{p}}\\) by **(12.16)**. Hence by **(17.3)**, we have \\(\\mathfrak{p}R_{\\mathfrak{p}}\\in\\operatorname{Ass}(N^{\\prime}_{\\mathfrak{p}})\\). Thus by **(17.8)** also \\(\\mathfrak{p}\\in\\operatorname{Ass}(N^{\\prime})\\).\n\nConversely, given \\(\\mathfrak{p}\\in\\operatorname{Ass}(N^{\\prime})\\), recall from the third paragraph that \\(\\mathfrak{p}\\in\\operatorname{Supp}(M)\\). So \\(M_{\\mathfrak{p}}\\neq 0\\). So by Nakayama's Lemma, \\(M_{\\mathfrak{p}}/\\mathfrak{p}M_{\\mathfrak{p}}\\) is a nonzero vector space over \\(k(\\mathfrak{p})\\). Take any nonzero \\(R\\)-map \\(M_{\\mathfrak{p}}/\\mathfrak{p}M_{\\mathfrak{p}}\\to k(\\mathfrak{p})\\), precede it by the quotient map \\(M_{\\mathfrak{p}}\\to M_{\\mathfrak{p}}/\\mathfrak{p}M_{\\mathfrak{p}}\\), and follow it by an \\(R\\)-injection \\(k(\\mathfrak{p})\\hookrightarrow N^{\\prime}_{\\mathfrak{p}}\\); the latter exists by **(17.3)** and **(17.8)** since \\(\\mathfrak{p}\\in\\operatorname{Ass}(N^{\\prime})\\).\n\nWe obtain a nonzero element of \\(\\operatorname{Hom}_{R_{\\mathfrak{p}}}(M_{\\mathfrak{p}},\\,N^{\\prime}_{ \\mathfrak{p}})\\), annihilated by \\(\\mathfrak{p}R_{\\mathfrak{p}}\\). But \\(\\mathfrak{p}R_{\\mathfrak{p}}\\) is maximal; so the annihilator is too. So \\(\\mathfrak{p}R_{\\mathfrak{p}}\\in\\operatorname{Ass}\\bigl{(}\\operatorname{Hom}_{R _{\\mathfrak{p}}}(M_{\\mathfrak{p}},\\,N^{\\prime}_{\\mathfrak{p}})\\bigr{)}\\) by **(17.9)**. So \\(\\mathfrak{p}\\in\\operatorname{Ass}(\\operatorname{Hom}(M,\\,N^{\\prime}))\\) by **(17.18.2)** and **(17.8)**. Thus **(17.18.1)** holds. \\(\\square\\)\n\n**Proposition (17.19). --**_Let \\(R\\) be a ring, \\(M\\) a Noetherian module, \\(\\mathfrak{p}\\) a prime, \\(x\\), \\(y\\in\\mathfrak{p}-\\mathrm{z.div}(M)\\). Assume \\(\\mathfrak{p}\\in\\operatorname{Ass}(M/xM)\\). Then \\(\\mathfrak{p}\\in\\operatorname{Ass}(M/yM)\\)._\n\n**Proof:** Form the sequence \\(0\\to K\\to M/xM\\xrightarrow{\\mu_{y}}M/xM\\) with \\(K:=\\operatorname{Ker}(\\mu_{y})\\). Apply the functor \\(\\operatorname{Hom}(R/\\mathfrak{p},\\bullet)\\) to that sequence, and get the following one:\n\n\\[0\\to\\operatorname{Hom}(R/\\mathfrak{p},\\,K)\\to\\operatorname{Hom}(R/\\mathfrak{p },\\,M/xM)\\xrightarrow{\\mu_{y}}\\operatorname{Hom}(R/\\mathfrak{p},\\,M/xM).\\]\n\nIt is exact by **(5.11)**(2). But \\(y\\in\\mathfrak{p}\\); so the right-hand map vanishes. Thus\n\n\\[\\operatorname{Hom}(R/\\mathfrak{p},K)\\xrightarrow{\\rightharpoonup}\\operatorname {Hom}(R/\\mathfrak{p},\\,M/xM).\\]\n\nForm the following commutative diagram with exact rows:\n\n\\[\\begin{CD}0\\to M@>{\\mu_{x}}>{}>M@>{}>{}>M/xM@>{}>{}>0\\\\ @V{\\mu_{y}}V{}V@V{\\mu_{y}}V{}V@V{\\mu_{y}}V{}V\\\\ 0\\to M@>{\\mu_{x}}>{}>M@>{}>{}>M/xM@>{}>{}>0\\end{CD}\\]\n\nThe Snake Lemma **(5.10)** yields an exact sequence \\(0\\to K\\to M/yM\\xrightarrow{\\mu_{x}}M/yM\\) as \\(\\operatorname{Ker}(\\mu_{y}|M)=0\\). Hence, similarly, \\(\\operatorname{Hom}(R/\\mathfrak{p},\\,K)\\xrightarrow{\\rightharpoonup} \\operatorname{Hom}(R/\\mathfrak{p},\\,M/yM)\\). Hence,\n\n\\[\\operatorname{Hom}(R/\\mathfrak{p},\\,M/yM)=\\operatorname{Hom}(R/\\mathfrak{p},\\,M/xM).\\]\n\nAssume for a moment that \\(R\\) is Noetherian. Then **(17.18)** yields\n\n\\[\\operatorname{Ass}(\\operatorname{Hom}(R/\\mathfrak{p},\\,M/xM))=\\operatorname{ Supp}(R/\\mathfrak{p})\\bigcap\\operatorname{Ass}(M/xM).\\]\n\nBut \\(\\mathfrak{p}\\in\\operatorname{Supp}(R/\\mathfrak{p})\\) by **(13.4)**(3) with \\(M:=R/\\mathfrak{p}\\). Also \\(\\mathfrak{p}\\in\\operatorname{Ass}(M/xM)\\) by hypothesis. So \\(\\mathfrak{p}\\) lies in the left side of **(17.19.2)**. So \\(\\mathfrak{p}\\in\\operatorname{Ass}(\\operatorname{Hom}(R/\\mathfrak{p},\\,M/yM))\\) by **(17.19.1)**. But **(17.19.2)** holds with \\(y\\) in place of \\(x\\). Thus \\(\\mathfrak{p}\\in\\operatorname{Ass}(M/yM)\\) as desired.\n\nIn general, set \\(\\mathfrak{a}:=\\operatorname{Ann}_{R}(M)\\) and \\(R^{\\prime}:=R/\\mathfrak{a}\\). Then \\(R^{\\prime}\\) is Noetherian by **(16.16)**. But \\(\\mathfrak{p}\\in\\operatorname{Ass}_{R}(M/xM)\\). So **(17.13)** yields \\(\\mathfrak{p}\\supset\\operatorname{Ann}_{R}(M/xM)\\). But \\(\\operatorname{Ann}_{R}(M/xM)\\supset\\mathfrak{a}\\). Set \\(\\mathfrak{p}^{\\prime}:=\\mathfrak{p}/\\mathfrak{a}\\). Then \\(\\mathfrak{p}^{\\prime}\\in\\operatorname{Ass}_{R^{\\prime}}(M/xM)\\) by **(17.4)**. Let \\(x^{\\prime}\\), \\(y^{\\prime}\\in\\mathfrak{p}^{\\prime}\\) be the residues of \\(x\\), \\(y\\). Then \\(M/x^{\\prime}M=M/xM\\) and \\(M/y^{\\prime}M=M/yM\\). But \\(R^{\\prime}\\) is Noetherian. Hence the above argument yields \\(\\mathfrak{p}^{\\prime}\\in\\operatorname{Ass}_{R^{\\prime}}(M/yM)\\). But \\(\\operatorname{Ann}_{R}(M/yM)\\supset\\mathfrak{a}\\). Thus **(17.4)** yields \\(\\mathfrak{p}\\in\\operatorname{Ass}(M/yM)\\) as desired. \\(\\square\\)", "(mmd) Homology Theory - Homology Theory - Vick.mmd-victoriacochran-victoria-p75-76-FacebookAI_roberta-base.json": "6. if \\((X,A)\\) is a pair and \\(U\\subseteq A\\) has \\(\\overline{U}\\subseteq\\operatorname{Int}A\\), then the inclusion map \\(i\\colon(X-U,A-U)\\to(X,A)\\) has \\(i_{\\bullet}\\colon\\mathcal{H}_{n}(X-U,A-U)\\to\\mathcal{H}_{n}(X,A)\\) an isomorphism;\n7. \\(\\mathcal{H}_{n}(\\operatorname{pt})=0\\) for \\(n\\neq 0\\) [\\(\\mathcal{H}_{0}(\\operatorname{pt})\\) is called the _coefficient group_].\n\n**3.8 Theorem** (Existence).: _Given any abelian group \\(G\\), there exists a homology theory with coefficient group \\(G\\)._\n\nProof.: Let \\(\\mathcal{H}_{n}(X,A)=H_{n}(X,A;G)\\), singular homology with coefficients in \\(G\\). Then each of the axioms has been proved previously. \n\n**3.9 Theorem** (Uniqueness).: _On the category of finite \\(CW\\) pairs and maps of pairs_, _homology theories are determined_, _up to isomorphism_, _by their coefficient groups_. _That is_, _if \\(\\mathcal{H}_{\\star}\\) and \\(\\mathcal{H}_{\\star}^{\\prime}\\) are homology theories and \\(h\\colon\\mathcal{H}_{\\star}\\to\\mathcal{H}_{\\star}^{\\prime}\\) is a natural transformation_ (_that is_, _it commutes with induced homomorphisms and boundary operators_) _such that \\(h\\colon\\mathcal{H}_{0}(\\operatorname{pt})\\to\\mathcal{H}_{0}^{\\prime}( \\operatorname{pt})\\) is an isomorphism_, _then \\(h\\colon\\mathcal{H}_{n}(X,A)\\to\\mathcal{H}_{n}^{\\prime}(X,A)\\) is an isomorphism for each integer \\(n\\) and each finite \\(CW\\) pair \\((X,A)\\)._\n\nProof.: First note that the proofs of Theorems 2.14 and 2.16 (the relative homeomorphism theorem) only require that singular homology theory satisfy these axioms. So the analogs of these results will hold for any homology theory.\n\nDenote the zero-sphere \\(S^{0}\\) as the union of two points \\(S^{0}=x\\cup y\\), and consider the diagram\n\nwhich commutes by the naturality of \\(h\\). The horizontal maps are excision maps, so both horizontal homomorphisms are isomorphisms by Axiom 6. Since the first vertical homomorphism is an isomorphism by the hypothesis, we conclude that\n\n\\[h\\colon\\mathcal{H}_{k}(S^{0},x)\\to\\mathcal{H}_{k}^{\\prime}(S^{0},x)\\]\n\nis an isomorphism for each \\(k\\). Now consider the diagram\n\nwhere the rows are exact by Axiom 4. By the five lemma (Exercise 4, Chapter 2), \\(h\\colon\\mathcal{H}_{k}(S^{0})\\to\\mathcal{H}_{k}^{\\prime}(S^{0})\\) is an isomorphism.\n\nWe now prove inductively that \\(h\\) is an isomorphism for spheres of all dimensions. Suppose \\(h\\colon\\mathcal{H}_{k}(S^{n-1})\\to\\mathcal{H}_{k}^{\\prime}(S^{n-1})\\) is an isomorphism, \\(n>0\\). The \\(n\\)-disk \\(D^{n}\\) has the homotopy type of a point, so by using Axiom 5 we have an isomorphism \\(h\\colon\\mathcal{H}_{k}(D^{n})\\to\\mathcal{H}_{k}(D^{n})\\). In the commutative diagram\n\nthe horizontal homomorphisms are isomorphisms since they are induced by relative homeomorphisms, while the vertical homomorphism on the left is an isomorphism by the five lemma (Exercise 4, Chapter 2). So we conclude that \\(h\\colon\\mathcal{H}_{k}(S^{n},x)\\to\\mathcal{H}_{k}(S^{n},x)\\) is an isomorphism, and again apply the five lemma to see that \\(h\\colon\\mathcal{H}_{k}(S^{n})\\to\\mathcal{H}_{k}(S^{n})\\) is an isomorphism. This completes the inductive step.\n\nWe are now ready to prove the theorem by inducting on the number of cells in the finite CW complex, \\(X\\). Of course the conclusion is true if \\(X\\) has only one cell, so suppose that \\(h\\) is an isomorphism for all complexes having less than \\(m\\) cells. Let \\(X\\) be a finite CW complex containing \\(m\\) cells. If \\(\\dim X=n\\), pick a specific \\(n\\)-cell of \\(X\\) and denote by \\(A\\) the complement of this top dimensional cell. Then \\(A\\) is a subcomplex of \\(X\\) having \\(m-1\\) cells and there is a relative homeomorphism\n\n\\[\\pi\\colon(D^{n},S^{n-1})\\to(X,A).\\]\n\nIn the commutative diagram\n\nthe horizontal homomorphisms are induced by relative homeomorphisms, so they are isomorphisms. The first vertical homomorphism is an isomorphism by the inductive argument above. Hence\n\n\\[h\\colon\\mathcal{H}_{k}(X,A)\\to\\mathcal{H}_{k}^{\\prime}(X,A)\\]\n\nis an isomorphism for each \\(k\\). Finally, the five lemma together with the inductive hypothesis imply that\n\n\\[h\\colon\\mathcal{H}_{k}(X)\\to\\mathcal{H}_{k}^{\\prime}(X)\\]\n\nis an isomorphism. This establishes the theorem for any finite CW complex, and the similar result for pairs follows by another application of the five lemma.", "(mmd) Functional Analysis - Introduction to Operator Theory I - Brown.mmd-nilay-davit_p251-252_mmd-FacebookAI_roberta-base.json": "arbitrary element of \\((\\ell_{p})^{\\#}\\), then _multiplication by \\(d\\)_ is the transformation carrying each \\(x=\\{\\xi_{n}\\}_{n=-\\infty}^{+\\infty}\\) in \\((\\ell_{p})^{\\#}\\) to the sequence\n\n\\[M_{d}x=dx=\\{\\delta_{n}\\xi_{n}\\}_{n=-\\infty}^{+\\infty},\\]\n\nand \\(M_{d}\\) is a bounded linear transformation on \\((\\ell_{p})^{\\#}\\) with \\(\\left\\|\\,M_{d}\\right\\|=\\left\\|\\,d\\,\\right\\|_{\\infty}\\). Likewise, the linear transformation \\(T=UM_{d}\\), where \\(U\\) denotes the bilateral shift of Example E, is a bounded linear transformation on \\((\\ell_{p})^{\\#}\\) with \\(\\left\\|\\,T\\,\\right\\|=\\left\\|\\,d\\,\\right\\|_{\\infty}\\). The action of \\(T\\) can be better viewed using the notation introduced in that example:\n\n\\[\\{\\ldots,\\xi_{-1},[\\xi_{0}],\\xi_{1},\\ldots\\}\\stackrel{{ T}}{{ \\rightarrow}}\\{\\ldots,\\delta_{-2}\\xi_{-2},[\\delta_{-1}\\xi_{-1}],\\delta_{0}\\xi_ {0},\\ldots\\}.\\]\n\nThe transformation \\(T\\) is called the _weighted bilateral shift_ on \\((\\ell_{p})^{\\#}\\) with _weight sequence \\(d\\)_.\n\n**Example G.** Let \\(X\\) be a nonempty compact Hausdorff space, let \\(f_{0}\\) be a fixed function in \\(\\mathcal{C}(X)\\) (Ex. 3D), and define \\(M_{f_{0}}\\) by\n\n\\[(M_{f_{0}}g)(x)=f_{0}(x)g(x)\\]\n\nfor all \\(x\\) in \\(X\\) and all \\(g\\) in \\(\\mathcal{C}(X)\\). Then \\(M_{f_{0}}\\) is a bounded linear transformation on \\(\\mathcal{C}(X)\\) known as _multiplication by_\\(f_{0}\\). Clearly \\(\\left\\|\\,M_{f_{0}}\\right\\|=\\left\\|\\,f_{0}\\right\\|_{\\infty}\\).\n\n**Example H.** Choose a fixed point \\(x_{0}\\) in a compact Hausdorff space \\(X\\), and define \\(\\varphi(f)=f(x_{0})\\) for every \\(f\\) in \\(\\mathcal{C}(X)\\). Then \\(\\varphi\\) is a bounded linear functional on \\(\\mathcal{C}(X)\\) with \\(\\left\\|\\,\\varphi\\,\\right\\|=1\\). (This example has appeared before; recall Example 10E.)\n\nThe following two examples have to do with some of the basic structural concepts relating to normed spaces; they will reappear regularly in the sequel.\n\n**Example I.** On any normed space \\(\\mathcal{E}\\) the dilatation \\(x\\rightarrow\\lambda x,x\\in\\mathcal{E}\\), is a bounded linear transformation of \\(\\mathcal{E}\\) into itself. As was announced in Chapter 2, this transformation will consistently be denoted by \\(\\lambda_{\\mathcal{E}}\\) or, when no confusion is possible, simply by \\(\\lambda\\). We observe that if \\(\\lambda\\neq 0\\), then the dilatation \\(\\lambda\\) maps \\(\\mathcal{E}\\) onto itself, and if \\(\\mathcal{E}\\neq(0)\\), then \\(\\left\\|\\,\\lambda_{\\mathcal{E}}\\,\\right\\|=\\left|\\,\\lambda\\right|\\).\n\n**Example J.** Let \\(\\mathcal{E}\\) be a normed space and let \\(\\mathcal{M}\\) be a subspace of \\(\\mathcal{E}\\). The natural projection \\(\\pi\\) of \\(\\mathcal{E}\\) onto the quotient space \\(\\mathcal{E}/\\mathcal{M}\\) is a bounded linear transformation such that \\(\\left\\|\\,\\pi\\,\\right\\|\\leq 1\\) (see Chapter 11 (8)). Since \\(\\pi\\) carries the open unit ball \\(\\mathcal{E}_{1}^{\\circ}\\) onto the open unit ball in \\(\\mathcal{E}/\\mathcal{M}\\) (Prob. 11H), it follows that \\(\\left\\|\\,\\pi\\,\\right\\|=1\\).\n\n**Notation and Terminology**. If \\(\\mathcal{E}\\) and \\(\\mathcal{F}\\) are normed spaces, the set of all bounded linear transformations of \\(\\mathcal{E}\\) into \\(\\mathcal{F}\\) will be denoted by \\(\\mathcal{L}(\\mathcal{E},\\mathcal{F})\\). If \\(\\mathcal{E}=\\mathcal{F}\\) we employ the simpler notation \\(\\mathcal{L}(\\mathcal{E})\\) for \\(\\mathcal{L}(\\mathcal{E},\\mathcal{E})\\). The elements of \\(\\mathcal{L}(\\mathcal{E})\\) are properly known as _bounded linear operators_ on \\(\\mathcal{E}\\). In this book, however, we shall not be concerned with nonlinear analysis, and we shall have only a limited interest in unbounded transformations. Accordingly, we frequently refer to the elements of \\(\\mathcal{L}(\\mathcal{E})\\) simply as _operators_, or as _bounded operators_, on \\(\\mathcal{E}\\). A bounded operator \\(T\\) on \\(\\mathcal{E}\\) with \\(\\|\\,T\\,\\|\\leq 1\\) is called a _contraction_ on \\(\\mathcal{E}\\).\n\nIt is easily seen that if \\(\\mathcal{E}\\) and \\(\\mathcal{F}\\) are arbitrary normed spaces, then \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\) is a linear submanifold of the full space of linear transformations of \\(\\mathcal{E}\\) into \\(\\mathcal{F}\\) (Ch. 2, p. 19), and is therefore a linear space in its own right. In order to verify this, it need only be checked that if \\(S\\) and \\(T\\) are bounded, and if \\(\\lambda\\) is a scalar, then \\(S+T\\) and \\(\\lambda S\\) are bounded too. But for an arbitrary vector \\(x\\) in \\(\\mathcal{E}\\) we have\n\n\\[\\|\\,(S+T)x\\,\\|\\,\\leq\\,\\|\\,Sx\\,\\|\\,+\\,\\|\\,Tx\\,\\|\\,\\leq\\,\\|\\,S\\,\\|\\,\\|\\,x\\,\\|\\,+\\, \\|\\,T\\,\\|\\,\\|\\,x\\,\\|\\]\n\nand\n\n\\[\\|\\,(\\lambda S)x\\,\\|\\,=\\,\\|\\,\\lambda(Sx)\\,\\|\\,\\leq\\,|\\lambda\\|\\,S\\,\\|\\,\\|\\,x\\,\\|,\\]\n\nand from these inequalities it follows not only that \\(S+T\\) and \\(\\lambda S\\) are bounded, but also that\n\n\\[\\|\\,S+T\\,\\|\\,\\leq\\,\\|\\,S\\,\\|\\,+\\,\\|\\,T\\,\\|\\]\n\nand\n\n\\[\\|\\,\\lambda S\\,\\|\\,=\\,|\\lambda|\\,S\\,\\|.\\]\n\nSince it is clear that \\(\\|\\,S\\,\\|\\,=0\\) implies \\(S=0\\), we see that \\(\\|\\,\\,\\|\\,\\), as defined in (2), is, in fact, a norm on \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\). Is the normed space \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\) complete?\n\n**Proposition 12.2**.: _If \\(\\mathcal{E}\\) is a normed space and \\(\\mathcal{F}\\) is a Banach space, then \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\) is a Banach space._\n\nProof. Let \\(\\{T_{n}\\}\\) be a Cauchy sequence in \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\). The inequality \\(\\|\\,T_{n}x-T_{m}x\\,\\|\\leq\\,\\|\\,T_{n}-T_{m}\\,\\|\\,\\|\\,x\\,\\|\\) shows that for each \\(x\\) in \\(\\mathcal{E}\\) the sequence \\(\\{T_{n}x\\}\\) is a Cauchy sequence in \\(\\mathcal{F}\\). Since \\(\\mathcal{F}\\) is complete there exists a vector in \\(\\mathcal{F}-\\)call it \\(Tx-\\)such that \\(T_{n}x\\to Tx\\). This defines a mapping \\(T\\) of \\(\\mathcal{E}\\) into \\(\\mathcal{F}\\). That \\(T\\) is linear is clear:\n\n\\[T(\\alpha x+\\beta y)=\\lim_{n}(\\alpha T_{n}x+\\beta T_{n}y)=\\alpha Tx+\\beta Ty.\\]\n\nThe proof that \\(\\mathcal{L}(\\mathcal{E},\\,\\mathcal{F})\\) is complete will be concluded by showing that \\(T\\) is also bounded and that \\(\\|\\,T-T_{n}\\,\\|\\to 0\\). To see this, let \\(\\varepsilon\\) be a positive number, and choose \\(N\\) such that \\(\\|\\,T_{n}-T_{m}\\,\\|\\leq\\varepsilon\\) for all \\(m\\), \\(n\\geq N\\). Then \\(\\|\\,T_{n}x-T_{m}x\\,\\|\\leq\\varepsilon\\,\\|\\,x\\,\\|\\) for each \\(x\\) in \\(\\mathcal{E}\\) and, letting \\(n\\) tend to infinity, we obtain\n\n\\[\\|\\,Tx-T_{m}x\\,\\|\\,\\leq\\varepsilon\\,\\|\\,x\\,\\|\\]for all \\(m\\geq N\\). (Recall that closed balls in a metric space are closed sets.) Thus we see that \\(T-T_{m}\\) is bounded and satisfies \\(\\parallel T-T_{m}\\parallel\\leq\\varepsilon\\) for all \\(m\\geq N\\). From this it follows, in the first place, that \\(T=(T-T_{m})+T_{m}\\) is also bounded, and, secondly, that \\(\\parallel T-T_{m}\\parallel\\to 0\\). ", "(mmd) Homological Algebra - A Course in Homological Algebra - Hilton.mmd-nilay-noah-p331-332-FacebookAI_roberta-base.json": "## 1 Homological Algebra and Algebraic Topology\n\nHomological algebra originated, as we have said, as an abstraction from algebraic topology (see the Introduction to our text and the Introduction to Chapter VI). Here we would like to go into somewhat greater detail in forging that connection, since many students today study homological algebra without the benefit of a prior familiarity with the related concepts of algebraic topology.\n\nThe primary link with algebraic topology is via the homology theory of topological spaces. Let us consider the simplest case, that of a polyhedron triangulated as a _simplicial complex_\\(K\\). Thus \\(K\\) is a union of simplexes \\(s^{n}\\) of various dimensions \\(n\\geq 0\\). A _simplex_\\(s^{n}\\) is just the convex hull of \\(n+1\\) independent points, the _vertices_ of \\(s^{n}\\), in some Euclidean space. If \\(s\\) and \\(t\\) are two simplexes of \\(K\\), then either they are disjoint or they intersect in a common _face_. We may _orient_ the simplexes of \\(K\\); then the oriented \\(n\\)-simplexes become a _basis_ for a free abelian group \\(C_{n}(K)\\), the \\(n\\)th _chain group_ of \\(K\\) (with integer coefficients). The _boundary_ of anoriented \\(n\\)-simplex is an \\((n-1)\\)-chain according to the formula\n\n\\[\\partial(a_{0}a_{1}\\cdots a_{n})=\\sum_{i=0}^{n}\\ (-1)^{i}(a_{0}a_{1}\\cdots\\hat{a }_{i}\\cdots a_{n}),\\]\n\nwhere \\(a_{0}\\), \\(a_{1}\\),..., \\(a_{n}\\) are the vertices of the oriented \\(n\\)-simplex, and \\(\\hat{a}_{i}\\) indicates that the vertex \\(a_{i}\\) is to be _deleted_ (compare formula (13.3) of Chapter VI). Then \\(\\partial\\partial=0\\), so that \\(\\big{(}\\mathbf{C}(K),\\partial\\big{)}\\) is a free abelian chain complex. We may then carry out the various processes described in the text. Thus we may pass to homology, obtaining the (integral) homology groups \\(H_{\\bullet}(K)\\); we may tensor with an abelian coefficient group \\(G\\), obtaining the homology groups \\(H_{\\bullet}(K;\\,G)\\) of \\(K\\) with coefficients in \\(G\\); we may form the _cochain complex_ Hom(\\(\\mathbf{C}(K)\\), \\(G\\)), and obtain the cohomology groups \\(H^{\\bullet}(K;\\,G)\\) of \\(K\\) with coefficients in \\(G\\); and we have _universal coefficient theorems_ (see Theorems 2.5 and 3.3 of Chapter V) relating these homology and cohomology groups with coefficients in \\(G\\) to the integral homology groups \\(H_{\\bullet}(K)\\). Moreover, we may introduce _chain maps_ and _chain homotopies_ as prototypes of the general concepts described in our text. Thus a simplicial map \\(f:K\\to L\\), that is, a function from the vertices of \\(K\\) to the vertices of \\(L\\) which sends vertices of a common simplex to vertices of a common simplex, induces in an obvious way a chain-map \\(\\varphi:\\mathbf{C}(K)\\to\\mathbf{C}(L)\\). A continuous map of the underlying polyhedra induces (but not uniquely) a simplicial map of a sufficiently fine subdivision of \\(K\\) into \\(L\\); and homotopic continuous maps lead to chain-homotopic chain-maps. There is a vitally important chain-map \\(\\omega:\\mathbf{C}(K)\\to\\mathbf{C}(K^{\\prime})\\) from the chain-complex of \\(K\\) to the chain-complex of \\(K^{\\prime}\\), the (first) barycentric subdivision of \\(K\\), which induces an isomorphism of homology groups and serves to explain (and to prove) the topological invariance - indeed the homotopy invariance - of the homology groups.\n\nThe developments described thus far may be generalized to a broader class of topological spaces beyond the polyhedra. Thus one may consider Whitehead _cell-complexes_ (or CW-complexes) instead of simplicial complexes; or one may use the so-called _singular theory_, building a simplicial complex from the _singular simplexes_ of an arbitrary topological space (see, for example, [D]).\n\nLet us now show how to apply the fundamental Theorem 2.1 of Chapter IV, proving that a short exact sequence of chain-complexes induces a long exact homology sequence. The first application is obvious and immediate: if \\(B^{\\prime}\\mapsto B\\twoheadrightarrow B^{\\prime}\\) is a short exact sequence of abelian groups then, since \\(\\mathbf{C}(K)\\) is free abelian, \\(\\mathbf{C}(K)\\otimes B^{\\prime}\\mapsto\\mathbf{C}(K)\\otimes B\\twoheadrightarrow \\mathbf{C}(K)\\otimes B^{\\prime\\prime}\\) is a short exact sequence of chain-complexes, yielding the _exact coefficient sequence in homology_\n\n\\[\\cdots\\to H_{n}(K;\\,B^{\\prime})\\to H_{n}(K;\\,B)\\to H_{n}(K;\\,B^{\\prime})\\to H_{n-1}(K;\\,B^{\\prime})\\to\\cdots.\\]", "(mmd) Noncommutative Algebra - Introduction to Noncommutative Algebra - Bresar.mmd-nilay-victoria-p11-12-FacebookAI_roberta-base.json": "### 5 Multiplication Algebra\n\nLet \\(A\\) be an algebra. For \\(a,\\,b\\in A\\) we define maps \\(L_{a},R_{b}:A\\to A\\), called the **left multiplication map** and **right multiplication map**, by\n\n\\[L_{a}(x):=ax,\\ \\ R_{b}(x):=xb.\\]\n\nThese maps will frequently play important roles in this book. Of course, they can be defined if \\(A\\) is merely a ring, but we will usually treat them on algebras. In this case they can be considered as elements of \\(\\mathrm{End}_{F}(A)\\), the algebra of all linear operators from \\(A\\) into itself.\n\nNote that for all \\(a,\\,b\\in A,\\,\\lambda,\\,\\mu\\in F\\) we have\n\n\\[L_{ab}=\\,L_{a}L_{b},\\ \\ \\ R_{ab}=\\,R_{b}R_{a},\\] \\[L_{a}R_{b}=R_{b}L_{a},\\] \\[L_{\\lambda a+\\mu b}=\\,\\lambda L_{a}+\\mu L_{b},\\ \\ \\ R_{\\lambda a+\\mu b}=\\lambda R_{a}+\\mu R_{b}.\\]\n\nHence we conclude that\n\n\\[M(A):=\\{L_{a_{1}}R_{b_{1}}+\\cdots+L_{a_{n}}R_{b_{n}}\\,|\\,a_{i},\\,b_{i}\\in A,\\, n\\in\\mathbb{N}\\}\\]\n\nis a subalgebra of \\(\\mathrm{End}_{F}(A)\\).\n\n**Definition 1.22**: The algebra \\(M(A)\\) is called the **multiplication algebra of \\(A\\)**.\n\nIf \\(A\\) is unital, then \\(L_{a}=L_{a}R_{1}\\) and \\(R_{b}=L_{1}R_{b}\\) lie in \\(M(A)\\), and so in this case we can describe \\(M(A)\\) as the subalgebra of \\(\\mathrm{End}_{F}(A)\\) generated by all left and right multiplication maps. We also remark that \\(a=L_{a}(1)=R_{a}(1)\\), and so the conditions \\(a=0\\), \\(L_{a}=0\\), and \\(R_{a}=0\\) are equivalent if \\(A\\) is unital.\n\n_Remark 1.23_: Take \\(f\\!\\in\\!M(A)\\). Then there exist \\(a_{i},\\,b_{i}\\!\\in\\!A\\) such that \\(f=\\sum_{i=1}^{n}L_{a_{i}}R_{b_{i}}\\), i.e.,\n\n\\[f(x)=\\sum_{i=1}^{n}a_{i}xb_{i},\\ \\ x\\in A.\\]\n\nThese elements are not unique, \\(f\\) can be presented as a sum of operators of the form \\(L_{a}R_{b}\\) in many ways. If \\(f\\neq 0\\), then \\(a_{i},\\,b_{i}\\) can be chosen so that both the set of all \\(a_{i}\\)'s and the set of all \\(b_{i}\\)'s are linearly independent. For example, this is fulfilled if we require that \\(n\\) is minimal. Indeed, if, under this assumption, one of the elements, say \\(b_{n}\\), was a linear combination of the others, \\(b_{n}=\\sum_{i=1}^{n-1}\\lambda_{i}b_{i}\\), then \\(f\\) would be equal to\n\n\\[\\sum_{i=1}^{n-1}L_{a_{i}+\\lambda_{i}a_{n}}R_{b_{i}},\\]contradicting the minimality of \\(n\\). Furthermore, if \\(\\{u_{i}\\mid i\\in I\\}\\) is a basis of \\(A\\), then we can express each \\(R_{b}\\) as a linear combination of \\(R_{u_{i}}\\), from which we see that every \\(f\\in M(A)\\) is a (finite) sum of operators of the form \\(L_{a_{i}}R_{u_{i}}\\). Similarly, \\(f\\) can be written as a sum of operators of the form \\(L_{u_{i}}R_{b_{i}}\\), and, moreover, as a linear combination of operators \\(L_{u_{i}}R_{u_{j}}\\).\n\nThe fact that the elements from \\(M(A)\\) can be expressed in different ways through left and right multiplication maps may create some annoyance. The following lemma shows that in central simple algebras this problem is controllable.\n\nLemma 1.24: _Let \\(A\\) be a central simple algebra, and let \\(a_{i},\\,b_{i}\\in A\\) be such that \\(\\sum_{i=1}^{n}L_{a_{i}}R_{b_{i}}=0\\). If the \\(a_{i}\\)'s are linearly independent, then each \\(b_{i}=0\\). Similarly, if the \\(b_{i}\\)'s are linearly independent, then each \\(a_{i}=0\\)._\n\nProof: The two assertions of the lemma are analogous, so we consider only the case where the \\(a_{i}\\)'s are independent. Suppose \\(b_{n}\\neq 0\\). Since \\(A\\) is simple, the ideal generated by \\(b_{n}\\) is equal to \\(A\\). That is, \\(\\sum_{j=1}^{m}w_{j}b_{n}z_{j}=1\\) for some \\(w_{j},\\,z_{j}\\in A\\). Hence\n\n\\[0=\\sum_{j=1}^{m}R_{z_{j}}\\Big{(}\\sum_{i=1}^{n}L_{a_{i}}R_{b_{i}}\\Big{)}R_{w_{j }}=\\sum_{i=1}^{n}L_{a_{i}}\\Big{(}\\sum_{j=1}^{m}R_{w_{j}b_{i}z_{j}}\\Big{)}=\\sum_ {i=1}^{n}L_{a_{i}}R_{c_{i}}\\]\n\nwhere \\(c_{i}=\\sum_{j=1}^{m}w_{j}b_{i}z_{j}\\); thus, \\(c_{n}=1\\). This clearly implies that \\(n>1\\). We may assume that \\(n\\) is the smallest natural number for which the lemma does not hold. Since\n\n\\[0=\\Big{(}\\sum_{i=1}^{n}L_{a_{i}}R_{c_{i}}\\Big{)}R_{x}-R_{x}\\Big{(}\\sum_{i=1}^{ n}L_{a_{i}}R_{c_{i}}\\Big{)}=\\sum_{i=1}^{n-1}L_{a_{i}}R_{xc_{i}-c_{i}x}\\]\n\nfor every \\(x\\in A\\), it thus follows that \\(xc_{i}-c_{i}x=0\\). Consequently, \\(c_{i}\\in F\\). But then\n\n\\[0=\\sum_{i=1}^{n}L_{a_{i}}R_{c_{i}}=L_{c_{1}a_{1}+\\cdots+c_{n}a_{n}},\\]\n\nwhich contradicts the linear independence of the \\(a_{i}\\)'s. \n\nIn the next lemma we consider the finite dimensional situation. Let us recall that if \\([A:F]=d\\), then \\([\\text{End}_{F}(A):F]=d^{2}\\).\n\nLemma 1.25: _If \\(A\\) is a finite dimensional central simple algebra, then \\(M(A)=\\text{End}_{F}(A)\\)._\n\nProof: Let \\(\\{u_{1},\\,\\ldots,\\,u_{d}\\}\\) be a basis of \\(A\\). Lemma 1.24 implies that the operators \\(L_{u_{i}}R_{u_{j}}\\), \\(1\\leq i,j\\leq d\\), are linearly independent. This becomes clear if we rewrite \\(\\sum_{i,j=1}^{d}\\lambda_{ij}L_{u_{i}}R_{u_{j}}\\) as \\(\\sum_{i=1}^{d}L_{u_{i}}R_{b_{i}}\\) where \\(b_{i}=\\sum_{j=1}^{d}\\lambda_{ij}u_{j}\\). Therefore\\[[M(A):F]\\geq d^{2}=[\\operatorname{End}_{F}(A):F],\\]\n\nand so \\(M(A)=\\operatorname{End}_{F}(A)\\).", "(mmd) Functional Analysis - Introduction to Operator Theory I - Brown.mmd-nilay-davit_p180-181_mmd-FacebookAI_roberta-base.json": "**Theorem 9.11**.: _Let \\(\\Phi\\) be a weak measure ring isomorphism of the measure ring \\((\\dot{\\mathbf{S}},\\,\\dot{\\mu})\\) of a \\(\\sigma\\)-finite measure space \\((X,\\mathbf{S},\\,\\mu)\\) onto the measure ring \\((\\dot{\\mathbf{T}},\\,\\dot{\\nu})\\) of a \\(\\sigma\\)-finite measure space \\((Y,\\mathbf{T},\\,v)\\). Then there exists a nonnegative measurable function \\(h\\) on \\(Y\\) and a linear isomorphism \\(T_{\\Phi}\\) of \\(\\dot{\\mathcal{L}}_{\\mu}\\) onto \\(\\dot{\\mathcal{L}}_{\\nu}\\) satisfying the following conditions:_\n\n1. _If_ \\(E\\) _is a set in_ \\(\\mathbf{S}\\) _such that_ \\(\\mu(E)<+\\infty\\)_, and if_ \\(\\Phi([E])=[F]\\)_, then_ \\(T_{\\Phi}([\\chi_{E}])=[h\\chi_{F}]\\)_,_\n2. _If_ \\([f]\\in\\dot{\\mathcal{L}}_{\\mu}\\) _and_ \\(T_{\\Phi}([f])=[g]\\)_, then_ \\(T_{\\Phi}([f\\,])=([g\\,])\\) _and_ \\[\\int_{X}[f]d\\mu=\\int_{Y}[g]dv.\\]\n\n_Both the function \\(h\\) and the linear transformation \\(T_{\\Phi}\\) are uniquely determined by \\(\\Phi\\) and conditions (i) and (ii), and the isomorphism \\(T_{\\Phi}\\) is an isometry between the metric spaces \\(\\dot{\\mathcal{L}}_{\\mu}\\) and \\(\\dot{\\mathcal{L}}_{\\nu}\\) of Theorem 9.10._\n\nSketch of Proof. If we define \\(v_{0}(F)=\\dot{\\mu}(\\Phi^{-1}([F]))\\), \\(F\\in\\mathbf{T}\\), it is easy to verify that \\(v_{0}\\) is a \\(\\sigma\\)-finite measure on \\((Y,\\mathbf{T})\\) such that \\(v_{0}\\) is equivalent to \\(v\\), and that \\(\\Phi\\) is a measure ring isomorphism of \\((\\dot{\\mathbf{S}},\\,\\dot{\\mu})\\) onto the measure ring \\((\\dot{\\mathbf{T}},\\,\\dot{v}_{0})\\) of the measure space \\((Y,\\mathbf{T},\\,v_{0})\\). Since Theorem 9.10 applies to this latter isomorphism, a moment's reflection discloses that it suffices to treat the case in which \\(\\mu\\) and \\(v\\) are equivalent measures on the same measurable space \\((Y,\\mathbf{T})\\) and the isomorphism \\(\\Phi\\) is the identity mapping on \\(\\dot{\\mathbf{T}}\\). In this case there exists a nonnegative measurable function \\(h=d\\mu/dv\\) on \\(Y\\) such that\n\n\\[\\int_{Y}f\\ d\\mu=\\int_{Y}hf\\ dv,\\ \\ \\ \\ \\ \\ f\\in\\dot{\\mathcal{L}}_{\\mu}\\]\n\n(Th. 9.6), and if we simply define \\(T_{\\Phi}([f])=[h/]\\) for each element \\([f]\\) of \\(\\dot{\\mathcal{L}}_{\\mu}\\), then it is obvious that \\(T_{\\Phi}\\) is a linear transformation satisfying (i) and (ii). The fact that \\(T_{\\Phi}\\) is also an isometry follows from condition (ii), just as before. The uniqueness of the function \\(h\\) follows from the fact that \\(h\\) must coincide with \\(d\\mu/dv\\) on sets of finite measure with respect to \\(\\mu\\), along with the fact that \\(\\mu\\) is \\(\\sigma\\)-finite; the uniqueness of \\(T_{\\Phi}\\) is then also clear.\n\nThe scope of Theorem 9.10 is considerably enhanced by the fact that, up to isomorphism, there is only one separable atom-free measure space of a given size.\n\n**Theorem 9.12** (Halmos-von Neumann Theorem [33]).: _If \\((X,\\mathbf{S},\\mu)\\) is a separable atom-free measure space with \\(0\\leq\\mu(X)\\leq+\\infty,\\) then \\((X,\\mathbf{S},\\mu)\\) is isomorphic to the measure space consisting of Lebesgue-Borel measure on the interval \\(\\llbracket 0,\\mu(X)\\rangle.\\)_\n\nProof.: If \\((\\dot{\\mathbf{S}}_{\\mathcal{F}},\\rho)\\) is the metric space associated with \\((X,\\mathbf{S},\\mu),\\) then by hypothesis there exists a dense sequence \\(\\{[E_{n}]\\}\\) in \\(\\dot{\\mathbf{S}}_{\\mathcal{F}}.\\) Set \\(X_{0}=\\bigcup_{n}E_{n}.\\) If \\(E\\) is a measurable subset of \\(X\\setminus X_{0},\\) then \\(\\mu(E)\\) must be either \\(0\\) or \\(+\\infty.\\) Since \\(\\mu\\) is atom-free, this implies that \\(\\mu(X\\setminus X_{0})=0,\\) and hence that \\(\\mu\\) is \\(\\sigma\\)-finite. Thus it suffices to treat the case \\(0<\\mu(X)<+\\infty\\) (cf. Example 8H, Example K, and Problem 8R). Accordingly we assume henceforth that \\(\\{[E_{n}]\\}_{n=1}^{\\times}\\) is a fixed dense sequence in the metric space associated with the finite measure space \\((X,\\mathbf{S},\\mu)\\) (with \\(\\mu(X)>0\\)), and we write \\((Y,\\mathbf{B},v)\\) for the measure space consisting of the interval \\(\\llbracket 0,\\mu(X)\\rrbracket\\) equipped with Lebesgue-Borel measure. For each positive integer \\(n\\) let \\(\\mathcal{P}_{n}\\) be the partition of \\(X\\) determined by the sets \\(E_{1},E_{2},\\ldots,E_{n},\\) that is, the partition consisting of all the nonempty subsets of \\(X\\) of the form \\(A_{1}\\cap\\cdots\\cap A_{n},\\) where, for each \\(i=1,\\ldots,n,\\)\\(A_{i}\\) denotes either \\(E_{i}\\) or \\(X\\setminus E_{i}\\) (Prob. 1L). Let \\(\\mathbf{R}_{n}\\) denote the ring of subsets of \\(X\\) generated by \\(\\mathcal{P}_{n}\\) (thus \\(\\mathbf{R}_{n}\\) consists of the unions of the various sets belonging to \\(\\mathcal{P}_{n}\\)), and set \\(\\dot{\\mathbf{R}}_{n}=\\{[A]:A\\in\\mathbf{R}_{n}\\}.\\) Note that \\(\\mathcal{P}_{n+1}\\) refines \\(\\mathcal{P}_{n}\\) and that \\(\\mathbf{R}_{n}\\subset\\mathbf{R}_{n+1}\\) for each positive integer \\(n.\\) Hence, using Problem X repeatedly and starting with \\(n=1,\\) we may construct by induction a sequence \\(\\{\\varphi_{n}\\}_{n=1}^{\\infty}\\) of mappings and an accompanying sequence \\(\\{\\mathcal{P}_{n}\\}_{n=1}^{\\infty}\\) of partitions of the interval \\(\\llbracket 0,\\mu(X)\\rrbracket\\) possessing the following properties for each positive integer \\(n\\):\n\n1. The partition \\(\\mathcal{P}_{n+1}\\) refines \\(\\mathcal{P}_{n},\\)\n2. If \\(\\mathcal{P}_{n}=\\{t_{i}\\}_{i=0}^{N_{n}},\\) then \\(\\varphi_{n}\\) maps \\(\\dot{\\mathbf{R}}_{n}\\) onto the subset of \\(\\dot{\\mathbf{B}}\\) consisting of equivalence classes \\(\\llbracket B\\rrbracket,\\) where \\(B\\) runs over the ring of unions of the subintervals \\([t_{i-1},t_{i}),\\)\\(i=1,\\ldots,N_{n},\\) of \\(\\mathcal{P}_{n},\\)\n3. \\(\\varphi_{n+1}\\,|\\,\\mathbf{R}_{n}=\\varphi_{n},\\)\n4. If \\(A\\in\\mathbf{R}_{n},\\) then \\(\\dot{\\psi}(\\varphi_{n}(\\llbracket A\\rrbracket))=\\dot{\\mu}(\\llbracket A \\rrbracket),\\)\n5. If \\(A_{1},\\ A_{2}\\in\\mathbf{R}_{n},\\) then \\(\\varphi_{n}(\\llbracket A_{1}\\rrbracket\\vee\\llbracket A_{2}\\rrbracket)=\\varphi_ {n}(\\llbracket A_{1}\\rrbracket)\\vee\\varphi_{n}(\\llbracket A_{2}\\rrbracket)\\) and \\(\\varphi_{n}(\\llbracket A_{1}\\rrbracket\\setminus\\llbracket A_{2}\\rrbracket)= \\varphi_{n}(\\llbracket A_{1}\\rrbracket)\\setminus\\varphi_{n}(\\llbracket A_{2}\\rrbracket).\\)\n\nLet \\(\\dot{\\mathbf{R}}=\\bigcup_{n}\\dot{\\mathbf{R}}_{n}\\) and define \\(\\Phi_{0}\\) on \\(\\dot{\\mathbf{R}}\\) by setting \\(\\Phi_{0}(\\llbracket A\\rrbracket)=\\varphi_{n}(\\llbracket A\\rrbracket)\\) for any one \\(n\\) such that \\(\\llbracket A\\rrbracket\\in\\dot{\\mathbf{R}}_{n}.\\) The mapping \\(\\Phi_{0}\\) is unambiguously defined by virtue of (iii), and it is clear from (iv) and (v) that if \\(\\llbracket A\\rrbracket\\in\\dot{\\mathbf{R}}\\) then \\(\\dot{\\psi}(\\Phi_{0}(\\llbracket A\\rrbracket))=\\dot{\\mu}(\\llbracket A\\rrbracket),\\) and likewise that \\(\\Phi_{0}\\) preserves the operations \\(\\vee\\) and \\(\\setminus.\\) Hence \\(\\Phi_{0}\\) is an isometry of \\(\\dot{\\mathbf{R}},\\) regarded as a subset of \\((\\dot{\\mathbf{S}},\\rho),\\) into the metric space associated with \\((Y,\\mathbf{B},v).\\) Moreover, \\(\\dot{\\mathbf{R}}\\) is dense in \\(\\dot{\\mathbf{S}},\\) since \\(\\dot{\\mathbf{R}}\\) contains the entire sequence \\(\\{\\llbracket E_{n}\\rrbracket\\},\\) and the range of \\(\\Phi_{0}\\) is also dense in \\(\\dot{\\mathbf{B}},\\) since the sequence \\(\\{\\text{mesh }\\mathcal{P}_{n}\\}\\) tends to zero as may be seen by consulting Problem W. Hence, extending by continuity, we obtain an isometry \\(\\Phi\\) of \\(\\dot{\\mathbf{S}}\\) onto \\(\\dot{\\mathbf{B}}\\). Since \\(\\Phi\\) is isometric, we have \\(\\dot{v}(\\Phi([E]))=\\dot{\\mu}([E])\\) for every \\(E\\) in \\(\\mathbf{S}\\). Likewise, \\(\\Phi|\\dot{\\mathbf{R}}=\\Phi_{0}\\) preserves \\(\\vee\\) and \\(\\setminus\\), and since \\(\\dot{\\mathbf{R}}\\) is dense in \\(\\dot{\\mathbf{S}}\\), and since the operations \\(\\vee\\) and \\(\\setminus\\) are continuous on \\(\\dot{\\mathbf{S}}\\) and on \\(\\dot{\\mathbf{B}}\\) (Prop. 9.9), we see that \\(\\Phi\\) also preserves \\(\\vee\\) and \\(\\setminus\\). Finally, this shows that \\(\\Phi\\) is order preserving, from which it follows at once that\n\n\\[\\Phi\\left(\\bigvee_{n=1}^{\\infty}[F_{n}]\\right)=\\bigvee_{n=1}^{\\infty}\\Phi([F_{ n}])\\]\n\nfor every sequence \\(\\{[F_{n}]\\}\\) in \\(\\dot{\\mathbf{S}}\\). Thus \\(\\Phi\\) is a measure ring isomorphism of \\((\\dot{\\mathbf{S}},\\,\\dot{\\mu})\\) onto \\((\\dot{\\mathbf{B}},\\,\\dot{v})\\). ", "(mmd) Homological Algebra - A Course in Homological Algebra - Hilton.mmd-nilay-hafsah-p77-78-FacebookAI_roberta-base.json": "[MISSING_PAGE_FAIL:88]\n\nand\n\n\\[\\left(F(i_{1})\\,p_{1}+F(i_{2})\\,p_{2}\\right)\\left\\{Fp_{1},Fp_{2}\\right\\} = F(i_{1})\\,p_{1}\\left\\{Fp_{1},Fp_{2}\\right\\}+F(i_{2})\\,p_{2}\\left\\{Fp _{1},Fp_{2}\\right\\}\\] \\[= Fi_{1}Fp_{1}+Fi_{2}Fp_{2}\\] \\[= F(i_{1}p_{1}+i_{2}p_{2})\\,,\\quad\\text{since $F$ satisfies (iii)},\\] \\[= 1\\,.\\quad\\qed\\]\n\nWe call a functor satisfying any of the three conditions of Proposition 9.5 an _additive_ functor. Such functors will play a crucial role in the sequel. However in order to be able to do effective homological algebra we need to introduce a richer structure into our additive categories; we want to have kernels, cokernels and images. Recall that kernels, if they exist, are always monomorphisms and (by duality) cokernels are always epimorphisms. In an additive category a monomorphism is characterized as having zero kernel, an epimorphism as having zero cokernel.\n\n_Definition._ An _abelian category_ is an additive category in which\n\n1. every morphism has a kernel and a cokernel;\n2. every monomorphism is the kernel of its cokernel; every epimorphism is the cokernel of its kernel;\n3. every morphism is expressible as the composite of an epimorphism and a monomorphism.\n\nThe reader will verify that all the examples given of additive categories are, in fact, examples of abelian categories. The category of finite abelian groups is abelian; the category of free abelian groups is additive but not abelian. We will be content in this section to prove a few fundamental properties of abelian categories and to define exact sequences. Notice however that the concept of an abelian category is certainly self-dual.\n\n**Proposition 9.6**.: _Given \\(\\varphi:A\\!\\to\\!B\\) in the abelian category \\(\\mathfrak{A}\\), we may develop from \\(\\varphi\\) the sequence_\n\n\\[(S_{\\varphi})\\qquad\\quad K\\!\\stackrel{{\\mu}}{{\\to}}A\\!\\stackrel{{\\eta}}{{\\to}}I\\!\\stackrel{{\\nu}}{{\\to}}B\\!\\stackrel{{\\varepsilon}}{{\\to}}C\\,,\\]\n\n_where \\(\\varphi=v\\eta,\\mu\\) is the kernel of \\(\\varphi,\\varepsilon\\) is the cokernel of \\(\\varphi,\\eta\\) is the cokernel of \\(\\mu\\), and \\(v\\) is the kernel of \\(\\varepsilon\\). Moreover, the decomposition of \\(\\varphi\\) as a composite of an epimorphism and a monomorphism is essentially unique._\n\nWe first prove a lemma.\n\n**Lemma 9.7**.: _Suppose \\(v\\eta\\) and \\(\\eta\\) have the same kernel and \\(\\eta\\) is an epimorphism. Then \\(v\\) is a monomorphism._\n\n_Proof_. Use property (iii) of an abelian category to write \\(v\\!=\\!\\varrho\\sigma\\), with \\(\\sigma\\) epimorphic, \\(\\varrho\\) monomorphic. Then \\(v\\eta=\\varrho\\sigma\\eta\\) and if \\(\\mu\\) is the kernel of \\(\\sigma\\eta\\), then \\(\\mu\\) is the kernel of \\(\\varrho\\sigma\\eta=v\\eta\\) and hence also of \\(\\eta\\). Thus \\(\\mu\\) is the kernel of \\(\\sigma\\eta\\) and of \\(\\eta\\) so that, by property (ii), \\(\\sigma\\eta\\) and \\(\\eta\\) are both cokernelsof \\(\\mu\\). This means that there exists an isomorphism in \\(\\mathfrak{A}\\), say \\(\\omega\\), such that \\(\\sigma\\eta=\\omega\\eta\\), so that \\(\\sigma=\\omega\\). Thus \\(\\sigma\\) is an isomorphism so that \\(v\\) is a monomorphism.", "(mmd) Probability Theory - Integration and Probability - Malliavin.mmd-nilay-davit_p113_mmd-FacebookAI_roberta-base.json": "Proof.\n\n\\[\\widehat{\\tau_{g_{0}}f}(\\chi)=\\int_{G}f(g-g_{0})\\chi(g)dg.\\]\n\nThe change of variables \\(g\\mapsto g-g_{0}=g^{\\prime}\\) leaves the Haar measure invariant: \\(dg=dg^{\\prime}\\). Making this change of variables gives\n\n\\[\\int f(g-g_{0})\\chi(g)dg=\\int f(g^{\\prime})\\chi(g^{\\prime}+g_{0})dg^{\\prime}= \\chi(g_{0})\\int f(g^{\\prime})\\chi(g^{\\prime})dg^{\\prime}.\\Box\\]\n\n#### 1.7.3 Continuity of the translation operator\n\nLet \\(C_{K}(G)\\) denote the compactly supported continuous functions on \\(G\\), with the norm\n\n\\[\\|f\\|_{C_{K}}=\\max|f(g)|,\\ g\\in G.\\]\n\n**Continuity theorem.**_(i) Let \\(f\\in C_{K}(G)\\). Then the mapping from \\(G\\) to \\(C_{K}(G)\\) defined by \\(g\\mapsto\\tau_{g}f\\) is uniformly continuous. (ii) Similarly, let \\(u\\in L^{p}(G)\\), where \\(1\\leq p<+\\infty\\). Then the mapping from \\(G\\) to \\(L^{p}(G)\\) defined by \\(g\\mapsto\\tau_{g}u\\) is uniformly continuous._\n\nProof.(i) Since \\(f\\) is continuous and compactly supported, \\(f\\) is _uniformly_ continuous. Given \\(\\epsilon>0\\), there exists \\(\\eta\\) such that\n\n\\[|f(g_{1})-f(g_{2})|<\\epsilon\\quad\\mbox{if}\\quad d(g_{1},g_{2})<\\eta.\\]\n\nHence\n\n\\[|\\tau_{g_{0}}(f)(g)-\\tau_{g_{0}^{\\prime}}(f)(g)|=|f(g-g_{0})-f(g-g_{0}^{\\prime })|<\\epsilon\\quad\\mbox{if}\\quad d(g-g_{0},g-g_{0}^{\\prime})<\\eta.\\]\n\nBut it follows from the invariance of the distance under translation (cf. 1.1(ii)) that \\(d(g-g_{0},g-g_{0}^{\\prime})=d(g_{0},g_{0}^{\\prime})\\), whence\n\n\\[\\|\\tau_{g_{0}}(f)-\\tau_{g_{0}^{\\prime}}(f)\\|_{C_{b}}<\\epsilon\\quad\\mbox{if} \\quad d(g_{0},g_{0}^{\\prime})<\\eta.\\Box\\]\n\n(ii) We now consider the case where \\(u\\in L^{p}\\). Since \\(p<+\\infty\\), by II-3.5 there exists \\(f\\in C_{K}(G)\\) such that \\(\\|f-u\\|_{L^{p}}<\\frac{\\epsilon}{3}\\). Let us write\n\n\\[\\tau_{g}u-\\tau_{g^{\\prime}}u=\\tau_{g}f-\\tau_{g^{\\prime}}f+\\tau_{g^{\\prime}}(f- u)-\\tau_{g}(f-u).\\]\n\nUsing 1.7.1(ii),\n\n\\[\\|\\tau_{g}(f-u)\\|_{L^{p}}=\\|f-u\\|_{L^{p}}<\\frac{\\epsilon}{3},\\]\n\nwhence\n\n\\[\\|\\tau_{g}u-\\tau_{g^{\\prime}}u\\|_{L^{p}}<\\frac{2}{3}\\epsilon+\\|\\tau_{g}f-\\tau _{g^{\\prime}}f\\|_{L^{p}}.\\]\n\nLet \\(A=\\mbox{supp}\\,(f)\\). Then\n\n\\[\\begin{array}{c}\\mbox{supp}\\,(\\tau_{g}f-\\tau_{g^{\\prime}}f)\\subset\\tau_{g}(A )\\cup\\tau_{g^{\\prime}}(A),\\\\ \\mbox{meas}\\,(\\mbox{supp}\\,(\\tau_{g}f-\\tau_{g^{\\prime}}f))<2\\ \\mbox{meas}\\,(A),\\\\ \\|\\tau_{g}f-\\tau_{g^{\\prime}}f\\|_{L^{p}}\\leq\\|\\tau_{g}f-\\tau_{g^{\\prime}}f\\|_{ C_{b}}(2\\ \\mbox{meas}\\,(A))^{1/p}.\\end{array}\\]\n\nThe right-hand side of the last inequality tends to zero as \\(d(g,g^{\\prime})\\to 0\\) by the first part of the theorem. \\(\\Box\\)", "(mmd) Graph Theory - Graph Theory - Diestel.mmd-nilay-nilay-noah-p307-309-FacebookAI_roberta-base.json": "## Chapter 1 Introduction\n\nIn Chapter 1.8 we briefly discussed the problem of when a graph contains an Euler tour, a closed walk traversing every edge exactly once. The simple Theorem 1.8.1 solved that problem quite satisfactorily. Let us now ask the analogous question for vertices: when does a graph \\(G\\) contain a closed walk that contains every vertex of \\(G\\) exactly once? If \\(|G|\\geqslant 3\\), then any such walk is a cycle: a _Hamilton cycle_ of \\(G\\). If \\(G\\) has a Hamilton cycle, it is called _hamiltonian_. Similarly, a path in \\(G\\) containing every vertex of \\(G\\) is a _Hamilton path_.\n\nTo determine whether or not a given graph has a Hamilton cycle is much harder than deciding whether it is Eulerian, and no good characterization is known1 of the graphs that do. In the first two sections of this chapter we present the standard sufficient conditions for the existence of a Hamilton cycle, as well as a more recent non-standard one. The third section is devoted to the proof of another classic: Fleischner's theorem that the'square' of every 2-connected graph has a Hamilton cycle. We shall present this theorem with an ingenious short proof due to Georgakopoulos.\n\nFootnote 1:...or indeed expected to exist; see the notes for details.\n\n### 10.1 Sufficient conditions\n\nWhat kind of condition might be sufficient for the existence of a Hamilton cycle in a graph \\(G\\)? Purely global assumptions, like high edge density, will not be enough: we cannot do without the local property that every vertex has at least two neighbours. But neither is any large (but constant) minimum degree sufficient: it is easy to find graphs without a Hamilton cycle whose minimum degree exceeds any given constant bound.\n\nThe following classic result derives its significance from this background:Theorem 10.1.1: (Dirac 1952) Every graph with \\(n\\geqslant 3\\) vertices and minimum degree at least \\(n/2\\) has a Hamilton cycle.\n\nProof: Let \\(G=(V,E)\\) be a graph with \\(|G|=n\\geqslant 3\\) and \\(\\delta(G)\\geqslant n/2\\). Then \\(G\\) is connected: otherwise, the degree of any vertex in the smallest component \\(C\\) of \\(G\\) would be less than \\(|C|\\leqslant n/2\\).\n\nLet \\(P=v_{0}\\ldots v_{k}\\) be a longest path in \\(G\\). Let us call \\(v_{i}\\) the _left_ end of the edge \\(v_{i}v_{i+1}\\), and \\(v_{i+1}\\) its _right_ end. By the maximality of \\(P\\), each of the \\(d(v_{0})\\geqslant n/2\\) neighbours of \\(v_{0}\\) is the right end of an edge of \\(P\\), and these \\(d(v_{0})\\) edges are distinct. Similarly, at least \\(n/2\\) edges of \\(P\\) are such that their left end is adjacent to \\(v_{k}\\). Since \\(P\\) has fewer than \\(n\\) edges, it has an edge \\(v_{i}v_{i+1}\\) with both properties (Fig. 10.1.1).\n\n\\(\\cdots\\)\\(v_{k}\\)\\(v_{0}\\)\\(P\\)\\(v_{i+1}\\)\\(v_{i+1}\\)\\(v_{k}\\)\\(v_{k}\\)\n\nWe claim that the cycle \\(C:=v_{0}v_{i+1}Pv_{k}v_{i}Pv_{0}\\) is a Hamilton cycle of \\(G\\). Indeed, since \\(G\\) is connected, \\(C\\) would otherwise have a neighbour in \\(G-C\\), which could be combined with a spanning path of \\(C\\) into a path longer than \\(P\\). \n\nTheorem 10.1.1 is best possible in that we cannot replace the bound of \\(n/2\\) with \\(\\lfloor n/2\\rfloor\\): if \\(n\\) is odd and \\(G\\) is the union of two copies of \\(K^{\\lceil n/2\\rceil}\\) meeting in one vertex, then \\(\\delta(G)=\\lfloor n/2\\rfloor\\) but \\(\\kappa(G)=1\\), so \\(G\\) cannot have a Hamilton cycle. In other words, the high level of the bound of \\(\\delta\\geqslant n/2\\) is needed to ensure, if nothing else, that \\(G\\) is \\(2\\)-connected: a condition just as trivially necessary for hamiltonicity as a minimum degree of at least \\(2\\). It would seem, therefore, that prescribing some high (constant) value for \\(\\kappa\\) rather than for \\(\\delta\\) stands a better chance of implying hamiltonicity. However, this is not so: although every large enough \\(k\\)-connected graph contains a cycle of length at least \\(2k\\) (Ex. 21, Ch. 3), the graphs \\(K_{k,n}\\) show that this is already best possible.\n\nSlightly more generally, a graph \\(G\\) with a separating set \\(S\\) of \\(k\\) vertices such that \\(G-S\\) has more than \\(k\\) components is clearly not hamiltonian. Could it be true that all non-hamiltonian graphs have such a separating set, one that leaves many components compared with its size? We shall return to this question at the end of this section.\n\nFor now, just note that such graphs as above also have relatively large independent sets: pick one vertex from each component of \\(G-S\\) to obtain one of order at least \\(k+1\\). Might we be able to force a Hamilton cycle by forbidding large independent sets?\n\nFigure 10.1.1: Finding a Hamilton cycle in the proof Theorem 10.1.1\n\nBy itself, the assumption of \\(\\alpha(G)\\leqslant k\\) already guarantees a cycle of length at least \\(|G|/k\\) (Ex. 13, Ch. 5). And combined with the assumption of \\(k\\)-connectedness, it does indeed imply hamiltonicity:\n\n**Proposition 10.1.2.** Every graph \\(G\\) with \\(|G|\\geqslant 3\\) and \\(\\alpha(G)\\leqslant\\kappa(G)\\) has a Hamilton cycle.\n\n_Proof._ Put \\(\\kappa(G)=:k\\), and let \\(C\\) be a longest cycle in \\(G\\). Enumerate the vertices of \\(C\\) cyclically, say as \\(V(C)=\\{\\,v_{i}\\mid i\\in\\mathbb{Z}_{n}\\,\\}\\) with \\(v_{i}v_{i+1}\\in E(C)\\) for all \\(i\\in\\mathbb{Z}_{n}\\). If \\(C\\) is not a Hamilton cycle, pick a vertex \\(u\\in G-C\\) and a \\(u\\)-\\(C\\) fan \\(\\mathcal{F}=\\{\\,P_{i}\\mid i\\in I\\,\\}\\) in \\(G\\), where \\(I\\subseteq\\mathbb{Z}_{n}\\) and each \\(P_{i}\\) ends in \\(v_{i}\\). Let \\(\\mathcal{F}\\) be chosen with maximum cardinality; then \\(uv_{j}\\notin E(G)\\) for any \\(j\\notin I\\), and\n\n\\[|\\mathcal{F}|\\geqslant\\min\\,\\{k,|C|\\} \\tag{1}\\]\n\nby Menger's theorem (3.3.4).\n\n_Fig. 10.1.2._ Two cycles longer than \\(C\\)\n\nFor every \\(i\\in I\\), we have \\(i+1\\notin I\\): otherwise, \\((C\\cup P_{i}uP_{i+1})-v_{i}v_{i+1}\\) would be a cycle longer than \\(C\\) (Fig. 10.1.2, left). Thus \\(|\\mathcal{F}|<|C|\\), and hence \\(|I|=|\\mathcal{F}|\\geqslant k\\) by (1). Furthermore, \\(v_{i+1}v_{j+1}\\notin E(G)\\) for all \\(i,j\\in I\\), as otherwise \\((C\\cup P_{i}uP_{j})+v_{i+1}v_{j+1}-v_{i}v_{i+1}-v_{j}v_{j+1}\\) would be a cycle longer than \\(C\\) (Fig. 10.1.2, right). Hence \\(\\{\\,v_{i+1}\\mid i\\in I\\,\\}\\cup\\{u\\}\\) is a set of \\(k+1\\) or more independent vertices in \\(G\\), contradicting \\(\\alpha(G)\\leqslant k\\). \\(\\square\\)\n\nOur next result uses the ideas from the proof of Proposition 10.1.2 to establish a local degree condition for hamiltonicity, considerably strengthening Dirac's theorem and several similar results proved later in its wake:\n\n**Theorem 10.1.3.** (Asratian & Khachatrian 1990)\n\nA connected graph \\(G\\) of order at least \\(3\\) is hamiltonian if\n\n\\[d(u)+d(w)\\geqslant|N(u)\\cup N(v)\\cup N(w)|\\]\n\nfor every induced path \\(uvw\\).", "(mmd) Noncommutative Algebra - Introduction to Noncommutative Algebra - Bresar.mmd-victoriacochran-victoria-p156-157-FacebookAI_roberta-base.json": "monomials could only be of degree \\(k\\), and therefore cannot involve more than \\(k\\) indeterminates. Hence \\(P=0\\). \n\nIn the characteristic zero case we can therefore express the \\(e_{k}\\)'s through the \\(p_{j}\\)'s. Say, from (6.7) we obtain\n\n\\[e_{1}=p_{1},\\ \\ e_{2}=\\frac{1}{2}\\big{(}p_{1}^{2}-p_{2}\\big{)},\\ \\ e_{3}=\\frac{1}{6} \\big{(}p_{1}^{3}-3p_{1}p_{2}+2p_{3}\\big{)}.\\]\n\nIn general, for each \\(k=1,\\ldots,n\\) there exists a polynomial \\(q_{k}=q_{k}(\\omega_{1},\\ldots,\\omega_{k})\\in\\mathbb{Q}[\\omega_{1},\\omega_{2},\\ldots]\\) such that\n\n\\[e_{k}=q_{k}(p_{1},\\ldots,p_{k}). \\tag{6.9}\\]\n\nFor our goals it is important to note that \\(q_{k}\\) has zero constant term. We also remark that if \\(\\lambda\\omega_{1}^{m_{1}}\\ldots\\omega_{k}^{m_{k}}\\), \\(\\lambda\\in\\mathbb{Q},m_{j}\\geq 0\\), is a monomial of \\(q_{k}\\), then \\(m_{1}+2m_{2}+\\cdots+km_{k}=k\\). For convenience we also set \\(q_{0}:=1\\), so that (6.9) holds for \\(k=0\\), \\(1\\), \\(\\ldots\\), \\(n\\).\n\n**Theorem 6.36**: _If \\(C\\) is a commutative \\(\\mathbb{Q}\\)-algebra, then for every \\(A\\in M_{n}(C)\\) we have_\n\n\\[p_{A}(\\omega)=\\sum_{j=0}^{n}(-1)^{j}q_{n-j}\\big{(}\\mathrm{tr}(A),\\,\\mathrm{tr} (A^{2}),\\,\\ldots,\\,\\mathrm{tr}(A^{n-j})\\big{)}\\omega^{\\,j}.\\]\n\n_Proof_ A standard reasoning shows that it suffices to consider the case where \\(A\\) is a generic matrix. Therefore we may assume that \\(C=\\mathbb{Q}[\\omega_{11},\\omega_{12}\\ldots,\\omega_{nn}]\\). In particular, \\(C\\) is thus a commutative domain and as such it can be embedded into a field (e.g., its field of quotients), which can be further embedded into an algebraically closed fields (e.g., its algebraic closure). But then there is no loss of generality in assuming that \\(C\\) itself is an algebraically closed field. Hence we have \\(p_{A}(\\omega)=(-1)^{n}(\\omega-\\lambda_{1})\\ldots(\\omega-\\lambda_{n})\\), where the \\(\\lambda_{i}\\)'s are the eigenvalues of \\(A\\). From the Jordan normal form of \\(A\\) it readily follows that \\(\\mathrm{tr}(A^{i})=p_{i}(\\lambda_{1},\\ldots,\\lambda_{n})\\), \\(i=1,\\ldots,n\\). Using (6.6) we now obtain\n\n\\[p_{A}(\\omega) =\\sum_{j=0}^{n}(-1)^{j}e_{n-j}(\\lambda_{1},\\ldots,\\lambda_{n}) \\omega^{\\,j}\\] \\[=\\sum_{j=0}^{n}(-1)^{j}q_{n-j}\\big{(}p_{1}(\\lambda_{1},\\ldots, \\lambda_{n}),\\ldots,p_{n-j}(\\lambda_{1},\\ldots,\\lambda_{n})\\big{)}\\omega^{\\,j}\\] \\[=\\sum_{j=0}^{n}(-1)^{j}q_{n-j}\\big{(}\\mathrm{tr}(A),\\ldots,\\, \\mathrm{tr}(A^{n-j})\\big{)}\\omega^{\\,j},\\]\n\nas desired.\n\nFor example, for \\(n=2\\) we have\n\n\\[p_{A}(\\omega)=\\omega^{2}-\\operatorname{tr}(A)\\omega+\\frac{1}{2}\\bigl{(} \\operatorname{tr}(A)^{2}-\\operatorname{tr}(A^{2})\\bigr{)} \\tag{6.10}\\]\n\n(and hence \\(\\det(A)=\\frac{1}{2}\\bigl{(}\\operatorname{tr}(A)^{2}-\\operatorname{tr}(A^{2}) \\bigr{)}\\) in this case). In general, the coefficient at \\(\\omega^{j}\\) is a \\(\\mathbb{Q}\\)-linear combination of expressions of the form\n\n\\[\\operatorname{tr}(A)^{m_{1}}\\operatorname{tr}\\bigl{(}A^{2}\\bigr{)}^{m_{2}} \\ldots\\operatorname{tr}\\bigl{(}A^{n-j}\\bigr{)}^{m_{n-j}}\\]\n\nwhere \\(m_{1}+2m_{2}+\\cdots+(n-j)m_{n-j}=n-j\\).\n\n**Corollary 6.37**: _Let \\(C\\) be a commutative \\(\\mathbb{Q}\\)-algebra. If \\(A\\in M_{n}(C)\\) is such that \\(\\operatorname{tr}(A)=\\operatorname{tr}(A^{2})=\\cdots=\\operatorname{tr}(A^{n} )=0\\), then \\(A^{n}=0\\)._\n\n_Proof_ Since the polynomials \\(q_{k}\\), \\(k=1,\\ldots,n\\), have zero constant terms, it follows that \\(p_{A}(\\omega)=(-1)^{n}\\omega^{n}\\). \\(\\square\\)\n\n### The Amitsur-Levitzki Theorem\n\nThe matrix algebra \\(M_{n}(F)\\) has dimension \\(n^{2}\\), and thus satisfies \\(s_{n^{2}+1}\\) (see Example 6.15). From (6.3) we therefore see that it also satisfies \\(s_{n^{2}+2}\\), \\(s_{n^{2}+3}\\), etc. But does it satisfy \\(s_{k}\\) with \\(k<n^{2}+1\\)? Moreover, what is the minimal degree of a nonzero identity of \\(M_{n}(F)\\)? We first approach these questions from the opposite direction.\n\n**Lemma 6.38**: _A nonzero polynomial of degree less than \\(2n\\) is not an identity of \\(M_{n}(F)\\)._\n\n_Proof_ By Theorem 6.24 it suffices to treat multilinear polynomials. Take a nonzero multilinear polynomial \\(f\\) of degree \\(2n-1\\). Thus, \\(f=\\sum_{\\sigma\\in S_{2n-1}}\\lambda_{\\sigma}\\xi_{\\sigma(1)}\\ldots\\xi_{\\sigma(2n- 1)}\\) with, say, \\(\\lambda_{1}\\neq 0\\). The sequence of matrix units \\(E_{11},E_{12},E_{22},\\ldots,E_{n-1,n},E_{nn}\\) has the property that their product in the given order is \\(E_{1n}\\), while the product in any other order is zero. Therefore \\(f(E_{11},E_{12},\\ldots,E_{nn})=\\lambda_{1}E_{1n}\\neq 0\\). Similarly, by taking an appropriate subsequence we see that a nonzero multilinear polynomial of degree less than \\(2n-1\\) is not an identity of \\(M_{n}(F)\\). \\(\\square\\)\n\nThus, the best we can hope for is that \\(M_{n}(F)\\) satisfies \\(s_{2n}\\)--and this is indeed the case! This was proved by S. A. Amitsur and J. Levitzki in 1950. The charming proof that we are about to give is due to S. Rosset.\n\n**Theorem 6.39**: (Amitsur-Levitzki) _The standard polynomial \\(s_{2n}\\) is an identity of \\(M_{n}(C)\\) for every commutative algebra \\(C\\)._\n\n_Proof_ By assumption, \\(C\\) is an algebra over some field \\(F\\). Let \\(F_{0}\\) be the prime subfield of \\(F\\), and consider \\(C\\) as an algebra over \\(F_{0}\\). Since \\(M_{n}(C)\\cong C\\otimes_{F_{0}}M_{n}(F_{0})\\) (Example 4.22), and since multilinear identities are stable (Lemma 6.27), it is enough to prove that \\(s_{2n}\\) is an identity of \\(M_{n}(F_{0})\\). Suppose this is true for \\(F_{0}=\\mathbb{Q}\\). Then \\(s_{2n}\\) is also an identity of \\(M_{n}(\\mathbb{Z})\\). But \\(M_{n}(\\mathbb{Z}_{p})\\) is a homomorphic image of \\(M_{n}(\\mathbb{Z})\\). Indeed, if \\(\\varphi\\) is the canonical homomorphism from \\(\\mathbb{Z}\\) onto \\(\\mathbb{Z}_{p}\\), then \\((m_{ij})\\mapsto\\bigl{(}\\varphi(m_{ij})\\bigr{)}\\) is a homomorphism from \\(M_{n}(\\mathbb{Z})\\) onto \\(M_{n}(\\mathbb{Z}_{p})\\). Therefore \\(s_{2n}\\) is also an identity of \\(M_{n}(\\mathbb{Z}_{p})\\). We have thus reduced the problem to proving that \\(s_{2n}\\) is an identity of \\(M_{n}(\\mathbb{Q})\\).\n\nTake \\(A_{1},\\ldots,A_{2n}\\in M_{n}(\\mathbb{Q})\\). We must show that \\(s_{2n}(A_{1},A_{2},\\ldots,A_{2n})=0\\). We will accomplish this with the help of the Grassmann algebra \\(G=G_{0}\\oplus G_{1}\\) over \\(\\mathbb{Q}\\) with generators \\(x_{1},x_{2},\\ldots\\) (see Example 6.7). For \\(B=(b_{ij})\\in M_{n}(\\mathbb{Q})\\) and \\(x\\in G\\) we define \\(Bx\\) to be the matrix \\((b_{ij}x)\\in M_{n}(G)\\). Note that the product \\((Bx)(B^{\\prime}x^{\\prime})\\) of two such matrices is equal to \\((BB^{\\prime})(xx^{\\prime})\\). Let us set\n\n\\[A:=A_{1}x_{1}+A_{2}x_{2}+\\cdots+A_{2n}x_{2n}\\in M_{n}(G).\\]\n\nFrom \\(x_{i}Gx_{i}=0\\) we easily infer that\n\n\\[A^{2n}=\\sum_{\\sigma\\in S_{2n}}A_{\\sigma(1)}A_{\\sigma(2)}\\ldots A_{\\sigma(2n)}x _{\\sigma(1)}x_{\\sigma(2)}\\ldots x_{\\sigma(2n)}.\\]\n\nRecall that \\(x_{\\sigma(1)}\\ldots x_{\\sigma(r)}=\\operatorname{sgn}(\\sigma)x_{1}\\ldots x_{r}\\) (see (6.4)). Consequently,\n\n\\[A^{2n}=s_{2n}(A_{1},A_{2},\\ldots,A_{2n})x_{1}x_{2}\\ldots x_{2n}.\\]\n\nHence we are reduced to proving that \\(A^{2n}=0\\), i.e., \\(\\bigl{(}A^{2}\\bigr{)}^{n}=0\\). Note that \\(A^{2}\\) lies in \\(M_{n}(G_{0})\\). As \\(G_{0}\\) is a commutative algebra, Corollary 6.37 tells us that it suffices to show that \\(\\bigl{(}A^{2}\\bigr{)}^{k}=A^{2k}\\) has zero trace for \\(k=1,\\ldots,n\\). To this end, notice that \\(A^{2k-1}=\\sum_{j}B_{j}y_{j}\\) for some \\(B_{j}\\in M_{n}(\\mathbb{Q})\\) and \\(y_{j}\\in G_{1}\\). Consequently,\n\n\\[\\operatorname{tr}\\bigl{(}A^{2k}\\bigr{)}=\\operatorname{tr}\\bigl{(}AA^{2k-1} \\bigr{)}=\\operatorname{tr}\\Bigl{(}\\sum_{i,j}A_{i}B_{j}x_{i}y_{j}\\Bigr{)}=\\sum _{i,j}\\operatorname{tr}\\bigl{(}A_{i}B_{j}\\bigr{)}x_{i}y_{j}.\\]\n\nOn the other hand,\n\n\\[\\operatorname{tr}\\bigl{(}A^{2k}\\bigr{)}=\\operatorname{tr}\\bigl{(}A^{2k-1}A \\bigr{)}=\\sum_{i,j}\\operatorname{tr}\\bigl{(}B_{j}A_{i}\\bigr{)}y_{j}x_{i}.\\]\n\nComparing both expressions and using \\(\\operatorname{tr}\\bigl{(}A_{i}B_{j}\\bigr{)}=\\operatorname{tr}\\bigl{(}B_{j}A_ {i}\\bigr{)}\\) (a general property of the trace) and \\(x_{i}y_{j}=-y_{j}x_{i}\\) (a consequence of \\(y_{j}\\in G_{1}\\)), we obtain \\(\\operatorname{tr}\\bigl{(}A^{2k}\\bigr{)}=0\\).", "(mmd) Probability Theory - Integration and Probability - Malliavin.mmd-nilay-Timothy-p32-33-FacebookAI_roberta-base.json": "**6.6.1 Proposition**.: _For every \\(f\\in\\mathcal{L}_{\\mu}^{\\infty,1}(X,\\mathcal{A})\\), there exist \\(\\varphi_{n}\\in\\mathcal{E}_{\\mu}^{1}(X,\\mathcal{A})\\) such that_\n\n1. \\(\\{\\varphi_{n}\\}\\) _converges uniformly to_ \\(f\\)_, and_\n2. \\(\\{x:\\varphi_{n}(x)\\neq 0\\}=\\{x:f(x)\\neq 0)\\}\\)_._\n\nProof.: Cf. Proposition 6.4.1. \\(\\Box\\)\n\n**6.6.2 Proposition**.: _If \\(\\{\\varphi_{n}\\}\\) satisfies 6.6.1, then \\(\\{I(\\varphi_{n})\\}\\) is a Cauchy sequence._\n\nProof.: Let \\(K=\\{x:f(x)\\neq 0)\\}\\). Then \\(\\varphi_{n}=\\varphi_{n}\\mathbf{1}_{K}\\) and\n\n\\[I(\\varphi_{n}-\\varphi_{m})=I((\\varphi_{n}-\\varphi_{m})\\mathbf{1}_{K})\\leq\\mu( K)\\sup|\\varphi_{n}-\\varphi_{m}|\\to 0\\]\n\nby the uniform convergence of \\(\\{\\varphi_{n}\\}\\). \\(\\Box\\)\n\n**6.6.3 Definition**.: \\(\\widetilde{I}(f)=\\lim I(\\varphi_{n})\\ \\forall f\\in\\mathcal{L}_{\\mu}^{\\infty,\\,1}\\), where \\(\\{\\varphi_{n}\\}\\) is the sequence of Proposition 6.6.1.\n\nThis is independent of the choice of sequence. Let \\(\\{\\varphi^{\\prime}_{n}\\}\\) be another sequence satisfying 6.6.1(i). Set\n\n\\[\\begin{array}{ll}\\varphi^{\\prime\\prime}_{m}&=\\varphi_{m/2}\\qquad\\quad\\text{ if $m$ is even, and}\\\\ \\varphi^{\\prime\\prime}_{m}&=\\varphi^{\\prime}_{(m-1)/2}\\qquad\\text{if $m$ is odd.}\\end{array}\\]\n\nThen \\(\\varphi^{\\prime\\prime}_{m}\\) satisfies 6.6.1(i) and hence \\(\\lim I(\\varphi^{\\prime\\prime}_{m})\\) exists. But this implies that \\(\\lim I(\\varphi_{n})=\\lim I(\\varphi^{\\prime}_{n})\\).\n\n**6.6.4 Proposition**.: _Let \\(f\\in\\mathcal{L}_{\\mu}^{\\infty,\\,1}\\). Then the following statements are true:_\n\n1. \\(\\widetilde{I}(f_{1}+f_{2})=\\widetilde{I}(f_{1})+\\widetilde{I}(f_{2})\\)_._\n2. \\(f_{1}\\geq f_{2}\\Rightarrow\\widetilde{I}(f_{1})\\geq\\widetilde{I}(f_{2})\\)_._\n3. \\(f_{1}=f_{2}\\) _a.e._ \\(\\Rightarrow\\widetilde{I}(f_{1})=\\widetilde{I}(f_{2})\\)_._\n\n### The truncation operator\n\nFor a fixed positive integer \\(n\\), let \\(\\varphi_{n}\\) be the continuous function defined on \\(\\mathbf{R}\\) by\n\n\\[\\begin{array}{ll}\\varphi_{n}(t)=t\\qquad\\text{if}\\quad-n\\leq t\\leq+n\\\\ \\varphi_{n}(t)=n\\qquad\\text{if}\\quad t>n\\\\ \\varphi_{n}(t)=-n\\quad\\text{if}\\quad t<-n.\\end{array}\\]\n\nLet \\(A_{1}\\subset A_{2}\\ldots\\subset A_{n}\\ldots\\) be an exhaustion of \\(X\\), i.e. \\(\\mu(A_{k})<+\\infty\\ \\forall k\\) and \\(X=\\cup_{k}A_{k}\\).\n\nWe define \\(T_{n}\\), the truncation operator of order \\(n\\) on \\(\\mathcal{L}^{0}(X,\\mathcal{A})\\), as follows:\n\n\\[T_{n}(f)=f_{n}\\mathbf{1}_{A_{n}},\\quad\\text{where}\\quad f_{n}=\\varphi_{n} \\circ f.\\]\\(f_{n}\\) is bounded and (since \\(\\varphi_{n}\\) is continuous) measurable. Furthermore, since the set \\(\\{x:(T_{n}f)(x)\\neq 0\\}\\subset A_{n}\\), it has finite measure. Hence, by the definition of \\(\\mathcal{L}_{\\mu}^{\\infty,1}\\),\n\n\\[T_{n}(f)\\in\\mathcal{L}_{\\mu}^{\\infty,1}(X,\\mathcal{A})\\quad\\text{for any}\\quad f \\in\\mathcal{L}^{0}(X,\\mathcal{A}).\\]\n\n### Construction of \\(L^{1}\\)\n\n#### 6.8.1 Definition of \\(L^{1}_{\\mu}(X,\\mathcal{A})\\)\n\n(i) **Definition.**\\(\\mathcal{L}^{1}_{\\mu}(X,\\mathcal{A})=\\{f\\in\\mathcal{L}^{0}(X,\\mathcal{A}):\\lim_ {n\\to\\infty}\\widetilde{I}(|T_{n}(f)|)<+\\infty\\}\\).\n\n**Proposition.**_If \\(f_{1}\\in\\mathcal{L}^{1}_{\\mu}\\) and \\(f_{2}=f_{1}\\) a.e., then \\(f_{2}\\in\\mathcal{L}^{1}_{\\mu}(X,\\mathcal{A})\\). This justifies the notation_\n\n\\[L^{1}_{\\mu}(X,\\mathcal{A})=\\{\\text{equivalence classes of }\\mathcal{L}^{1}_{\\mu} (X,\\mathcal{A})\\}.\\]\n\n* \\(\\|f\\|_{L^{1}}=\\lim\\widetilde{I}(|T_{n}(f)|)\\)_._\n* _If_ \\(f\\in L^{0}_{\\mu}\\) _and_ \\(|f|\\leq|h|\\)_, where_ \\(h\\in L^{1}_{\\mu}\\)_, then_ \\(f\\in L^{1}_{\\mu}\\)_._\n* _If_ \\(f\\in\\mathcal{L}^{\\infty,1}_{\\mu}(X,\\mathcal{A})\\)_, then_ \\(f\\in\\mathcal{L}^{1}_{\\mu}(X,\\mathcal{A})\\)_._\n\n#### 6.8.2 Proposition.\n\n_If \\(f\\in L^{1}_{\\mu}\\), then \\(\\lim_{n\\to\\infty}\\tilde{I}(T_{n}(f))\\) exists._\n\nProof. Let \\(f^{+}=\\sup(f,0)\\) and let \\(f^{-}=\\sup(-f,0)\\). Although \\(T_{n}\\) is not a linear operator, it is elementary to verify that, for all \\(x\\in X\\),\n\n\\[T_{n}(f)(x)=T_{n}(f^{+})(x)-T_{n}(f^{-})(x)\\]\n\nand\n\n\\[|T_{n}(f)|=T_{n}(f^{+})+T_{n}(f^{-}),\\]\n\nwhence\n\n\\[\\widetilde{I}(T_{n}(f^{+}))\\leq\\widetilde{I}(|T_{n}(f)|)\\leq\\|f\\|_{L^{1}}.\\]\n\n\\(\\{\\widetilde{I}(T_{n}(f^{+}))\\}\\) is thus an increasing sequence which is bounded above, and therefore converges. \\(\\Box\\)\n\n**Definition.** For \\(f\\in L^{1}_{\\mu}\\), the integral of \\(f\\) is defined by \\(\\int f=\\lim\\tilde{I}(T_{n}(f))\\).\n\n#### 6.8.3 Proposition.\n\n\\(L^{1}_{\\mu}\\) _is a vector space with the following properties:_\n\n* \\(\\int(f_{1}+f_{2})=\\int f_{1}+\\int f_{2}\\)_._\n* _If_ \\(f\\geq 0\\)_, then_ \\(\\int f\\geq 0\\)_._\n\n_Set \\(\\|f\\|_{L^{1}}=\\int|f|\\). Then_\n\n* \\(|\\int f|\\leq\\|f\\|_{L^{1}}\\)_._\n* \\(\\mu(\\{x:f(x)>c\\})\\leq\\frac{1}{c}\\|f\\|_{L^{1}}\\)_._\n* \\(\\|f\\|_{L^{1}}\\) _is a norm._\n\nProof. The statements clearly hold for \\(\\mathcal{L}^{\\infty,1}_{\\mu}\\) and pass to \\(L^{1}_{\\mu}\\). \\(\\Box\\)", "(mmd) All the Mathematics You Missed - Garrity.mmd-nilay-hafsah-p35-36-FacebookAI_roberta-base.json": "### 2.6 Pointwise Convergence of Functions\n\n**Definition 2.6.1**: _Let \\(f_{n}:[a,b]\\rightarrow\\mathbf{R}\\) be a sequence of functions_\n\n\\[f_{1}(x),f_{2}(x),f_{3}(x),...\\]\n\n_defined on an interval \\([a,b]=\\{x:a\\leq x\\leq b\\}\\). This sequence \\(\\{f_{n}(x)\\}\\) will converge pointwise to a function_\n\n\\[f(x):[a,b]\\rightarrow\\mathbf{R}\\]\n\n_if for all \\(\\alpha\\) in \\([a,b]\\),_\n\n\\[\\lim_{n\\rightarrow\\infty}f_{n}(\\alpha)=f(\\alpha).\\]\n\nIn \\(\\epsilon\\) and \\(\\delta\\) notation, we would say that \\(\\{f_{n}(x)\\}\\)_converges pointwise_ to \\(f(x)\\) if for all \\(\\alpha\\) in \\([a,b]\\) and given any \\(\\epsilon>0\\), there is a positive integer \\(N\\) such that for all \\(n\\geq N\\), we have \\(|f(\\alpha)-f_{n}(\\alpha)|<\\epsilon\\).\n\nIntuitively, a sequence of functions \\(f_{n}(x)\\) will converge pointwise to a function \\(f(x)\\) if, given any \\(\\alpha\\), eventually (for huge \\(n\\)) the numbers \\(f_{n}(\\alpha)\\) become arbitrarily close to the number \\(f(\\alpha)\\). The importance of a good notion for convergence of functions stems from the frequent practice of only approximately solving a problem and then using the approximation to understand the true solution. Unfortunately, pointwise convergence is not as useful or as powerful as the next section's topic, uniform convergence, in that the pointwise limit of reasonable functions (e.g., continuous or integrable functions) does not guarantee the reasonableness of the limit, as we will see in the next example.\n\nHere we show that the pointwise limit of continuous functions need not be continuous. For each positive integer \\(n\\), set\n\n\\[f_{n}(x)=x^{n}\\]\n\nfor all \\(x\\) on \\([0,1]\\).\n\n\\[f(x)=\\left\\{\\begin{array}{ll}1,&x=1\\\\ 0,&0\\leq x<1\\end{array}\\right.\\]\n\nClearly \\(f(x)\\) is not continuous at the endpoint \\(x=1\\) while all of the functions \\(f_{n}(x)=x^{n}\\) are continuous on the entire interval. But we will see that the sequence \\(\\{f_{n}(x)\\}\\) does indeed converge pointwise to \\(f(x)\\).\n\nFix \\(\\alpha\\) in \\([0,1]\\). If \\(\\alpha=1\\), then \\(f_{n}(1)=1^{n}=1\\) for all \\(n\\). Then\n\n\\[\\lim_{x\\to\\infty}f_{n}(1)=\\lim_{n\\to\\infty}1=1=f(1).\\]\n\nNow let \\(0\\leq\\alpha<1\\). We will use (without proving) the fact that for any number \\(\\alpha\\) less than \\(1\\), the limit of \\(\\alpha^{n}\\) will approach \\(0\\) as \\(n\\) approaches \\(\\infty\\). In particular,\n\n\\[\\lim_{n\\to\\infty}f_{n}(\\alpha) = \\lim_{n\\to\\infty}\\alpha^{n}\\] \\[= 0\\] \\[= f(\\alpha).\\]\n\nThus the pointwise limit of a sequence of continuous functions need not be continuous.\n\n### 2.7 Uniform Convergence\n\n**Definition 2.7.1**: _A sequence of functions \\(f_{n}:[a,b]\\to{\\bf R}\\) will converge uniformly to a function \\(f:[a,b]\\to{\\bf R}\\) if given any \\(\\epsilon>0\\), there is a positive integer \\(N\\) such that for all \\(n\\geq N\\), we have_\n\n\\[|f(x)-f_{n}(x)|<\\epsilon\\]\n\n_for all points \\(x\\)._\n\nThe intuition is that if we put an \\(\\epsilon\\)-tube around the function \\(y=f(x)\\), the functions \\(y=f_{n}(x)\\) will eventually fit inside this band.\n", "(mmd) All the Mathematics You Missed - Garrity.mmd-nilay-hafsah-p149-FacebookAI_roberta-base.json": "**Definition 7.2.1**: _For a space curve parametrized by arc length_\n\n\\[r(s)=(x(s),y(s),z(s)),\\]\n\n_define the principal curvature \\(\\kappa\\) at a point to be the length of the derivative of the tangent vector with respect to the parameter \\(s\\), i.e.,_\n\n\\[\\kappa=\\left|\\frac{\\mathrm{d}\\mathbf{T}(s)}{\\mathrm{d}s}\\right|.\\]\n\nThe number \\(\\kappa\\) is one of the numbers that captures curvature. Another is the torsion, but before giving its definition we need to do some preliminary work.\n\nSet\n\n\\[\\mathbf{N}=\\frac{1}{\\kappa}\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}.\\]\n\nThe vector \\(\\mathbf{N}\\) is called the _principal normal vector_. Note that it has length one. More importantly, as the following proposition shows, this vector is perpendicular to the tangent vector \\(\\mathbf{T}(s)\\).\n\n**Proposition 7.2.1**: \\[\\mathbf{N}\\cdot\\mathbf{T}=0\\]\n\n_at all points on the space curve._\n\n**Proof:** Since we are using the arc length parametrization, the length of the tangent vector is always one, which means\n\n\\[\\mathbf{T}\\cdot\\mathbf{T}=1.\\]\n\nThus\n\n\\[\\frac{\\mathrm{d}}{\\mathrm{d}s}(\\mathbf{T}\\cdot\\mathbf{T})=\\frac{\\mathrm{d}}{ \\mathrm{d}s}(1)=0.\\]\n\nBy the product rule we have\n\n\\[\\frac{\\mathrm{d}}{\\mathrm{d}s}(\\mathbf{T}\\cdot\\mathbf{T})=\\mathbf{T}\\cdot \\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}+\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d }s}\\cdot\\mathbf{T}=2\\mathbf{T}\\cdot\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}.\\]\n\nThen\n\n\\[\\mathbf{T}\\cdot\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}=0.\\]\n\nThus the vectors \\(\\mathbf{T}\\) and \\(\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}\\) are perpendicular. Since the principal normal vector \\(\\mathbf{N}\\) is a scalar multiple of the vector \\(\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}s}\\), we have our result. \\(\\Box\\)\n\nSet\n\n\\[\\mathbf{B}=\\mathbf{T}\\times\\mathbf{N},\\]", "(mmd) Model Theory - Model Theory An Introduction - Marker.mmd-nilay-timothy-p261-262-FacebookAI_roberta-base.json": "### 7.3 The Indecomposability Theorem\n\nIn this section, we prove a theorem of Zil'ber's that is an important tool for studying groups of finite Morley rank. It again generalizes a result from algebraic group theory (see [14] I.2.2).\n\n**Definition 7.3.1**: We say that a definable \\(X\\subseteq G\\) is _indecomposable_ if and only if whenever \\(H\\) is a definable subgroup of \\(G\\) the coset space \\(X/H=\\{xH:x\\in X\\}\\) is either infinite or contains a unique element.\n\nIndecomposable sets play the role of irreducible subvarieties in arbitrary finite Morley rank groups (see Exercise 7.6.13). For example, if \\(X\\leq G\\) is an infinite connected definable subgroup, then \\(X\\) is indecomposable. If \\(H\\leq G\\) is a definable group and \\(a,b\\in X\\), then \\(aH=bH\\) if and only if \\(b\\in a(X\\cap H)\\). Thus, the number of cosets in \\(X/H\\) is equal to the index \\([X:X\\cap H]\\). Because \\(X\\) is connected, this is either one or infinite.\n\n**Theorem 7.3.2** (Zil'ber's Indecomposability Theorem): _Let \\(G\\) be a group of finite Morley rank and \\((X_{i}:i\\in I)\\) a collection of definable indecomposable subsets of \\(G\\) each containing 1. Then, the subgroup of \\(G\\) generated by \\(\\bigcup_{i\\in I}X_{i}\\) is definable and connected._\n\n**Proof** For each \\(\\sigma=(i_{1},\\ldots,i_{n})\\in I^{<\\omega}\\), let \\(X^{\\sigma}=\\{x_{1}\\cdots x_{n}:x_{1}\\in X_{i_{1}},\\ldots,x_{n}\\in X_{i_{n}}\\}\\). Because \\(\\operatorname{RM}(G)\\) is finite, there is a \\(\\sigma\\) such that \\(\\operatorname{RM}(X^{\\sigma})=k\\) is maximal. Let \\(p\\in S_{1}(G)\\) be a type of Morley rank \\(k\\) containing the formula \\(v\\in X^{\\sigma}\\). Let \\(H=\\operatorname{Stab}(p)\\).\n\n**Claim** Each \\(X_{i}\\subseteq H\\).\n\nIf not, then \\(|X_{i}/H|>1\\) as \\(1\\in X_{i}\\cap H\\) and \\(X_{i}\\not\\subseteq H\\). Because \\(X_{i}\\) is indecomposable, there are \\(a_{1},a_{2},\\ldots\\) in \\(X_{i}\\) such that \\(a_{n}H\\neq a_{m}H\\) for \\(n\\neq m\\). Because \\(a_{m}^{-1}a_{n}\\not\\in H=\\operatorname{Stab}(p)\\), \\(a_{n}p\\neq a_{m}p\\) for \\(n\\neq m\\). Thus, \\(a_{1}p,a_{2}p,\\ldots\\) are infinitely many distinct types of rank \\(k\\). But each of these types contains the formula \\(v\\in X_{i}\\cdot X^{\\sigma}\\). Thus, \\(X^{i}\\cdot X^{\\sigma}\\) has rank at least \\(k+1\\), contradicting our choice of \\(\\sigma\\).\n\nThus, the group generated by \\(\\bigcup_{i\\in I}X_{i}\\) is contained in \\(H\\).\n\nBecause \\(H=\\operatorname{Stab}(p)\\), by Lemma 7.1.11, \\(\\operatorname{RM}(H)\\leq\\operatorname{RM}(p)=\\operatorname{RM}(X^{\\sigma})\\leq \\operatorname{RM}(H)\\). Thus, \\(p\\in H\\) and \\(\\operatorname{RM}(p)=\\operatorname{RM}(H)\\), so \\(p\\) is a generic type of \\(H\\). Because any \\(\\omega\\)-stable group acts transitively on its generic types (see Exercise 7.6.9) and \\(H=\\operatorname{Stab}(p)\\) fixes \\(p\\), \\(H\\) is connected. Because \\(X^{\\sigma}\\subseteq H\\) is generic, by Lemma 7.2.7, \\(H=X^{\\sigma}\\cdot X^{\\sigma}\\). Thus, \\(H\\) is contained in the group generated by \\(\\bigcup_{i\\in I}X_{i}\\).\n\nWe have shown that \\(H\\) is the group generated by \\(\\bigcup_{i\\in I}X_{i}\\) and \\(H\\) is connected.\n\nThe proof of the Indecomposability Theorem shows a bit more. Namely, there are \\(i_{1},\\ldots,i_{m}\\in I\\) such that \\(H=X_{i_{1}}\\cdots X_{i_{m}}\\). If we start with a single indecomposable set \\(X\\), and \\(H\\) is the group generated by \\(X\\), then there is a number \\(m\\) such that every element of \\(H\\) is a product of \\(m\\) elements of \\(X\\)Let \\(\\Gamma\\) be a group and \\(S\\) a set. An _action_ of \\(\\Gamma\\) on \\(S\\) is a map \\(\\alpha:\\Gamma\\times S\\to S\\) such that \\(\\alpha(1,s)=s\\) for all \\(s\\in S\\) and \\(\\alpha(\\gamma,\\alpha(\\mu,s))=\\alpha(\\gamma\\mu,s)\\) for all \\(\\gamma,\\mu\\in\\Gamma\\) and \\(s\\in S\\). When no confusion arises, we write \\(\\gamma s\\) for \\(\\alpha(\\gamma,s)\\). We say that \\(X\\subseteq S\\) is \\(\\Gamma\\)_-invariant_ if \\(\\gamma X=X\\) for all \\(\\gamma\\in\\Gamma\\). We say that \\(\\Gamma\\) acts _transitively_ on \\(X\\subseteq S\\) if for all \\(x,y\\in X\\) there is \\(\\gamma\\in\\Gamma\\) such that \\(\\gamma x=y\\). If \\(G\\) is a group, we say that \\(\\alpha:\\Gamma\\times G\\to G\\) is the action of a group of automorphisms, if for each \\(\\gamma\\in\\Gamma\\), the function \\(g\\mapsto\\alpha(\\gamma,g)\\) is a group automorphism.\n\nWe say that the action is \\(\\omega\\)-stable if \\((\\Gamma,\\cdot,S,\\alpha)\\) is interpretable in an \\(\\omega\\)-stable structure. Similarly, we say that the action has finite Morley rank if \\((\\Gamma,\\cdot,S,\\alpha)\\) is interpretable in a finite Morley rank structure.\n\nFor example, if \\(G\\) is a group, \\(G\\) acts on itself by conjugation \\(\\alpha(h,g)=hgh^{-1}\\). If \\(K\\) is a field, then \\(K^{\\times}\\) acts on \\((K,+)\\) by \\(\\alpha(a,x)=ax\\). If \\(G\\) and \\(K\\) are \\(\\omega\\)-stable (finite Morley rank), then these actions are also \\(\\omega\\)-stable (finite Morley rank).\n\nThe next lemma shows that to test the indecomposability of a \\(\\Gamma\\)-invariant \\(X\\) we need only show that it is indecomposable by \\(\\Gamma\\)-invariant definable subgroups.\n\n**Lemma 7.3.3**: _Suppose that there is an \\(\\omega\\)-stable action of \\(\\Gamma\\) on a group \\(G\\) as a group of automorphisms, \\(X\\subseteq G\\) is \\(\\Gamma\\)-invariant, and for all definable \\(\\Gamma\\)-invariant subgroups \\(H\\) of \\(G\\) either \\(|X/H|=1\\) or \\(X/H\\) is infinite. Then, \\(X\\) is indecomposable._\n\n**Proof** Suppose that \\(H\\) is a definable subgroup of \\(G\\) and \\(1<|X/H|<\\aleph_{0}\\). Suppose that \\(X\\subseteq x_{1}H\\cup\\ldots\\cup x_{n}H\\). If \\(\\gamma\\in\\Gamma\\) and \\(x\\in X\\), then \\(\\gamma^{-1}x\\in X\\). Thus, \\(\\gamma^{-1}x=x_{i}h\\) for some \\(h\\in H\\) and \\(x=(\\gamma x_{i})(\\gamma h)\\). Thus \\(X\\subseteq(\\gamma x_{1})(\\gamma H)\\cup\\ldots\\cup(\\gamma x_{n})(\\gamma H)\\). In particular, \\(X/\\gamma H\\) is finite.\n\nLet \\(H^{*}=\\bigcap_{\\gamma\\in\\Gamma}\\gamma H\\). By the Descending Chain Condition there are \\(\\gamma_{1},\\ldots,\\gamma_{m}\\in\\Gamma\\) such that \\(H^{*}=\\gamma_{1}H\\cap\\ldots\\cap\\gamma_{m}H\\). Because \\(X\\) is \\(\\Gamma\\)-invariant, \\(X/\\gamma_{i}H\\) is finite for each \\(i\\) and \\(X/H^{*}\\) is finite. Thus \\(1<|X/H^{*}|<\\aleph_{0}\\). But \\(H^{*}\\) is \\(\\Gamma\\)-invariant, a contradiction.\n\nIf \\(g,h\\in G\\) we let \\(g^{h}\\) denote \\(hgh^{-1}\\). If \\(H\\leq G\\), we let \\(g^{H}=\\{g^{h}:h\\in H\\}\\).\n\n**Corollary 7.3.4**: _Suppose that \\(G\\) is an \\(\\omega\\)-stable group. If \\(H\\) is a definable connected subgroup of \\(G\\) and \\(g\\in G\\), then \\(g^{H}\\) is indecomposable._\n\n**Proof** The group \\(H\\) acts on \\(G\\) via conjugation, and \\(g^{H}\\) is invariant under this action. Thus, by the preceding lemma, it suffices to show that \\(g^{H}\\) is indecomposable for definable \\(N\\leq G\\) where \\(hNh^{-1}=N\\) for all \\(h\\in H\\). Suppose that \\(g^{H}/N\\) is finite and \\(m\\) is minimal such that \\(g^{H}\\subseteq a_{1}N\\cup a_{2}N\\cup\\ldots\\cup a_{m}N\\) for some \\(a_{1},\\ldots,a_{m}\\in g^{H}\\). If \\(h\\in H\\), then \\(ha^{H}h^{-1}=a^{H}\\) and \\(h(a_{i}N)h^{-1}=a^{h}_{i}(hNh^{-1})=a^{h}_{i}N\\). Thus, for each \\(i\\) there is a unique \\(j\\) such that \\(a^{h}_{i}N=a_{j}N\\). This gives a definable transitive action of \\(H\\) on the finite set \\(\\{a_{1},\\ldots,a_{m}\\}\\). By Exercise 7.6.11, \\(m=1\\) as desired. Thus, \\(g^{H}\\) is indecomposable.", "(mmd) Graph Theory - Graph Theory - Diestel.mmd-nilay-noah-p384-385-FacebookAI_roberta-base.json": "Recall that two separations \\(\\{U_{1},U_{2}\\}\\) and \\(\\{W_{1},W_{2}\\}\\) of \\(G\\) are _nested_ if we can choose \\(i,j\\in\\{1,2\\}\\) so that \\(U_{i}\\subseteq W_{j}\\) and \\(U_{3-i}\\supseteq W_{3-j}\\). 1. Show that the separations \\(S_{e}:=\\{U_{1},U_{2}\\}\\) in Lemma 12.3.1 are pairwise nested (for different choices of the edge \\(e=t_{1}t_{2}\\in T\\)). 2. Conversely, show that given a set \\(\\mathcal{S}\\) of nested separations of \\(G\\) there is a tree-decomposition \\((\\mathcal{V},T)\\) of \\(G\\) such that \\(\\mathcal{S}=\\{\\,S_{e}\\mid e\\in E(T)\\,\\}\\).\n17. Prove Theorem 12.3.7 for \\(k=3\\). Specifically, prove Tutte's theorem that every 2-connected graph has a tree-decomposition of adhesion 2 whose torsos are each either 3-connected or a cycle. Conversely, show that every graph with such a tree-decomposition is 2-connected. (Hint. Try the tree-decomposition defined, as in Exercise 16 (ii), by the set of all separations of order 2 that are nested with all other such separations.)\n18. Describe the tree-decomposition of a contraction minor \\(H\\) of \\(G\\) which a given tree-decomposition of \\(G\\) induces as in Lemma 12.3.3, in terms subtrees of \\(T\\) (as in Exercise 12).\n19. Show that any graph with a simplicial tree-decomposition into \\(k\\)-colourable parts is itself \\(k\\)-colourable.\n20. Let \\(\\mathcal{H}\\) be a set of graphs, and let \\(G\\) be constructed recursively from elements of \\(\\mathcal{H}\\) by pasting along complete subgraphs. Show that \\(G\\) has a simplicial tree-decomposition into elements of \\(\\mathcal{H}\\).\n21. Use the previous exercise to show that \\(G\\) has no \\(K^{5}\\) minor if and only if \\(G\\) has a tree-decomposition in which every torso is either planar or a copy of the Wagner graph \\(W\\) (Figure 7.3.1).\n22. Call a graph _irreducible_ if it is not separated by any complete subgraph. Every finite graph \\(G\\) can be decomposed into irreducible induced subgraphs, as follows. If \\(G\\) has a separating complete subgraph \\(S\\), then decompose \\(G\\) into proper induced subgraphs \\(G^{\\prime}\\) and \\(G^{\\prime\\prime}\\) with \\(G=G^{\\prime}\\cup G^{\\prime\\prime}\\) and \\(G^{\\prime}\\cap G^{\\prime\\prime}=S\\). Then decompose \\(G^{\\prime}\\) and \\(G^{\\prime\\prime}\\) in the same way, and so on, until all the graphs obtained are irreducible. By Exercise 20, \\(G\\) has a simplicial tree-decomposition into these irreducible subgraphs. Show that they are uniquely determined if the complete separators were all chosen minimal.\n23. If \\(\\mathcal{F}\\) is a family of sets, then the graph \\(G\\) on \\(\\mathcal{F}\\) with \\(XY\\in E(G)\\Leftrightarrow X\\cap Y\\neq\\emptyset\\) is called the _intersection graph_ of \\(\\mathcal{F}\\). Show that a graph is chordal if and only if it is isomorphic to the intersection graph of a family of (vertex sets of) subtrees of a tree.\n24. Show that for \\(n\\geqslant 3\\) the graphs \\(K^{n}\\), \\(C^{n}\\), an arbitrary tree of order \\(n\\), and the \\(n\\times n\\) grid have tree-decompositions of widths \\(n-1\\), \\(2\\), \\(1\\), and \\(n\\), respectively. For \\(K^{n}\\) and \\(C^{n}\\) show that these values are best possible.\n25. Can the tree-width of a subdivision of a graph \\(G\\) be smaller than \\(\\operatorname{tw}(G)\\)? Can it be larger?Show that the tree-width of a finite graph is at least its minimum degree. Is this still true for infinite graphs?\n* Show that if a graph has circumference \\(k\\neq 0\\), then its tree-width is at most \\(k-1\\).\n* A graph is called _outerplanar_ if it has a drawing in which every vertex lies on the boundary of the outer face. Show that outerplanar graphs can have arbitrarily large tree-width, or find the best upper bound.\n\nA tree-decomposition whose tree is a path is a _path-decomposition_. The _path-width_\\(\\operatorname{pw}(G)\\) of \\(G\\) is the least width of a path-decomposition of \\(G\\).\n\n* Show that a graph has a path-decomposition into complete graphs if and only if it is isomorphic to an interval graph. (Interval graphs are defined in Exercise 42, Chapter 5.)\n* (continued) Prove the following analogue of Proposition 12.4.4 for path-width: every graph \\(G\\) satisfies \\(\\operatorname{pw}(G)=\\min\\,\\omega(H)-1\\), where the minimum is taken over all interval graphs \\(H\\) containing \\(G\\).\n* Do trees have unbounded path-width?\n\nA _transaction_ of a sequence \\((v_{1},\\ldots,v_{n})\\) of vertices is a set of disjoint paths from an initial segment \\(\\{v_{1},\\ldots,v_{i}\\}\\) to the rest, \\(\\{v_{i+1},\\ldots,v_{n}\\}\\).\n\n* Given \\(k\\in\\mathbb{N}\\) and a sequence \\(v_{1},\\ldots,v_{n}\\) of vertices in a graph \\(G\\), show that \\(G\\) has a path-decomposition \\((V_{1},\\ldots,V_{n})\\) of adhesion \\(\\leqslant k\\), with \\(v_{i}\\in V_{i}\\) for all \\(i\\), if and only if \\(G\\) contains no transaction \\(\\mathcal{P}\\) of \\((v_{1},\\ldots,v_{n})\\) of order \\(|\\mathcal{P}|>k\\).\n* Show that the cycle \\(C^{n}\\) has connected tree-width \\(\\lceil n/2\\rceil\\).\n* Show that the \\(n\\times n\\) grid has tree-width \\(n\\).\n* Let \\(\\mathcal{B}\\) be a maximum-order bramble in a graph \\(G\\). Show that every minimum-width tree-decomposition of \\(G\\) has a unique part covering \\(\\mathcal{B}\\).\n* Let \\(\\mathcal{P}\\) be a minor-closed graph property. Show that strengthening the notion of a minor (for example, to that of topological minor) increases the set of forbidden minors required to characterize \\(\\mathcal{P}\\).\n* Deduce from the graph minor theorem that every minor-closed property can be expressed by forbidding finitely many topological minors. Is the same true for every property that is closed under taking topological minors?\n\nCall a set \\(X\\subseteq V(G)\\) of vertices \\(k\\)_-connected in \\(G\\)_ if \\(|X|\\geqslant k\\) and for all subsets \\(Y,Z\\subseteq X\\) with \\(|Y|=|Z|\\leqslant k\\) there are \\(|Y|\\) disjoint \\(Y\\)-\\(Z\\) paths in \\(G\\).\n\n* Show that the tree-width of a graph \\(G\\) is large if and only if it contains a large set of vertices that is \\(k\\)-connected in \\(G\\) for some large \\(k\\). For example, show that graphs of tree-width \\(<k\\) contain no \\((k+1)\\)-connected set of \\(3k\\) vertices, and that graphs containing no \\((k+1)\\)-connected set of \\(3k\\) vertices have tree-width \\(<4k\\).", "(mmd) Model Theory - Model Theory An Introduction - Marker.mmd-nilay-timothy-p218-220-FacebookAI_roberta-base.json": "**Definition 6.2.5**: If \\({\\cal M}\\) is an \\({\\cal L}\\)-structure and \\(\\phi\\) is any \\({\\cal L}\\)-formula, we define \\({\\rm RM}(\\phi)\\), the _Morley rank_ of \\(\\phi\\), to be \\({\\rm RM}^{\\cal N}(\\phi)\\), where \\({\\cal N}\\) is any \\(\\aleph_{0}\\)-saturated elementary extension of \\({\\cal M}\\).\n\nMorley rank gives us our desired notion of \"dimension\" for definable sets.\n\n**Definition 6.2.6**: Suppose that \\({\\cal M}\\models T\\) and \\(X\\subseteq M^{n}\\) is defined by the \\({\\cal L}_{M}\\)-formula \\(\\phi(\\overline{v})\\). We let \\({\\rm RM}(X)\\), the _Morley rank_ of \\(X\\), be \\({\\rm RM}(\\phi)\\).\n\nIn particular, if \\({\\cal M}\\) is \\(\\aleph_{0}\\)-saturated and \\(X\\subseteq M^{n}\\) is definable, then \\({\\rm RM}(X)\\geq\\alpha+1\\) if and only if we can find \\(Y_{1},Y_{2},\\ldots\\) pairwise disjoint definable subsets of \\(X\\) of Morley rank at least \\(\\alpha\\).\n\nThe next lemma shows that Morley rank has some basic properties that we would want for a good notion of dimension.\n\n**Lemma 6.2.7**: _Let \\({\\cal M}\\) be an \\({\\cal L}\\)-structure and let \\(X\\) and \\(Y\\) be definable subsets of \\(M^{n}\\)._\n\n_i) If \\(X\\subseteq Y\\), then \\({\\rm RM}(X)\\leq{\\rm RM}(Y)\\)._\n\n_ii) \\({\\rm RM}(X\\cup Y)\\) is the maximum of \\({\\rm RM}(X)\\) and \\({\\rm RM}(Y)\\)._\n\n_iii) If \\(X\\) is nonempty, then \\({\\rm RM}(X)=0\\) if and only if \\(X\\) is finite._\n\n**Proof** We leave the proofs of i) and ii) as exercises.\n\niii) Let \\(X=\\phi({\\cal M})\\). Because \\(X\\) is nonempty, \\({\\rm RM}(\\phi)\\geq 0\\). Because \\(\\phi({\\cal M})\\) is finite if and only if \\(\\phi({\\cal N})\\) is finite for any \\({\\cal M}\\prec{\\cal N}\\), we may, without loss of generality, assume that \\({\\cal M}\\) is \\(\\aleph_{0}\\)-saturated. If \\(X\\) is finite, then, because \\(X\\) cannot be partitioned into infinitely many nonempty sets, \\({\\rm RM}(X)\\ngeq 1\\). Thus \\({\\rm RM}(X)=0\\). If \\(X\\) is infinite, let \\(a_{1},a_{2},\\ldots\\) be distinct elements of \\(X\\). Then, \\(\\{a_{1}\\},\\{a_{2}\\},\\ldots\\) is an infinite sequence of pairwise disjoint definable subsets of \\(X\\). Thus \\({\\rm RM}(X)\\geq 1\\).\n\nWe will be interested in theories where every formula is ranked.\n\n**Definition 6.2.8**: A theory \\(T\\) is called _totally transcendental_ if, for all \\({\\cal M}\\models T\\), if \\(\\phi\\) is an \\({\\cal L}_{M}\\)-formula, then \\({\\rm RM}(\\phi)<\\infty\\).\n\n#### The Monster Model\n\nThe definition we just gave of Morley rank is rather awkward because even if a formula has parameters from \\({\\cal M}\\models T\\) we need to work in an \\(\\aleph_{0}\\)-saturated elementary extension to calculate the Morley rank. Then, to show that Morley rank is well-defined, we must show that our calculation did not depend on our choice of \\(\\aleph_{0}\\)-saturated model. Arguments such as this come up very frequently and tend to be both routine and repetitive. To simplify proofs, we will frequently adopt the expository device of assuming that we are working in a fixed, very large, saturated model of \\(T\\).\n\nLet \\({\\mathbb{M}}\\models T\\) be saturated of cardinality \\(\\kappa\\), where \\(\\kappa\\) is \"very large.\" We call \\({\\mathbb{M}}\\) the _monster model of T_. If \\({\\cal M}\\models T\\) and \\(|M|\\leq\\kappa\\), then by Lemma4.3.17 there is an elementary embedding of \\(\\mathcal{M}\\) into \\(\\mathbb{M}\\). Moreover, if \\(\\mathcal{M}\\prec\\mathbb{M}\\), \\(f:\\mathcal{M}\\rightarrow\\mathcal{N}\\) is elementary, and \\(|N|<\\kappa\\), we can find \\(j:\\mathcal{N}\\rightarrow\\mathbb{M}\\) elementary such that \\(j|M\\) is the identity. Thus, if we focus attention on models of \\(T\\) of cardinality less than \\(\\kappa\\), we can view all models as elementary submodels of \\(\\mathbb{M}\\).\n\nThere are several problems with this approach. First, we really want to prove theorems about all models of \\(T\\), not just the small ones. But if there are arbitrarily large saturated models of \\(T\\), then we can prove something about all models of \\(T\\) by proving it for submodels of larger and larger monster models. Second, and more problematic, for general theories \\(T\\) there may not be any saturated models. For our purposes, this is not a serious problem because, for the remainder of this text, we will be focusing on \\(\\omega\\)-stable theories and, by Theorem 4.3.15, if \\(T\\) is \\(\\omega\\)-stable, there are saturated models of \\(T\\) of cardinality \\(\\kappa\\) for each regular cardinal \\(\\kappa\\). If we were considering arbitrary theories, we could get around this by making some extra set-theoretic assumptions. For example, we could assume that for all cardinals \\(\\lambda\\) there is a strongly inaccessible cardinal \\(\\kappa>\\lambda\\). Then, by Corollary 4.3.14, there are arbitrarily large saturated models.\n\nWe will tacitly assume that \\(T\\) has arbitrarily large saturated models, and thus we can prove theorems about all models of \\(T\\) by proving theorems about elementary submodels of saturated models.1 We will only use this assumption in arguments where, by careful bookkeeping as in the proofs above, we could avoid it.\n\nFootnote 1: There are other approaches to the monster model, which we discuss in the remarks at the end of this chapter.\n\nFor the remainder of the chapter, we make the following assumptions:\n\n\\(\\bullet\\)\\(\\mathbb{M}\\) is a large saturated model of \\(T\\);\n\n\\(\\bullet\\) all \\(\\mathcal{M}\\models T\\) that we consider are elementary submodels of \\(\\mathbb{M}\\) and \\(|M|<|\\mathbb{M}|\\);\n\n\\(\\bullet\\) all sets \\(A\\) of parameters that we consider are subsets of \\(\\mathbb{M}\\) with \\(|A|<\\mathbb{M}\\);\n\n\\(\\bullet\\) if \\(\\phi(\\overline{v},\\overline{a})\\) is a formula with parameters, we assume \\(\\overline{a}\\in\\mathbb{M}\\);\n\n\\(\\bullet\\) we write \\(\\operatorname{tp}(\\overline{a}/A)\\) for \\(\\operatorname{tp}^{\\mathbb{M}}(\\overline{a}/A)\\) and \\(S_{n}(A)\\) for \\(S_{n}^{\\mathbb{M}}(A)\\).\n\nNote that if \\(\\overline{a}\\in M\\), then, because \\(\\mathcal{M}\\prec\\mathbb{M}\\), \\(\\mathcal{M}\\models\\phi(\\overline{a})\\) if and only if \\(\\mathbb{M}\\models\\phi(\\overline{a})\\). We will say that \\(\\phi(\\overline{a})\\) holds if \\(\\mathbb{M}\\models\\phi(\\overline{a})\\).\n\nBecause \\(\\mathbb{M}\\) is saturated, if \\(A\\subset\\mathbb{M}\\) and \\(p\\in S_{n}(A)\\), then \\(p\\) is realized in \\(\\mathbb{M}\\). Moreover, if \\(f:A\\rightarrow\\mathbb{M}\\) is a partial elementary map, then \\(f\\) extends to an automorphism of \\(\\mathbb{M}\\).\n\nWe could define Morley rank referring only to the monster model. The Morley rank of an \\(\\mathcal{L}_{\\mathbb{M}}\\)-formula is inductively defined as follows:\n\n\\(\\operatorname{RM}(\\phi)\\geq 0\\) if and only if \\(\\phi(\\mathbb{M})\\) is nonempty;\n\n\\(\\operatorname{RM}(\\phi)\\geq\\alpha+1\\) if and only if there are \\(\\mathcal{L}_{\\mathbb{M}}\\)-formulas \\(\\psi_{1},\\psi_{2},\\ldots\\) such that \\(\\psi_{1}(\\mathbb{M}),\\psi_{2}(\\mathbb{M}),\\ldots\\) is an infinite sequence of pairwise disjoint subsets of \\(\\phi(\\mathbb{M})\\) and \\(\\operatorname{RM}(\\psi_{i})\\geq\\alpha\\) for each \\(i\\);if \\(\\alpha\\) is a limit ordinal, \\(\\mathrm{RM}(\\phi)\\geq\\alpha\\) if and only if \\(\\mathrm{RM}(\\phi)\\geq\\beta\\) for each \\(\\beta<\\alpha\\).\n\n#### Morley Degree\n\nIf \\(X\\) is a definable set of Morley rank \\(\\alpha\\), then we cannot partition \\(X\\) into infinitely many pairwise disjoint definable subsets of Morley rank \\(\\alpha\\). Indeed, we will show that there is a number \\(d\\) such that \\(X\\) cannot be partitioned into more than \\(d\\) definable sets of Morley rank \\(\\alpha\\).\n\n**Proposition 6.2.9**: _Let \\(\\phi\\) be an \\(\\mathcal{L}_{\\mathbb{M}}\\)-formula with \\(\\mathrm{RM}(\\phi)=\\alpha\\) for some ordinal \\(\\alpha\\). There is a natural number \\(d\\) such that if \\(\\psi_{1},\\ldots,\\psi_{n}\\) are \\(\\mathcal{L}_{\\mathbb{M}}\\)-formulas such that \\(\\psi_{1}(\\mathbb{M}),\\ldots,\\psi_{n}(\\mathbb{M})\\) are disjoint subsets of \\(\\phi(\\mathbb{M})\\) such that \\(\\mathrm{RM}(\\psi_{i})=\\alpha\\) for all \\(i\\), then \\(n\\leq d\\)._\n\n_We call \\(d\\) the_ Morley degree _of \\(\\phi\\) and write \\(\\mathrm{deg}_{\\mathrm{M}}(\\phi)=d\\)._\n\n**Proof** We build \\(S\\subseteq 2^{<\\omega}\\) and \\((\\phi_{\\sigma}:\\sigma\\in S)\\) with the following properties.\n\ni) If \\(\\sigma\\in S\\) and \\(\\tau\\subseteq\\sigma\\), then \\(\\tau\\in S\\).\n\nii) \\(\\phi_{\\emptyset}=\\phi\\).\n\niii) \\(\\mathrm{RM}(\\phi_{\\sigma})=\\alpha\\) for all \\(\\sigma\\in S\\).\n\niv) If \\(\\sigma\\in S\\), there are two cases to consider. If there is an \\(\\mathcal{L}_{\\mathbb{M}}\\)-formula \\(\\psi\\) such that \\(\\mathrm{RM}(\\phi_{\\sigma}\\wedge\\psi)=\\mathrm{RM}(\\phi_{\\sigma}\\wedge\\neg\\psi)=\\alpha\\), then \\(\\sigma,0\\) and \\(\\sigma,1\\) are in \\(S\\), \\(\\phi_{\\sigma,0}\\) is \\(\\phi_{\\sigma}\\wedge\\psi\\), and \\(\\phi_{\\sigma,1}\\) is \\(\\phi_{\\sigma}\\wedge\\neg\\psi\\). If there is no such \\(\\psi\\), then no \\(\\tau\\supset\\sigma\\) is in \\(S\\).\n\nThe set \\(S\\) is a binary tree. We claim that \\(S\\) is finite. If \\(S\\) is infinite, then, by Konig's Lemma (see Lemma A.21), there is \\(f:\\omega\\to 2\\) such that \\(f|n\\in S\\) for all \\(n\\). Let \\(\\psi_{n}\\) be the formula \\(\\phi_{f|n}\\wedge\\neg\\phi_{f|n+1}\\) for \\(n=1,2,\\ldots\\). Then, \\(\\mathrm{RM}(\\psi_{n})=\\alpha\\) for all \\(n\\) and \\(\\psi_{1}(\\mathbb{M}),\\psi_{2}(\\mathbb{M}),\\ldots\\) are disjoint subsets of \\(\\phi(\\mathbb{M})\\). But then \\(\\mathrm{RM}(\\phi)\\geq\\alpha+1\\), a contradiction. Thus, \\(S\\) is finite.\n\nLet \\(S_{0}=\\{\\sigma\\in S:\\tau\\not\\in S\\) for all \\(\\tau\\supset\\sigma\\}\\) be the terminal nodes of the tree \\(S\\). Let \\(d=|S_{0}|\\), and let \\(\\psi_{1},\\ldots,\\psi_{d}\\) be an enumeration of \\(\\{\\phi_{\\sigma}:\\sigma\\in S_{0}\\}\\). Then, \\(\\mathrm{RM}(\\psi_{i})=\\alpha\\) for all \\(i\\), \\(\\phi(\\mathcal{M})\\) is the disjoint union of \\(\\psi_{1}(\\mathbb{M}),\\ldots,\\psi_{d}(\\mathbb{M})\\), and, for each \\(i\\), there is no formula \\(\\chi\\) such that \\(\\mathrm{RM}(\\psi_{i}\\wedge\\chi)=\\mathrm{RM}(\\psi_{i}\\wedge\\neg\\chi)=\\alpha\\).\n\nSuppose that \\(\\theta_{1},\\ldots,\\theta_{n}\\) is a sequence of \\(\\mathcal{L}_{\\mathbb{M}}\\)-formulas of Morley rank \\(\\alpha\\) such that \\(\\theta_{1}(\\mathbb{M}),\\ldots,\\theta_{n}(\\mathbb{M})\\) is a sequence of pairwise disjoint subsets of \\(\\phi(\\mathbb{M})\\). We claim that \\(n\\leq d\\). By our choice of \\(\\psi_{1},\\ldots,\\psi_{d}\\), for each \\(i\\leq d\\), there is at most one \\(j\\leq n\\) such that \\(\\mathrm{RM}(\\psi_{i}\\wedge\\theta_{j})=\\alpha\\). If \\(n>d\\), there is \\(\\widehat{j}\\leq n\\) such that \\(\\mathrm{RM}(\\psi_{i}\\wedge\\theta_{\\widehat{j}})<\\alpha\\) for all \\(i\\leq d\\). But\n\n\\[\\mathbb{M}\\models\\theta_{\\widehat{j}}\\leftrightarrow\\bigvee_{i=1}^{d}\\psi_{i }\\wedge\\theta_{\\widehat{j}}.\\]\n\nThus, by Lemma 6.2.7, \\(\\mathrm{RM}(\\theta_{\\widehat{j}})<\\alpha\\), a contradiction.", "(mmd) Number Theory - Number Theory - An Introduction to Mathematics - Coppel.mmd-nilay-laurel-p62-63-FacebookAI_roberta-base.json": "manner just described. It was proved by Stone (1936) that every Boolean ring may be obtained in this way. Thus the algebraic laws of set theory may be replaced by the more familiar laws of algebra and all such laws are consequences of a small number among them.\n\nWe now return to arbitrary rings. In the same way as for \\(\\mathbb{Z}\\), in any ring \\(R\\) we have\n\n\\[a0=0=0a\\quad\\text{for every }a\\]\n\nand\n\n\\[(-a)b=-(ab)=a(-b)\\quad\\text{for all }a,b.\\]\n\nIt follows that \\(R\\) contains only one element if \\(1=0\\). We will say that the ring \\(R\\) is 'trivial' in this case.\n\nSuppose \\(R\\) is a nontrivial ring. Then, viewing \\(R\\) as a group under addition, the cyclic subgroup \\((1)\\) is either infinite, and isomorphic to \\(\\mathbb{Z}/0\\mathbb{Z}\\), or finite of order \\(s\\), and isomorphic to \\(\\mathbb{Z}/s\\mathbb{Z}\\) for some positive integer \\(s\\). The ring \\(R\\) is said to have _characteristic_\\(0\\) in the first case and _characteristic_\\(s\\) in the second case.\n\nFor any positive integer \\(n\\), write\n\n\\[na:=a+\\cdots+a\\quad(n\\text{ summands}).\\]\n\nIf \\(R\\) has characteristic \\(s>0\\), then \\(sa=0\\) for every \\(a\\in R\\), since\n\n\\[sa=(1+\\cdots+1)a=0a=0.\\]\n\nOn the other hand, \\(n1\\neq 0\\) for every positive integer \\(n<s\\), by the definition of characteristic.\n\nAn element \\(a\\) of a nontrivial ring \\(R\\) is said to be 'invertible' or a _unit_ if there exists an element \\(a^{-1}\\) such that\n\n\\[a^{-1}a=1=aa^{-1}.\\]\n\nThe element \\(a^{-1}\\) is then uniquely determined and is called the _inverse_ of \\(a\\). For example, \\(1\\) is a unit and is its own inverse. If \\(a\\) is a unit, then \\(a^{-1}\\) is also a unit and its inverse is \\(a\\). If \\(a\\) and \\(b\\) are units, then \\(ab\\) is also a unit and its inverse is \\(b^{-1}a^{-1}\\). It follows that the set \\(R^{\\times}\\) of all units is a group under multiplication.\n\nA nontrivial ring \\(R\\) in which every nonzero element is invertible is said to be a _division ring_. Thus all nonzero elements of a division ring form a group under multiplication, the _multiplicative group_ of the division ring. A _field_ is a commutative division ring.\n\nA nontrivial commutative ring \\(R\\) is said to be an _integral domain_ if it has no 'divisors of zero', i.e. if \\(a\\neq 0\\) and \\(b\\neq 0\\) imply \\(ab\\neq 0\\). A division ring also has no divisors of zero, since if \\(a\\neq 0\\) and \\(b\\neq 0\\), then \\(a^{-1}ab=b\\neq 0\\), and hence \\(ab\\neq 0\\).\n\nAs examples, the set \\(\\mathbb{Q}\\) of rational numbers, the set \\(\\mathbb{R}\\) of real numbers and the set \\(\\mathbb{C}\\) of complex numbers are all fields, with the usual definitions of addition and multiplication. The set \\(\\mathbb{H}\\) of quaternions is a division ring, and the set \\(\\mathbb{Z}\\) of integers is an integral domain, but neither is a field.\n\nIn a ring with no divisors of zero, the additive order of any nonzero element \\(a\\) is the same as the additive order of \\(1\\), since \\(ma=(m1)a=0\\) if and only if \\(m1=0\\). Furthermore, the characteristic of such a ring is either \\(0\\) or a prime number. For assume \\(n=lm\\), where \\(l\\) and \\(m\\) are positive integers less than \\(n\\). If \\(n1=0\\), then\n\n\\[(l1)(m1)=n1=0.\\]\n\nSince there are no divisors of zero, either \\(l1=0\\) or \\(m1=0\\), and hence the characteristic cannot be \\(n\\).\n\nA subset \\(S\\) of a ring \\(R\\) is said to be a (two-sided) _ideal_ if it is a subgroup of \\(R\\) under addition and if, for every \\(a\\in S\\) and \\(c\\in R\\), both \\(ac\\in S\\) and \\(ca\\in S\\).\n\nAny ring \\(R\\) has two obvious ideals, namely \\(R\\) itself and the subset \\(\\{0\\}\\). It is said to be _simple_ if it has no other ideals and is nontrivial.\n\nAny division ring is simple. For if an ideal \\(S\\) of a division ring \\(R\\) contains \\(a\\neq 0\\), then for every \\(c\\in R\\) we have \\(c=(ca^{-1})a\\in S\\).\n\nConversely, if a _commutative_ ring \\(R\\) is simple, then it is a field. For, if \\(a\\) is any nonzero element of \\(R\\), the set\n\n\\[S_{a}=\\{xa:x\\in R\\}\\]\n\nis an ideal (since \\(R\\) is commutative). Since \\(S_{a}\\) contains \\(1a=a\\neq 0\\), we must have \\(S_{a}=R\\). Hence \\(1=xa\\) for some \\(x\\in R\\). Thus every nonzero element of \\(R\\) is invertible.\n\nIf \\(R\\) is a commutative ring and \\(a_{1},\\ldots,a_{m}\\in R\\), then the set \\(S\\) consisting of all elements \\(x_{1}a_{1}+\\cdots+x_{m}a_{m}\\), where \\(x_{j}\\in R\\) (\\(1\\leq j\\leq m\\)), is clearly an ideal of \\(R\\), the ideal _generated_ by \\(a_{1},\\ldots,a_{m}\\). An ideal of this type is said to be _finitely generated_.\n\nWe now show that if \\(S\\) is an ideal of the ring \\(R\\), then the set \\(\\mathcal{S}\\) of all cosets \\(S+a\\) of \\(S\\) can be given the structure of a ring. The ring \\(R\\) is a commutative group under addition. Hence, as we saw in SS7, \\(\\mathcal{S}\\) acquires the structure of a (commutative) group under addition if we define the sum of \\(S+a\\) and \\(S+b\\) to be \\(S+(a+b)\\). If \\(x=s+a\\) and \\(x^{\\prime}=s^{\\prime}+b\\) for some \\(s,s^{\\prime}\\in S\\), then \\(xx^{\\prime}=s^{\\prime\\prime}+ab\\), where \\(s^{\\prime\\prime}=ss^{\\prime}+as^{\\prime}+sb\\). Since \\(S\\) is an ideal, \\(s^{\\prime\\prime}\\in S\\). Thus without ambiguity we may define the product of the cosets \\(S+a\\) and \\(S+b\\) to be the coset \\(S+ab\\). Evidently multiplication is associative, \\(S+1\\) is an identity element for multiplication and both distributive laws hold. The new ring thus constructed is called the _quotient ring_ of \\(R\\) by the ideal \\(S\\), and is denoted by \\(R/S\\).\n\nA mapping \\(f:R\\to R^{\\prime}\\) of a ring \\(R\\) into a ring \\(R^{\\prime}\\) is said to be a (ring) _homomorphism_ if, for all \\(a,b\\in R\\),\n\n\\[f(a+b)=f(a)+f(b),\\quad f(ab)=f(a)f(b),\\]\n\nand if \\(f(1)=1^{\\prime}\\) is the identity element for multiplication in \\(R^{\\prime}\\).\n\nThe _kernel_ of the homomorphism \\(f\\) is the set \\(N\\) of all \\(a\\in R\\) such that \\(f(a)=0^{\\prime}\\) is the identity element for addition in \\(R^{\\prime}\\). The kernel is an ideal of \\(R\\), since it is a subgroup under addition and since \\(a\\in N\\), \\(c\\in R\\) imply \\(ac\\in N\\) and \\(ca\\in N\\).\n\nFor any \\(a\\in R\\), put \\(a^{\\prime}=f(a)\\in R^{\\prime}\\). The coset \\(N+a\\) is the set of all \\(x\\in R\\) such that \\(f(x)=a^{\\prime}\\), and the map \\(N+a\\to a^{\\prime}\\) is a bijection from the collection of all cosets of \\(N\\) to \\(f(R)\\). Since \\(f\\) is a homomorphism, \\(N+(a+b)\\) is mapped to \\(a^{\\prime}+b^{\\prime}\\) and \\(N+ab\\) is mapped to \\(a^{\\prime}b^{\\prime}\\). Hence the map \\(N+a\\to a^{\\prime}\\) is also a homomorphism of the quotient ring \\(R/N\\) into \\(f(R)\\).", "(mmd) Homological Algebra - A Course in Homological Algebra - Hilton.mmd-nilay-noah-p335-336-FacebookAI_roberta-base.json": "vertex to 1, \\({\\bf C}(\\widetilde{K})\\) provides a free resolution of \\(\\mathbb{Z}\\) as (trivial) \\(\\pi\\)-module, so that\n\n\\[H_{n}\\bigl{(}K(\\pi,\\,1);\\,\\{B\\}\\bigr{)}=H_{n}(\\pi,\\,B),\\qquad H^{n}\\bigl{(}K( \\pi,\\,1);\\,\\{A\\}\\bigr{)}=H^{n}(\\pi,\\,A).\\]\n\nThus our theory in Chapter VI precisely provides a description of the way in which the fundamental group \\(\\pi\\) of the Eilenberg-MacLane space \\(K(\\pi,\\,1)\\) determines its homology and cohomology groups.\n\nWe have already described how the cohomology groups of a simplicial complex (and hence of any polyhedron) with coefficients in a ring \\(R\\) may be turned into a graded ring. So may the cohomology groups of \\(\\pi\\) (see Exercise 13.6 of Chapter VI), and then\n\n\\[H^{\\bullet}\\bigl{(}K(\\pi,\\,1);\\,R\\bigr{)}\\simeq H^{\\bullet}(\\pi,\\,R)\\]\n\nas rings.\n\nThere are now many ways in which the algebra and topology interplay between \\(\\pi\\) and \\(K(\\pi,\\,1)\\). Let us be content with just one example.\n\n**Theorem 1.1.**_If \\(\\pi\\) has an element of finite order_, _then there can be no finite-dimensional model for \\(K(\\pi,\\,1)\\)._\n\n_Proof_. First consider \\(K(C_{m},\\,1)\\), where \\(C_{m}\\) is a cyclic group of order \\(m\\geq 2\\). Since \\({\\bf C}\\bigl{(}\\widetilde{K}(C_{m},\\,1)\\bigr{)}\\) is a free \\(C_{m}\\)-resolution of \\(\\mathbb{Z}\\), and since \\(C_{m}\\) has nonzero integral homology groups in all odd dimensions (see Section 7 of Chapter VI), \\(\\widetilde{K}(C_{m},\\,1)\\), and hence \\(K(C_{m},\\,1)\\), must have cells in arbitrarily high dimensions, i.e., it must be infinite dimensional.\n\nNow let \\(\\pi\\) have an element of order \\(m\\). Then \\({\\bf C}\\bigl{(}\\widetilde{K}(\\pi,\\,1)\\bigr{)}\\) is a free \\(C_{m}\\)-resolution, since \\(C_{m}\\) is a subgroup of \\(\\pi\\) (Lemma 1.3 of Chapter VI). Thus \\(\\widetilde{K}(\\pi,\\,1)\\), and hence \\(K(\\pi,\\,1)\\), has cells in arbitrarily high dimensions, and so must be infinite dimensional.\n\n**Literature**\n\n[D] A. Dold: Lectures in Algebraic Topology. New York: Springer-Verlag, 1970.\n\n## 2. Nilpotent Groups\n\nHomological algebra, in particular the (co)homology theory of groups has seen many applications to the structure theory of groups, both finite and infinite. Here we shall describe one of these applications, the localization theory of nilpotent groups. This theory was developed extensively between 1960 and 1980 in order to facilitate and deepen the homotopy-theoretical study of _nilpotent spaces_ (for a definition see below), but it also has considerable purely algebraic interest.\n\nFor a group \\(G\\) the series of subgroups \\(\\gamma^{i}G\\), the _lower central series_ of \\(G\\), is defined by \\[\\gamma^{1}(G)=G,\\qquad\\gamma^{i+1}(G)=[G,\\gamma^{i}(G)],\\qquad i\\geq 1,\\]\n\nwhere for two subgroups \\(U\\), \\(V\\) of \\(G\\) the symbol \\([U,V]\\) denotes the subgroup of \\(G\\) generated by all elements \\(u^{-1}v^{-1}uv\\) with \\(u\\in U\\) and \\(v\\in V\\). It is easy to see that \\(\\gamma^{i}(G)\\) is a normal subgroup of \\(G\\) and that \\(\\gamma^{i}(G)/\\gamma^{i+1}(G)\\) is a central, and hence also abelian, subgroup of \\(G/\\gamma^{i+1}(G)\\). A group \\(G\\) is called _nilpotent_ of class \\(\\leq c\\) if \\(\\gamma^{e+1}(G)=1\\); the smallest such \\(c\\) is called the _nilpotency class_ of \\(G\\), nil \\(G\\). From this definition it is clear that a nilpotent group can be obtained by a finite number of successive central extensions, starting with an abelian group. This is the key to the method of obtaining detailed results about the homology and the localization of nilpotent groups.\n\nWe consider a possibly empty family \\(P\\) of primes. As usual, we call the integer \\(n\\) a \\(P\\)_-number_ if the prime factors of \\(n\\) lie in \\(P\\), and a \\(P^{\\prime}\\)_-number_ if they lie outside \\(P\\). A group \\(N\\) is called \\(P\\)_-local_ if the function \\(x\\mapsto x^{q}\\), \\(x\\in N\\), is bijective for all \\(P^{\\prime}\\)-numbers \\(q\\). A _commutative_ group \\(A\\) is thus \\(P\\)-local if and only if it is uniquely divisible by \\(P^{\\prime}\\)-numbers, and this is equivalent to saying that \\(A\\) is a \\(\\mathbb{Z}_{P}\\)-module, where \\(\\mathbb{Z}_{P}\\) is the ring of integers _localized_ at \\(P\\). For abelian groups the tensor product with \\(\\mathbb{Z}_{P}\\) defines a functor that associates with any abelian group \\(A\\) a \\(P\\)-local abelian group \\(A_{P}=\\mathbb{Z}_{P}\\otimes A\\). Attached to this \\(P\\)-localization functor is a natural transformation given by the obvious map \\(l\\colon A\\to A_{P}=\\mathbb{Z}_{P}\\otimes A\\).\n\nThis \\(P\\)-localization functor, defined on the category of abelian groups, can be extended to a \\(P\\)-localization functor on the category of nilpotent groups. It associates with any nilpotent group \\(N\\) a \\(P\\)-local group \\(N_{P}\\), and there is a natural transformation \\(l\\colon N\\to N_{P}\\) with the following universal property: for all \\(P\\)-local nilpotent groups \\(M\\) and all homomorphisms \\(\\varphi\\colon N\\to M\\), there exists a unique homomorphism \\(\\psi\\colon N_{P}\\to M\\) with \\(\\psi l=\\varphi\\). In that case, one says that the map \\(l\\colon N\\to N_{P}\\)\\(P\\)_-localizes_.\n\nThe existence of the \\(P\\)-localizing functor on the category of nilpotent groups can be proved using homological algebra, in particular, the (co)homology theory of groups, and induction on the nilpotency class. The general result is as follows:\n\n**Proposition 2.1.**_Let \\(N\\) be a nilpotent group. Then there is a \\(P\\)-local group \\(N_{P}\\) and a map \\(l\\colon N\\to N_{P}\\) which \\(P\\)-localizes_; _and_ nil \\(N_{P}\\leq\\operatorname{nil}N\\). _Moreover_, _a homomorphism \\(\\widehat{l}\\colon N\\to M\\) between nilpotent groups \\(P\\)-localizes if and only if the induced map \\(l_{n}\\colon H_{n}(N)\\to H_{n}(M)\\)\\(P\\)-localizes for all \\(n\\geq 1\\). In particular_, _a nilpotent group is \\(P\\)-local if and only if its homology groups in positive dimensions are \\(P\\)-local_.\n\nThe group \\(N_{P}\\), as well as the map \\(l\\), may be constructed, as we have said, by induction on the nilpotency class of the group \\(N\\). To start the induction, one has to show that, for an abelian group \\(A\\), the map \\(l\\colon A\\to\\mathbb{Z}_{P}\\otimes A\\) induces localizing maps \\(l_{n}\\colon H_{n}(A)\\to H_{n}(\\mathbb{Z}_{P}\\otimes A)\\) for all", "(mmd) Model Theory - Model Theory An Introduction - Marker.mmd-nilay-victoria-p141-142-FacebookAI_roberta-base.json": "**Example 4.3.10**: _Algebraically Closed Fields_\n\nFix \\(p\\) prime or \\(0\\). Let \\(k\\) be \\(\\mathbb{F}_{p}\\) if \\(p>0\\) and \\(\\mathbb{Q}\\) if \\(p=0\\). Because \\(S_{n}(\\mathrm{ACF}_{p})\\) is in bijection with \\(\\mathrm{Spec}(k[X_{1},\\ldots,X_{n}])\\), by Corollary 4.1.18, \\(|S_{n}(\\mathrm{ACF}_{p})|=\\aleph_{0}\\). Thus, there is a countable saturated model of \\(\\mathrm{ACF}_{p}\\).\n\nLet \\(q_{n}\\) be the type corresponding to the \\(0\\) ideal in \\(k[X_{1},\\ldots,X_{n}]\\). If \\(a_{1},\\ldots,a_{n}\\) realizes \\(q_{n}\\), then \\(a_{1},\\ldots,a_{n}\\) are algebraically independent over \\(k\\). Thus, any saturated model has infinite transcendence degree. It followsthat the countable saturated model of \\({\\rm ACF}_{p}\\) is the unique algebraically closed field of characteristic \\(p\\) and transcendence degree \\(\\aleph_{0}\\).\n\n**Example 4.3.11**: _Real Closed Fields_\n\nLet \\(r\\in{\\mathbb{R}}\\setminus{\\mathbb{Q}}\\). Let \\(p_{r}\\) be the set of formulas \\(\\Big{\\{}\\underbrace{v+\\ldots+v}_{m-{\\rm times}}<\\underbrace{1+\\ldots+1}_{n-{ \\rm times}}:m,n\\in{\\mathbb{N}},r<\\frac{n}{m}\\Big{\\}}\\cup\\ \\Big{\\{} \\underbrace{v+\\ldots+v}_{m-{\\rm times}}>\\underbrace{1+\\ldots+1}_{n-{\\rm times }}:m,n\\in{\\cal N},r>\\frac{n}{m}\\Big{\\}}\\). Clearly, \\(p_{r}\\) is satisfiable. Let \\(p_{r}^{*}\\in S_{1}({\\rm RCF})\\) with \\(p_{r}^{*}\\supseteq p_{r}\\). If \\(r\\neq s\\), then \\(p_{r}^{*}\\neq p_{s}^{*}\\). Thus, \\(|S_{1}({\\rm RCF})|=2^{\\aleph_{0}}\\) and RCF has no saturated model.\n\n#### Existence of Saturated Models\n\nNext we think about the existence of \\(\\kappa\\)-saturated models for \\(\\kappa>\\aleph_{0}\\).\n\n**Theorem 4.3.12**: _For all \\({\\cal M}\\), there is a \\(\\kappa^{+}\\)-saturated \\({\\cal M}\\prec{\\cal N}\\) with \\(|N|\\leq|M|^{\\kappa}\\)._\n\n**Proof**\n\n**Claim**: For any \\({\\cal M}\\) there is \\({\\cal M}\\prec{\\cal M}^{\\prime}\\) such that \\(|M^{\\prime}|\\leq|M|^{\\kappa}\\), and if \\(A\\subseteq M\\), \\(|A|\\leq\\kappa\\) and \\(p\\in S_{1}^{\\cal M}(A)\\), then \\(p\\) is realized in \\({\\cal M}^{\\prime}\\).\n\nWe first note that\n\n\\[|\\{A\\subseteq M:|A|\\leq\\kappa\\}|\\leq|M|^{\\kappa}\\]\n\nbecause for each such \\(A\\) there is \\(f\\) mapping \\(\\kappa\\) onto \\(A\\). Also, for each such \\(A\\), \\(|S_{1}^{\\cal M}(A)|\\leq 2^{\\kappa}\\). Let \\((p_{\\alpha}:\\alpha<|M|^{\\kappa})\\) list all types in \\(S_{1}^{\\cal M}(A)\\) for \\(n<\\omega\\), \\(A\\subseteq M\\) with \\(|A|\\leq\\kappa\\). We build an elementary chain \\(({\\cal M}_{\\alpha}:\\alpha<|M|^{\\kappa})\\) as follows:\n\ni) \\({\\cal M}_{0}={\\cal M}\\);\n\nii) \\({\\cal M}_{\\alpha}=\\bigcup_{\\beta<\\alpha}{\\cal M}_{\\beta}\\) for \\(\\alpha\\) a limit ordinal;\n\niii) \\({\\cal M}_{\\alpha}\\prec{\\cal M}_{\\alpha+1}\\) with \\(|M_{\\alpha+1}|=|M_{\\alpha}|\\), and \\({\\cal M}_{\\alpha+1}\\) realizes \\(p_{\\alpha}\\). By induction, we see that \\(|M_{\\alpha}|\\leq|M|^{\\kappa}\\) for all \\(\\alpha\\). Let \\({\\cal M}^{\\prime}=\\bigcup_{\\alpha<|M|^{\\kappa}}{\\cal M}_{\\alpha}\\). Then, \\(|M^{\\prime}|\\leq|M|^{\\kappa}\\) and \\({\\cal M}^{\\prime}\\) is the desired model. This proves the claim.\n\nWe build an elementary chain \\(({\\cal N}_{\\alpha}:\\alpha<\\kappa^{+})\\) such that each \\(|N_{\\alpha}|\\leq|M|^{\\kappa}\\) and\n\ni) \\({\\cal N}_{0}={\\cal M}\\);\n\nii) \\({\\cal N}_{\\alpha}=\\bigcup_{\\beta<\\alpha}{\\cal N}_{\\beta}\\) for \\(\\alpha\\) a limit ordinal;\n\niii) \\({\\cal N}_{\\alpha}\\prec{\\cal N}_{\\alpha+1}\\), \\(|{\\cal N}_{\\alpha}|\\leq|M|^{\\kappa}\\), and if \\(A\\subseteq N_{\\alpha}\\) with \\(|A|\\leq\\kappa\\) and \\(p\\in S_{n}^{{\\cal N}_{\\alpha}}(A)\\), then \\(p\\) is realized in \\({\\cal N}_{\\alpha+1}\\). This is possible by the claim because, by induction,\n\n\\[|N_{\\alpha}|^{\\kappa}\\leq(|M|^{\\kappa})^{\\kappa}=|M|^{\\kappa}.\\]\n\nLet \\({\\cal N}=\\bigcup_{\\alpha<\\kappa^{+}}{\\cal N}_{\\alpha}\\). Because \\(\\kappa^{+}\\leq|M|^{\\kappa}\\), \\(N\\) is the union of at most \\(|M|^{\\kappa}\\) sets of size \\(|M|^{\\kappa}\\) so \\(|N|\\leq|M|^{\\kappa}\\). Suppose that \\(|A|\\subseteq N\\), \\(|A|\\leq\\kappa\\), and \\(p\\in S_{n}^{\\mathcal{N}}(A)\\). Because \\(\\kappa^{+}\\) is a regular cardinal, there is \\(\\alpha<\\kappa^{+}\\) such that \\(A\\subset N_{\\alpha}\\) and \\(p\\) is realized in \\(\\mathcal{N}_{\\alpha+1}\\prec\\mathcal{N}\\). Thus, \\(\\mathcal{N}\\) is \\(\\kappa^{+}\\)-saturated.\n\nTheorem 4.3.12 guarantees the existence of saturated models under suitable set-theoretic assumptions.\n\n**Corollary 4.3.13**: _Suppose that \\(2^{\\kappa}=\\kappa^{+}\\). Then, there is a saturated model of \\(T\\) of size \\(\\kappa^{+}\\). In particular, if the Generalized Continuum Hypothesis is true, there are saturated models of size \\(\\kappa^{+}\\) for all \\(\\kappa\\)._\n\nFor arbitrary \\(T\\), some set-theoretic assumption is necessary. For example, if \\(|S_{n}(T)|=2^{\\aleph_{0}}\\), then any \\(\\aleph_{0}\\)-saturated model has size \\(2^{\\aleph_{0}}\\). If \\(\\aleph_{1}<2^{\\aleph_{0}}\\), then there is no saturated model of size \\(\\aleph_{1}\\).\n\nWe can extend this a bit further.\n\n**Corollary 4.3.14**: _Suppose that \\(\\kappa\\geq\\aleph_{1}\\) is regular and \\(2^{\\lambda}\\leq\\kappa\\) for \\(\\lambda<\\kappa\\). Then, there is a saturated model of size \\(\\kappa\\). In particular, if \\(\\kappa\\geq\\aleph_{1}\\) is strongly inaccessible, then there is a saturated model of size \\(\\kappa\\)._\n\nLet \\(\\mathcal{M}\\models T\\) with \\(|M|=\\kappa\\). If \\(\\kappa=\\lambda^{+}\\) for \\(\\lambda<\\kappa\\), then the corollary follows from Corollary 4.3.13. Thus, we may assume that \\(\\kappa\\) is a limit cardinal. We build an elementary chain \\((\\mathcal{M}_{\\lambda}:\\lambda<\\kappa,\\lambda\\) a cardinal). Each \\(\\mathcal{M}_{\\lambda}\\) will have cardinality \\(\\kappa\\). Let \\(\\mathcal{M}_{0}=\\mathcal{M}\\).\n\nLet \\(\\mathcal{M}_{\\lambda}=\\bigcup_{\\mu<\\lambda}\\mathcal{M}_{\\mu}\\) for \\(\\lambda\\) a limit cardinal. Because \\(\\mathcal{M}_{\\alpha}\\) is the union of fewer than \\(\\kappa\\) models of size \\(\\kappa\\), \\(|M_{\\alpha}|=\\kappa\\).\n\nGiven \\(\\mathcal{M}_{\\lambda}\\), by Theorem 4.3.12 there is \\(\\mathcal{M}_{\\lambda}\\prec\\mathcal{M}_{\\lambda^{+}}\\) such that \\(\\mathcal{M}\\) is \\(\\lambda^{+}\\)-saturated and \\(|M_{\\lambda^{+}}|\\leq\\kappa^{\\lambda}=\\kappa\\) (see Corollary A.17).\n\nLet \\(\\mathcal{N}=\\bigcup\\mathcal{M}_{\\lambda}\\). Because \\(\\kappa\\) is a regular limit cardinal, \\(\\kappa=\\aleph_{\\kappa}\\) (see Proposition A.13). Thus, because \\(\\kappa\\) is regular, if \\(A\\subset N\\) and \\(|A|<\\kappa\\), then there is \\(\\lambda<\\kappa\\) such that \\(A\\subset M_{\\lambda}\\). Thus, if \\(p\\in S_{n}^{\\mathcal{N}}(A)\\), then \\(p\\) is realized in \\(\\mathcal{M}_{\\lambda^{+}}\\prec\\mathcal{N}\\).\n\nThe assumption of regularity is necessary for some \\(T\\). For example, suppose that \\(\\mathcal{M}\\models\\) DLO with \\(|M|=\\aleph_{\\omega}\\). We claim that \\(\\mathcal{M}\\) is not saturated. Let \\(M=\\bigcup_{n<\\omega}M_{n}\\) where \\(|M_{n}|=\\aleph_{n}\\). If \\(\\mathcal{M}\\) is saturated, then for each \\(n<\\omega\\) we can find \\(a_{n}\\in M\\) such that \\(a_{n}>b\\) for all \\(b\\in M_{n}\\). One more use of saturation allows us to find \\(c\\in M\\) such that \\(c>a_{n}\\) for \\(n<\\omega\\). This is impossible. Similar arguments show that all saturated dense linear orders must have regular cardinality.\n\nIf \\(T\\) is \\(\\kappa\\)-stable, then we can eliminate all assumptions about cardinal exponentiation.\n\n**Theorem 4.3.15**: _Let \\(\\kappa\\) be a regular cardinal. If \\(T\\) is \\(\\kappa\\)-stable, then there is a saturated \\(\\mathcal{M}\\models T\\) with \\(|M|=\\kappa\\). Indeed, if \\(\\mathcal{M}_{0}\\models T\\) with \\(|M_{0}|=\\kappa\\), then there is a saturated elementary extension \\(\\mathcal{M}\\) of \\(\\mathcal{M}_{0}\\) with \\(|M|=\\kappa\\)._\n\n_In particular, if \\(T\\) is \\(\\omega\\)-stable, then there are saturated models of size \\(\\kappa\\) for all regular cardinals \\(\\kappa\\)._", "(mmd) Noncommutative Algebra - Introduction to Noncommutative Algebra - Bresar.mmd-nilay-victoria-p98-99-FacebookAI_roberta-base.json": "### The Skolem-Noether Theorem\n\nMost parts of this and the preceding chapter were devoted to building machinery. In these final sections we shall finally be rewarded. We are going to prove two appealing theorems on finite dimensional central simple algebras by using several abstract results on tensor products and modules.\n\nIn Sect. 6 we have proved that all automorphisms of finite dimensional central simple algebras are inner. As we pointed out then, this result is an important special case of the so-called Skolem-Noether Theorem. We are now in a position to establish the general version of this theorem.\n\n**Theorem 4.46**: (Skolem-Noether) _Let \\(A\\) be a finite dimensional central simple algebra. If \\(S\\) is a simple subalgebra of \\(A\\) that contains the unity \\(1\\) of \\(A\\), then every homomorphism from \\(S\\) into \\(A\\) that maps \\(1\\) into \\(1\\) can be extended to an inner automorphism of \\(A\\)._\n\n_Proof_ As we know, \\(A\\) is isomorphic to a matrix algebra over a central division algebra (Corollary 2.62). However, for the purposes of this proof it is more convenient to represent it as an endomorphism algebra. More precisely, according to Theorem 3.31 we have \\(A\\cong\\operatorname{End}_{\\Delta}(V)\\), where \\(\\Delta\\) is a central division algebra and \\(V\\) is a finite dimensional vector space over \\(\\Delta\\). In fact, there is no loss of generality in assuming that \\(A=\\operatorname{End}_{\\Delta}(V)\\) (note that the conclusion of the theorem holds simultaneously for isomorphic algebras).\n\nLet \\(T=S\\otimes_{F}\\Delta\\), where \\(F\\) is the base field. As \\(S\\) is simple and \\(\\Delta\\) is central simple, \\(T\\) is a simple algebra by Theorem 4.42. Let us point out that \\(V\\) is also a vector space over \\(F\\) and elements in \\(A\\) are \\(F\\)-linear maps (cf. Remark 3.34). Given \\(v\\in V\\), we see that the map \\(S\\times\\Delta\\to V\\), \\((\\sigma,\\delta)\\mapsto\\sigma(\\delta v)\\) is bilinear, and hence there is an \\(F\\)-linear map \\(T\\to V\\), \\(\\sigma\\otimes\\delta\\mapsto\\sigma(\\delta v)\\). Since \\(v\\) is arbitrary, there exists a bilinear map \\(T\\times V\\to V\\), \\((t,v)\\mapsto tv\\), such that\n\n\\[(\\sigma\\otimes\\delta)v=\\sigma(\\delta v)\\ \\ \\ \\text{for all}\\ \\sigma\\in S,\\delta \\in\\Delta,v\\in V. \\tag{4.3}\\]\n\nIn this way \\(V\\), considered as a space over \\(F\\), becomes a unital \\(T\\)-module. Indeed, since elements in \\(S\\) are \\(\\Delta\\)-linear maps, we have\n\n\\[\\big{(}(\\sigma\\otimes\\delta)(\\sigma^{\\prime}\\otimes\\delta^{\\prime })\\big{)}v =\\sigma\\sigma^{\\prime}\\big{(}(\\delta\\delta^{\\prime})v\\big{)}=\\sigma \\Big{(}\\sigma^{\\prime}\\big{(}\\delta(\\delta^{\\prime}v)\\big{)}\\Big{)}\\] \\[=\\sigma\\Big{(}\\delta\\big{(}\\sigma^{\\prime}(\\delta^{\\prime}v)\\big{)} \\Big{)}=(\\sigma\\otimes\\delta)\\big{(}(\\sigma^{\\prime}\\otimes\\delta^{\\prime})v \\big{)}.\\]\n\nTo avoid confusion, we denote \\(V\\), when viewed as a \\(T\\)-module with respect to (4.3), by \\(V_{1}\\).\n\nLet \\(\\varphi:S\\to A\\) be a homomorphism such that \\(\\varphi(1)=1\\). By making only obvious changes in the above discussion we see that \\(V\\) becomes a unital \\(T\\)-module with respect to the action\\[(\\sigma\\otimes\\delta)\\cdot v=\\varphi(\\sigma)(\\delta v)\\quad\\text{for all}\\quad \\sigma\\in S,\\delta\\in\\Delta,v\\in V\\,. \\tag{4.4}\\]\n\nLet us denote \\(V\\), when viewed as a \\(T\\)-module with respect to (4.4), by \\(V_{2}\\).\n\nWe have arrived at the crucial point of the proof: since \\(V_{1}\\) and \\(V_{2}\\) have the same dimension over \\(F\\) (indeed, as vector spaces over \\(F\\) they are simply identical) and \\(T\\) is a simple algebra, Corollary 3.60 implies that they are isomorphic as \\(T\\)-modules. Let \\(\\alpha:V_{1}\\to V_{2}\\) be an isomorphism. Given \\(\\delta\\in\\Delta\\) and \\(v\\in V\\), we have\n\n\\[\\alpha(\\delta v)=\\alpha((1\\otimes\\delta)v)=1\\otimes\\delta\\cdot\\alpha(v)=\\varphi (1)(\\delta\\alpha(v))=\\delta\\alpha(v).\\]\n\nThat is, \\(\\alpha\\) is a \\(\\Delta\\)-linear map. As vector spaces over \\(F\\), both \\(V_{1}\\) and \\(V_{2}\\) are equal to \\(V\\). Therefore \\(\\alpha\\in A\\). Moreover, since \\(\\alpha\\) is bijective, it is invertible in \\(A\\).\n\nLet \\(\\sigma\\in S\\). We can multiply \\(\\alpha\\) and \\(\\sigma\\) as elements in \\(A\\). For \\(v\\in V\\) we have\n\n\\[(\\alpha\\sigma)(v)=\\alpha(\\sigma(v))=\\alpha((\\sigma\\otimes 1)v)=\\sigma\\otimes 1 \\cdot\\alpha(v)=\\varphi(\\sigma)(\\alpha(v))=\\bigl{(}\\varphi(\\sigma)\\alpha\\bigr{)} (v).\\]\n\nSince \\(v\\) is arbitrary, this means that \\(\\alpha\\sigma=\\varphi(\\sigma)\\alpha\\) for every \\(\\sigma\\in S\\). That is, \\(\\varphi(\\sigma)=\\alpha\\sigma\\alpha^{-1}\\), so \\(\\varphi\\) can be extended to the inner automorphism \\(a\\mapsto\\alpha a\\alpha^{-1}\\) of \\(A\\). \n\nThe Skolem-Noether Theorem turns out to be very useful. In particular, as one can find in several textbooks (e.g., in [11], [12], and [13]). Frobenius' theorem on real division algebras and Wedderburn's theorem on finite division rings can be derived from it. Of course, these proofs are not as elementary as those given in Chap. 1. But they are very elegant and therefore worth seeing.\n\n### The Double Centralizer Theorem\n\nLet \\(S\\) be a subalgebra of an algebra \\(A\\). The centralizer of its centralizer, \\(C_{A}(C_{A}(S))\\), is called the **double centralizer** of \\(S\\). This is obviously a subalgebra of \\(A\\) which contains \\(S\\). Quite possibly \\(S\\) is its proper subset. Say, if \\(S\\) does not contain \\(Z(A)\\), this is certainly the case. Another example: if \\(A=M_{n}(F)\\) and \\(S=T_{n}(F)\\), \\(n\\geq 2\\), then \\(C_{A}(S)=F=Z(A)\\), and hence \\(C_{A}(C_{A}(S))=A\\supsetneq S\\). On the other hand, if \\(S=A\\) or \\(S=Z(A)\\), then \\(C_{A}(C_{A}(S))=S\\). A more illuminating situation where the equality holds is described in the following example.\n\n_Example 4.47_: Considering central algebras \\(S\\) and \\(T\\) as subalgebras of \\(A:=S\\otimes T\\), we have \\(C_{A}(S)=T\\) and \\(C_{A}(T)=S\\) by Corollary 4.33, and hence \\(C_{A}(C_{A}(S))=S\\) and \\(C_{A}(C_{A}(T))=T\\). If \\(S\\) and \\(T\\) are finite dimensional, then we also have \\([A:F]=[S:F][C_{A}(S):F]=[T:F][C_{A}(T):F]\\).\n\nThis example illustrates the next theorem in which, however, we will not assume that \\(S\\) is central.", "(mmd) Functional Analysis - Introduction to Operator Theory I - Brown.mmd-nilay-davit_p38-40_mmd-FacebookAI_roberta-base.json": "**Proposition 3.7**.: _If \\(E\\) is an arbitrary subset of the real line \\(\\mathbb{R}\\), then the following conditions are equivalent_:__\n\n1. \\(E\\) _is connected,_\n2. _If_ \\(a,b\\in E\\)_, and if_ \\(a<c<b\\)_, then_ \\(c\\in E\\)_,_\n3. \\(E\\) _is either an interval (open, closed, or half-open), or a ray (open or closed), or the entire real line_ \\(\\mathbb{R}\\)_If \\(U\\) is an open subset of \\(\\mathbb{R}\\), then \\(U\\) can be expressed uniquely as a countable union of pairwise disjoint nonempty open intervals, and these intervals are the connected components of \\(U\\)._\n\nProof.: That (iii) implies (i) was proved in Example I, while the proof that (ii) implies (iii) amounts to nothing more than a careful consideration of cases. Finally, to show that (i) implies (ii) we note that \\((-\\infty,c)\\cup(c,+\\infty)\\) is a disconnection of the set \\(\\mathbb{R}\\setminus\\{c\\}\\) obtained by removing a single point \\(c\\) from \\(\\mathbb{R}\\). Hence if \\(C\\) is a connected subset of \\(\\mathbb{R}\\) that does not contain \\(c\\), then either \\(C\\subset(-\\infty,c)\\) or \\(C\\subset(c,+\\infty)\\).\n\nTo prove the last assertion of the proposition we observe that, since \\(U\\) is open, every nonopen interval that is contained in \\(U\\) is contained in an open interval contained in \\(U\\). It follows from this that the connected components of \\(U\\) are all open intervals. That no disjoint collection of nonempty open intervals can be uncountable follows from the fact that \\(\\mathbb{R}\\) satisfies the second axiom of countability. To complete the proof it suffices to observe that if \\(\\{I_{n}\\}\\) is a disjoint (countable) collection of nonempty open intervals such that \\(U=\\bigcup_{n}I_{n}\\), and if \\(V\\) is a connected component of \\(U\\) that meets some one \\(I_{n}\\), then neither endpoint of \\(I_{n}\\) can belong to \\(V\\), and therefore \\(V=I_{n}\\) (Prop. 3.6). \n\nIf \\(X\\) is a connected space and \\(f:X\\to Y\\) is a continuous mapping, then \\(f(X)\\) is a connected set in \\(Y\\). Thus, in particular, if \\(f\\) is a continuous mapping of a closed interval \\([a,b]\\) into \\(Y\\), then the range of \\(f\\) is connected in \\(Y\\). Such a mapping is called an _arc_ in \\(Y\\), and \\([a,b]\\) is the _parameter interval_ of the arc \\(f\\). If \\(f(a)=y_{0}\\) and \\(f(b)=y_{1}\\), then the arc \\(f\\) is said to _join_\\(y_{0}\\) to \\(y_{1}\\). If for every pair of points \\(y_{0}\\) and \\(y_{1}\\) in \\(Y\\) there exists an arc joining \\(y_{0}\\) to \\(y_{1}\\), then \\(Y\\) is said to be _arcwise connected_. An arcwise connected space is clearly connected.\n\n**Proposition 3.8**.: _If \\(U\\) is a connected open subset of \\(\\mathbb{R}^{n}\\), then \\(U\\) is arcwise connected._\n\nProof.: We may assume \\(U\\) to be nonempty. Let \\(x_{0}\\) be a point of \\(U\\), and denote by \\(V\\) the set of those points \\(x\\) in \\(U\\) such that there exists an arc in \\(U\\) joining \\(x_{0}\\) to \\(x\\). If \\(x\\in V\\) and if \\(W\\) is an open cell in \\(\\mathbb{R}^{n}\\) containing \\(x\\) and contained in \\(U\\) (Ex. \\(A\\)), then \\(x\\) can clearly be joined to every point of \\(W\\) by an arc in \\(W\\). Hence \\(W\\subset V\\), and it follows that \\(V\\) is an open set.\n\nSuppose now that \\(y_{0}\\in U\\cap\\partial V\\), and let \\(W_{1}\\) be an open cell containing \\(y_{0}\\) and contained in \\(U\\). Then there exists a point \\(x\\) of \\(V\\) belonging to \\(W_{1}\\), and since \\(x\\) can be joined to \\(y_{0}\\) by an arc in \\(W_{1}\\), it follows that \\(y_{0}\\in V\\), which is impossible since \\(V\\) is open. Thus \\(U\\cap\\partial V=\\emptyset\\), and therefore \\(V=U\\) by Proposition 3.6. \n\nThe structure of the most general open subset of \\(\\mathbb{R}\\) is set forth in Proposition 3.7. In the topology of the plane matters are not quite so simple,but there are some useful things that can be said. (In this discussion we speak of the complex plane \\(\\mathbb{C}\\), but the following facts are equally valid for the real plane \\(\\mathbb{R}^{2}\\), which may be identified with \\(\\mathbb{C}\\) via the standard homeomorphism \\(s+it\\mapsto(s,t)\\).) We begin by recalling that a _domain_ in \\(\\mathbb{C}\\) is a nonempty connected open subset of \\(\\mathbb{C}\\).\n\n**Proposition 3.9**.: _Every open subset \\(U\\) of \\(\\mathbb{C}\\) is uniquely expressible as a countable union of disjoint domains, and these domains are the components of \\(U\\)._\n\nProof. The empty set is the empty union of domains. If \\(U\\) is a nonempty open set in \\(\\mathbb{C}\\), and if \\(\\lambda_{0}\\) is an element of some component \\(U_{0}\\) of \\(U\\), then (Ex. A) there is an open disc \\(D_{r}(\\lambda_{0})\\) about \\(\\lambda_{0}\\) (\\(r>0\\)) such that \\(D_{r}(\\lambda_{0})\\subset U\\). Since discs are (arcwise) connected, it is clear that \\(D_{r}(\\lambda_{0})\\subset U_{0}\\), and hence that the components of \\(U\\) are open. That no collection of disjoint open sets in \\(\\mathbb{C}\\) can be uncountable is clear from the fact that \\(\\mathbb{C}\\) satisfies the second axiom of countability. To complete the proof it suffices to observe that if \\(\\{U_{n}\\}\\) is a disjoint (countable) collection of nonempty domains such that \\(U=\\bigcup_{n}U_{n}\\), and if \\(V\\) is a connected component of \\(U\\) that meets some one \\(U_{n}\\), then \\(V\\cap\\partial U_{n}=\\emptyset\\), and therefore \\(V=U_{n}\\) (Prop. 3.6). \n\nIf \\(K\\) is a compact subset of \\(\\mathbb{C}\\), then \\(K\\) is _bounded_, that is, there exists a disc \\(D_{R}(0)\\) large enough so that \\(K\\subset D_{R}(0)^{-}\\), and since \\(V=\\mathbb{C}\\setminus D_{R}(0)^{-}\\) is (arcwise) connected, it follows that \\(V\\) is entirely contained in some one of the components of \\(\\mathbb{C}\\setminus K\\). Hence all of the components of \\(\\mathbb{C}\\setminus K\\)_except this one_ are contained in \\(D_{R}(0)\\), and are therefore bounded.\n\n**Definition.** If \\(K\\) is a compact subset of \\(\\mathbb{C}\\) then there is exactly one _unbounded component_ of \\(\\mathbb{C}\\setminus K\\). The other components of \\(\\mathbb{C}\\setminus K\\) (if any) are called the _holes_ of (or in) \\(K\\).\n\n**Proposition 3.10**.: _Let \\(K\\) be a compact subset of \\(\\mathbb{C}\\), and suppose \\(L\\) is a compact subset of \\(\\mathbb{C}\\) such that \\(K\\subset L\\) and such that \\(\\partial L\\subset K\\). Then \\(L\\) consists of the union of \\(K\\) and some of the holes of \\(K\\). In particular, if \\(K\\) has no holes, then \\(L=K\\)._\n\nProof. According to Proposition 3.6 each component of \\(\\mathbb{C}\\setminus K\\) is either contained in \\(L\\) or disjoint from \\(L\\). In particular, the unbounded component of \\(\\mathbb{C}\\setminus K\\) is disjoint from \\(L\\) since \\(L\\) is bounded. \n\nIn any deep study of plane topology an important role is played by the _Jordan curve theorem_. In this connection we shall employ the following terminology.\n\n**Definition.** A _Jordan loop_ or _Jordan curve_ is an arc \\(\\gamma\\) in \\(\\mathbb{C}\\) defined on a real parameter interval \\([a,b]\\) (\\(a<b\\)) such that \\(\\gamma(a)=\\gamma(b)\\) and such that \\(\\gamma\\) is one-to-one and never equal to \\(\\gamma(a)\\) on the open interval \\((a,b)\\). It is easily seen (Prop. 3.3) that the range \\(J\\) of a Jordan loop \\(\\gamma\\) is compact and could equally well be characterized as a homeomorphic image in \\(\\mathbb{C}\\) of the unit circle. We shall also refer to the range of a Jordan loop as a _Jordan loop_ or _Jordan curve_ when that is convenient. In the event that a Jordan curve \\(J\\) is a simple polygon in \\(\\mathbb{C}\\) (as defined in elementary geometry) we say that \\(J\\) is a _Jordan polygon_.\n\nA _Jordan domain_ in \\(\\mathbb{C}\\) is a domain whose (entire) boundary consists of the union of a finite number of pairwise disjoint Jordan curves. The closure of a Jordan domain is, therefore, the union of the domain and the various Jordan curves constituting its boundary. Such a closed set is known as a _Jordan region_.\n\nThe following result is the central fact concerning the topology of the plane; an elementary proof can be found in [66; pp. 100-104].\n\n**Theorem 3.11** (Jordan Curve Theorem).: _If \\(J\\) is a Jordan curve in \\(\\mathbb{C},\\) then the open set \\(\\mathbb{C}\\setminus J\\) is the union of exactly two components, each of which is a Jordan domain having \\(J\\) for its entire boundary._\n\n**Definition**.: If \\(J\\) is the range of a Jordan loop \\(\\gamma,\\) then the bounded component of \\(\\mathbb{C}\\setminus J\\) (that is, the hole in \\(J\\)), is called the _interior_ domain of \\(J\\), and is denoted by Int(\\(\\gamma\\)) or Int(\\(J\\)). The unbounded component of \\(\\mathbb{C}\\setminus J\\) is the _exterior_ domain of \\(J\\) and is denoted by Ext(\\(\\gamma\\)) or Ext(\\(J\\)).\n\n**Proposition 3.12**.: _Let \\(U\\) be an open subset of \\(\\mathbb{C},\\) and let \\(K\\) be a compact subset of \\(U.\\) Then there exists a finite set \\(\\Delta_{1},\\)\\(\\ldots,\\)\\(\\Delta_{p}\\) of Jordan domains such that the corresponding Jordan regions \\(R_{i}=\\Delta_{i}^{-}\\) are pairwise disjoint, and such that_\n\n\\[K\\subset\\Delta_{1}\\cup\\cdots\\cup\\Delta_{p}\\quad\\text{and}\\quad R_{1}\\cup\\cdots \\cup R_{p}\\subset U.\\]\n\n_Moreover, it is possible to arrange matters so that each of the boundaries \\(\\partial\\Delta_{i}\\) is the disjoint union of a finite number of disjoint Jordan polygons._\n\nWe shall have no occasion to refer to this fact until Chapter 5. At that time, in connection with some related material, we sketch a proof of Proposition 3.12. (See Problem 5K.)\n\nUsing Proposition 3.12 together with the Jordan curve theorem, it is not difficult to determine the structure of the most general Jordan domain.\n\n**Proposition 3.13**.: _If \\(J_{1},\\ldots,J_{n}\\) are Jordan loops that are mutually exterior in pairs, that is, are so situated that \\(J_{i}\\subset\\text{Ext}(J_{j}),\\)\\(i\\neq j,\\)\\(i,j=1,\\ldots,\\)\\(n,\\) and if \\(R_{i}=(\\text{Int}(J_{i}))^{-},\\)\\(i=1,\\ldots,\\)\\(n,\\) then the complement \\(\\mathbb{C}\\setminus(R_{1}\\cup\\cdots\\cup R_{n})\\) is an unbounded Jordan domain with boundary \\(J_{1}\\cup\\cdots\\cup J_{n}.\\) Conversely, every unbounded Jordan domain is of this form. If \\(J_{0},J_{1},\\ldots,J_{n}\\) are Jordan curves such that \\(J_{1},\\ldots,J_{n}\\) are mutually exterior in pairs, and such that \\(J_{i}\\subset\\text{Int}(J_{0})\\), \\(i=1,\\ldots,n\\), and if \\(R_{i}=(\\text{Int}(J_{i}))^{-}\\), \\(i=1,\\ldots,n\\), then \\(\\text{Int}(J_{0})\\backslash(R_{1}\\cup\\cdots\\cup R_{n})\\) is a bounded Jordan domain with boundary \\(J_{0}\\cup J_{1}\\cup\\cdots\\cup J_{n}\\). Conversely, every bounded Jordan domain is of this form._", "(mmd) Homological Algebra - A Course in Homological Algebra - Hilton.mmd-nilay-davit_p247-248_mmd-FacebookAI_roberta-base.json": "_Proof_. We have to find maps \\(\\Sigma_{n}\\!:C_{n}\\!\\!\\to\\!C_{n+1}\\), \\(n\\!=\\!0,1,\\ldots\\), such that \\(d_{1}\\Sigma_{0}\\!=\\!\\tau_{0}\\) and \\(d_{n+1}\\Sigma_{n}+\\Sigma_{n-1}d_{n}\\!=\\!\\tau_{m}\\)\\(n\\!\\geq\\!1\\). Define \\(\\Sigma_{n}\\) to be the \\(\\mathfrak{g}\\)-module homomorphism given by\n\n\\[\\Sigma_{n}\\langle x_{1},\\ldots,x_{n}\\rangle=\\sum\\limits_{k\\!=\\!1}^{m}e_{k} \\langle e^{\\prime}_{k},x_{1},\\ldots,x_{n}\\rangle\\,.\\]The assertion is then proved by the following computation (\\(k\\) varies from \\(1\\) to \\(m\\); \\(i,j\\) vary from \\(1\\) to \\(n\\)):\n\n\\[(d_{n+1}\\Sigma_{n}+\\Sigma_{n-1}d_{n})\\langle x_{1},\\,\\ldots,\\,x_{n}\\rangle=\\sum \\limits_{k}e_{k}e_{k}\\cdot\\langle x_{1},\\,\\ldots,\\,x_{n}\\rangle\\]\n\n\\[+ \\sum\\limits_{i,k}\\ (-1)^{i}e_{k}x_{i}\\langle e_{k}^{\\prime},\\,x_{1},\\, \\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,x_{n}\\rangle\\] \\[+ \\sum\\limits_{i,k}\\ (-1)^{i}e_{k}\\langle[e_{k}^{\\prime},\\,x_{i}],\\,x_{1}, \\,\\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,x_{n}\\rangle\\] \\[+ \\sum\\limits_{k,i+j}\\,(-1)^{i+j}e_{k}\\langle[x_{i},\\,x_{j}],\\,e_{k} ^{\\prime},\\,x_{1},\\,\\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,\\hat{x}_{j},\\,\\ldots,\\,x_{n}\\rangle\\] \\[+ \\sum\\limits_{i,k}\\ (-1)^{i+1}x_{i}e_{k}\\langle e_{k}^{\\prime},\\,x_{1}, \\,\\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,x_{n}\\rangle\\] \\[+ \\sum\\limits_{k,i+j}\\,(-1)^{i+j}e_{k}\\langle e_{k}\\cdot,\\,[x_{i}, \\,x_{j}],\\,x_{1},\\,\\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,\\hat{x}_{j},\\,\\ldots,\\,x_{n}\\rangle\\] \\[=\\tau_{n}\\langle x_{1},\\,\\ldots,\\,x_{n}\\rangle+\\sum\\limits_{i,k}( -1)^{i}[e_{k},\\,x_{i}]\\,\\langle e_{k}^{\\prime},\\,x_{1},\\,\\ldots,\\,\\hat{x}_{i}, \\,\\ldots,\\,x_{n}\\rangle\\] \\[+ \\sum\\limits_{i,k}\\ (-1)^{i}e_{k}\\langle[e_{k}^{\\prime},\\,x_{i}],\\,x_{1}, \\,\\ldots,\\,\\hat{x}_{i},\\,\\ldots,\\,x_{n}\\rangle\\;.\\]\n\nUsing (5.2) the two latter sums cancel each other, and thus assertion (c) is proved.\n\nConsider now the map \\(t=t_{A}:A\\to A\\) and the induced map\n\n\\[t_{\\#}:H^{q}({\\mathfrak{g}},\\,A)\\to H^{q}({\\mathfrak{g}},\\,A)\\,.\\]\n\nBy the nature of \\(t_{A}\\) (see the final remark in (b)), it is clear that \\(t_{\\#}\\) may be computed as the map induced by \\(\\tau:C\\to C\\). Hence, by assertion (c), \\(t_{\\#}\\) is the zero map. On the other hand \\(t:A\\to A\\) must either be an automorphism or the zero map, since \\(A\\) is simple. But it cannot be the zero map, because the trace of the linear transformation \\(t\\) equals \\(\\sum\\limits_{i=1}^{m}\\beta(e_{i},\\,e_{i}^{\\prime})=m\\neq 0\\). Hence, it follows that \\(H^{q}({\\mathfrak{g}},\\,A)=0\\) for all \\(q\\geqq 0\\).\n\nWe do not offer exercises on this section, but we do recommend the reader to study a proof of Theorem 5.2!\n\n## 6 The two Whitehead Lemmas\n\nAgain let \\({\\mathfrak{g}}\\) be a finite dimensional Lie algebra and let \\(A\\) be a finite dimensional \\({\\mathfrak{g}}\\)-module. We prove the first Whitehead Lemma:\n\n**Proposition 6.1.**_Let \\({\\mathfrak{g}}\\) be semi-simple_, _then_\\(H^{1}({\\mathfrak{g}},\\,A)=0\\).\n\n_Proof_. Suppose there is a \\({\\mathfrak{g}}\\)-module \\(A\\) with \\(H^{1}({\\mathfrak{g}},\\,A)\\neq 0\\). Then there is such a \\({\\mathfrak{g}}\\)-module \\(A\\) with minimal \\(K\\)-dimension. If \\(A\\) is not simple, then there is a proper submodule \\(0\\neq A^{\\prime}\\subset A\\). Consider \\(0\\to A^{\\prime}\\to A\\to A/A^{\\prime}\\to 0\\)and the associated long exact cohomology sequence\n\n\\[\\cdots\\to H^{1}(\\mathfrak{g},\\,A^{\\prime})\\to H^{1}(\\mathfrak{g},\\,A)\\to H^{1}( \\mathfrak{g},\\,A/A^{\\prime})\\to\\cdots\\,.\\]\n\nSince \\(\\dim_{K}A^{\\prime}<\\dim_{K}A\\) and \\(\\dim_{K}A/A^{\\prime}<\\dim_{K}A\\) it follows that\n\n\\[H^{1}(\\mathfrak{g},\\,A^{\\prime})=H^{1}(\\mathfrak{g},\\,A/A^{\\prime})=0\\,.\\]\n\nHence \\(H^{1}(\\mathfrak{g},\\,A)=0\\), which is a contradiction. It follows that \\(A\\) has to be simple. But then \\(A\\) has to be a trivial \\(\\mathfrak{g}\\)-module by Proposition 5.6. (Indeed it has to be \\(K\\); but we make no use of this fact.) We then have \\(H^{1}(\\mathfrak{g},\\,A)\\cong\\operatorname{Hom}_{K}(\\mathfrak{g}_{ab},\\,A)\\) by Proposition 2.2. Now consider\n\n\\[[\\mathfrak{g},\\mathfrak{g}]\\to\\mathfrak{g}\\to\\mathfrak{g}_{ab}\\,.\\]\n\nBy Corollary 5.4 the ideal \\([\\mathfrak{g},\\mathfrak{g}]\\) has a complement which plainly must be isomorphic to \\(\\mathfrak{g}_{ab}\\), in particular it must be abelian. Since \\(\\mathfrak{g}\\) is semi-simple, \\(\\mathfrak{g}_{ab}=0\\). Hence \\(H^{1}(\\mathfrak{g},\\,A)\\cong\\operatorname{Hom}_{K}(\\mathfrak{g}_{ab},\\,A)=0\\), which is a contradiction. It follows that \\(H^{1}(\\mathfrak{g},\\,A)=0\\) for all \\(\\mathfrak{g}\\)-modules \\(A\\).\n\n**Theorem 6.2** (Weyl). _Every ( finite-dimensional) module \\(A\\) over a semi-simple Lie algebra \\(\\mathfrak{g}\\) is a direct sum of simple \\(\\mathfrak{g}\\)-modules._\n\n_Proof_. Using induction on the \\(K\\)-dimension of \\(A\\), we have only to show that every non-trivial submodule \\(0\\neq A^{\\prime}\\subset A\\) is a direct summand in \\(A\\). To that end we consider the short exact sequence\n\n\\[A^{\\prime}\\to A\\to A^{\\prime\\prime}\\]\n\nand the induced sequence\n\n\\[0\\to\\operatorname{Hom}_{K}(A^{\\prime\\prime},\\,A^{\\prime})\\to\\operatorname{Hom }_{K}(A,\\,A^{\\prime})\\to\\operatorname{Hom}_{K}(A^{\\prime},\\,A^{\\prime})\\to 0\\,,\\]\n\nwhich is exact since \\(K\\) is a field. We remark that each of the vector spaces in (6.2) is finite-dimensional and can be made into a \\(\\mathfrak{g}\\)-module by the following procedure. Let \\(B,C\\) be \\(\\mathfrak{g}\\)-modules; then \\(\\operatorname{Hom}_{K}(B,C)\\) is a \\(\\mathfrak{g}\\)-module by \\((xf)\\,(b)=xf(b)-f(xb)\\), \\(x\\in\\mathfrak{g}\\), \\(b\\in B\\). With this understanding, (6.2) becomes an exact sequence of \\(\\mathfrak{g}\\)-modules. Note that the invariant elements in \\(\\operatorname{Hom}_{K}(B,C)\\) are precisely the \\(\\mathfrak{g}\\)-module homomorphisms from \\(B\\) to \\(C\\). Now consider the long exact cohomology sequence arising from (6.2)\n\n\\[\\begin{split} 0\\to& H^{0}(\\mathfrak{g},\\,\\operatorname{Hom}_{K}(A^{\\prime\\prime},\\,A^{\\prime})\\to H^{0}(\\mathfrak{g},\\,\\operatorname{Hom}_{K}(A,\\,A^{\\prime}))\\\\ \\to& H^{0}(\\mathfrak{g},\\,\\operatorname{Hom}_{K}(A^{\\prime},\\,A^{\\prime}))\\to H^{1}(\\mathfrak{g},\\,\\operatorname{Hom}_{K}(A^{\\prime\\prime},\\,A^{\\prime}))\\to\\cdots\\end{split}\\]\n\nBy Proposition 6.1, \\(H^{1}(\\mathfrak{g},\\operatorname{Hom}_{K}(A^{\\prime\\prime},A^{\\prime}))\\) is trivial. Passing to the interpretation of \\(H^{0}\\) as the group of invariant elements, we obtain an epimorphism\n\n\\[\\operatorname{Hom}_{\\mathfrak{g}}(A,\\,A^{\\prime})\\to\\operatorname{Hom}_{ \\mathfrak{g}}(A^{\\prime},\\,A^{\\prime})\\,.\\]\n\nIt follows that there is a \\(\\mathfrak{g}\\)-module homomorphism \\(A\\to A^{\\prime}\\) inducing the identity in \\(A^{\\prime}\\); hence (6.1) splits.", "(mmd) Commutative Algebra - Commutative Algebra II - Zariski.mmd-nilay-hafsah-p135-136-FacebookAI_roberta-base.json": "Proof. Assume that \\(L\\) is everywhere dense in \\(S\\) and let \\(f_{q}\\) be a form, of degree \\(q\\). If \\(n\\) is an integer \\(>\\!q\\), \\(L\\) must contain an element \\(f\\) such that \\(\\mathbf{o}(f\\!-\\!f_{q})\\!\\geqq n\\) (since \\(f_{q}\\) must be the limit of a sequence of elementsof \\(L\\)). Since \\(n>q\\), the inequality \\({\\bf o}(f-f_{q})\\geq n\\) implies that \\(f_{q}\\) is the initial form of \\(f\\). Note that in this part of the proof we have not used the assumption that \\(L\\) is a subring of \\(S\\).\n\nConversely, assume that \\(L\\) has the property stated in the lemma. Let \\(f\\) be any element of \\(S\\). We shall construct an infinite sequence \\(\\{f^{i}\\}\\), \\(f^{i}\\in L\\), such that \\({\\bf o}(f-f^{i})\\geq i\\), whence \\(f=\\mathop{\\rm Lim}f^{i}\\). For \\(i=0\\) we simply set \\(f^{0}=0\\). Let us assume that we have already defined the \\(n\\) elements \\(f^{0}\\), \\(f^{1}\\), \\(\\cdot\\cdot\\cdot\\), \\(f^{n-1}\\) in \\(L\\) and that we have then \\({\\bf o}(f-f^{i})\\geq i\\) for \\(i=0\\), \\(1\\), \\(\\cdot\\cdot\\cdot\\), \\(n-1\\). If \\({\\bf o}(f-f^{n-1})\\geq n\\) we set \\(f^{n}=f^{n-1}\\). If \\({\\bf o}(f-f^{n-1})=n-1\\), let \\(g_{n-1}\\) be the initial form of \\(f-f^{n-1}\\) and let \\(h^{n-1}\\) be some element of \\(L\\) whose initial form is \\(g_{n-1}\\). If we set \\(f^{n}=f^{n-1}+h^{n-1}\\), then \\(f^{n}\\in L\\), since \\(L\\) is a subring of \\(S\\), and we have \\({\\bf o}(f-f^{n})={\\bf o}(f-f^{n-1}-h^{n-1})\\geq n\\), since both \\(f-f^{n-1}\\) and \\(h^{n-1}\\) are of order \\(n-1\\) and have the same initial form \\(g_{n-1}\\). This completes the proof of the lemma.\n\nWe have seen in Vol. I, Ch. I that in any polynomial in \\(A[X_{1},X_{2},\\ldots,\\)\\(X_{n}]\\) one can substitute for the indeterminates elements of any overring of \\(A\\) (see Vol. I, Ch. I, SS 16, end of section). This operation of substitution cannot be performed for power series without further ado since infinite sums of power series have a meaning only if their partial sums form a Cauchy sequence (hence converge, in the formal sense explained above). Consider the power series ring \\(A[[\\,Y_{1},\\,Y_{2},\\,\\cdot\\cdot\\cdot\\), \\(Y_{m}]]\\) in \\(m\\) indeterminates and \\(m\\) power series \\(f^{1}(X_{1},\\,X_{2},\\cdot\\cdot\\cdot\\), \\(X_{n})\\), \\(f^{2}(X_{1},\\,X_{2},\\cdot\\cdot\\cdot\\), \\(X_{n})\\) in \\(n\\) indeterminates, over \\(A\\). We assume that each of the \\(m\\) power series \\(f^{i}\\) is of order \\(\\geqq 1\\). Under this assumption we proceed to define \\(g(f^{1},f^{2},\\,\\cdot\\cdot\\cdot,f^{m})\\), \\(g(Y_{1},\\,Y_{2},\\,\\cdot\\cdot\\cdot\\), \\(Y_{m})\\) being any power series in \\(A[[\\,Y_{1},\\,Y_{2},\\,\\cdot\\cdot\\cdot\\), \\(Y_{m}]]\\). Let \\(g=g_{0}+g_{1}+\\cdot\\cdot\\cdot+g_{q}+\\cdot\\cdot\\cdot\\), \\(g_{q}\\) being either zero or a form of degree \\(q\\) in \\(Y_{1},\\,Y_{2},\\,\\cdot\\cdot\\cdot\\), \\(Y_{m}\\), with coefficients in \\(A\\). Then \\(g_{q}(f^{1},f^{2},\\,\\cdot\\cdot\\cdot,f^{m})\\) is defined as an element \\(\\tilde{g}^{q}\\) of \\(A[[X_{1},\\,X_{2},\\cdot\\cdot\\cdot\\cdot,X_{n}]]\\). Furthermore, by Theorem 1, \\(\\tilde{g}^{q}\\) is a power series of order \\(\\geqq\\), since \\(g_{q}\\) is a form of degree \\(q\\) and since \\({\\bf o}(f^{i})\\geqq 1\\), \\(1\\leqq i\\leq m\\). Hence the series \\(\\sum\\limits_{q}\\tilde{g}^{q}\\) is defined as an element of \\(A[[X_{1},\\,X_{2},\\,\\cdot\\cdot\\cdot\\), \\(X_{n}]]\\). This power series \\(\\sum\\limits_{q}\\tilde{g}^{q}\\) in \\(A[[X_{1},\\,X_{2},\\,\\cdot\\cdot\\cdot\\), \\(X_{n}]]\\) we call the _result of substitution of \\(f^{1},f^{2},\\,\\cdot\\cdot\\cdot\\)_\\(f^{m}\\)_ into \\(g(Y_{1},\\,Y_{2},\\cdot\\cdot\\cdot\\), \\(Y_{m})\\), or the _transform of \\(g(Y_{1},\\,Y_{2},\\,\\cdot\\cdot\\cdot\\), \\(Y_{m})\\) by the substitution \\(Y_{i}\\to f^{i}\\)_. In symbols :\n\n\\[g(f^{1},f^{2},\\,\\cdot\\cdot\\cdot,f^{m})=\\sum\\limits_{q=0}^{\\infty}g_{q}(f^{1},f^ {2},\\,\\cdot\\cdot\\cdot,f^{m})=\\sum\\limits_{q=0}^{\\infty}\\tilde{g}^{q}.\\]\n\nFor fixed \\(f^{1},f^{2},\\,\\cdot\\cdot\\cdot\\), \\(f^{m}\\), (9) defines a mapping\n\n\\[g\\to g(f^{1},f^{2},\\,\\cdot\\cdot\\cdot,f^{m}),\\ \\ g\\in A[[\\,Y_{1},\\,Y_{2},\\, \\cdot\\cdot\\cdot\\,,\\,Y_{m}]],\\]of \\(A[[Y_{1},Y_{2},\\cdots,Y_{m}]]\\) into \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\). We shall refer to (10) as the _substitution mapping_ (relative to the substitution \\(Y_{i}\\to f^{i}\\)). It follows easily from the rules (6) and (6') of addition and multiplication of infinite sums, that _the substitution mapping_ (10) _is a homomorphism_. Furthermore, the mapping (10) is _continuous_ (with respect to the topology introduced earlier in power series rings). To see this it is sufficient to show that if \\(\\mathfrak{Y}\\) denotes the ideal generated in \\(A[[Y_{1},Y_{2},\\cdots,Y_{m}]]\\) by \\(Y_{1},Y_{2},\\cdots,Y_{m}\\), then the transform of \\(\\mathfrak{Y}^{i}\\) by (10) is contained in \\(\\mathfrak{X}^{\\rho(i)}\\), where \\(\\rho(i)\\) tends to \\(\\infty\\) with \\(i\\). This, however, is obvious, since from the definition of the substitution mapping it follows that if \\(g\\in\\mathfrak{Y}^{i}\\) then \\(g(f^{1},f^{2},\\cdots,f^{m})\\) belongs to \\(\\mathfrak{X}^{i}\\).\n\nThe image of the ring \\(A[[Y_{1},Y_{2},\\cdots,Y_{m}]]\\) under the substitution mapping (10) is a subring of \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\). We shall denote this subring by \\(A[[f^{1},f^{2},\\cdots,f^{m}]]\\).\n\nIt is not difficult to see that _any continuous homomorphism \\(\\tau\\) of \\(A[[Y_{1},Y_{2},\\cdots,Y_{m}]]\\) into \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\) is a substitution mapping_. For let \\(\\tau(Y_{i})=f^{i}\\). The continuity of \\(\\tau\\) requires that high powers of \\(f^{i}\\) belong to high powers of the ideal \\(\\mathfrak{X}\\). Hence \\(f^{i}\\in\\mathfrak{X}\\), \\(i=1\\), \\(2\\), \\(\\cdots\\), \\(m\\). Now, let \\(g=g_{0}+g_{1}+\\cdots+g_{q}+\\cdots\\) be any power series in \\(Y_{1}\\), \\(Y_{2}\\), \\(\\cdots\\), \\(Y_{m}\\). Since \\(\\tau\\) is a homomorphism we have \\(\\tau(g_{q})=g_{q}(f^{1},f^{2},\\cdots,f^{m})\\) and \\(\\tau\\biggl{(}\\sum\\limits_{q=0}^{i}g_{q}\\biggr{)}=\\sum\\limits_{q=0}^{i}g_{q}(f^ {1},f^{2},\\cdots,f^{m})\\). Since \\(g=\\mathop{\\rm Lim}\\limits_{i\\to\\infty}\\biggl{(}\\sum\\limits_{q=0}^{i}g_{q} \\biggr{)}\\) and since \\(\\tau\\) is continuous, we must have\n\n\\[\\tau(g)=\\mathop{\\rm Lim}\\limits_{i\\to\\infty}\\tau\\biggl{(}\\sum\\limits_{q=0}^{i} g_{q}\\biggr{)}=\\mathop{\\rm Lim}\\limits_{i\\to\\infty}\\sum\\limits_{q=0}^{i}g_{q}(f^ {1},f^{2},\\cdots,f^{m}),\\]\n\ni.e., \\(\\tau(g)=g(f^{1},f^{2},\\cdots,f^{m})\\), in view of (9). This shows that \\(\\tau\\) is the substitution mapping relative to the substitution \\(Y_{i}\\to f^{i}\\).\n\nIn the special case \\(m=n\\), the two rings \\(A[[Y_{1},Y_{2},\\cdots,Y_{m}]]\\) and \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\) coincide and we have \\(Y_{i}=X_{i}\\). In this case, our substitution mapping defines a continuous homomorphism of the power series ring \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\) into itself. We now describe a case in which this homomorphism is an automorphism.\n\nLemma 2. Let \\(f^{1},f^{2},\\cdots,f^{n}\\) be \\(n\\) power series in \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\) such that the initial form of \\(f^{i}\\) is \\(X_{i}\\)\\((1\\leq i\\leq n)\\). Then the substitution mapping \\(\\varphi\\colon g(X_{1},X_{2},\\cdots,X_{n})\\to g(f^{1},f^{2},\\cdots,f^{n})\\) is an automorphism of the power series ring \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\).\n\nproof. We first show that the kernel of \\(\\varphi\\) is zero. Let \\(g\\) be a non-zero power series in \\(A[[X_{1},X_{2},\\cdots,X_{n}]]\\) and let \\(g_{s}\\) be its initial form. From (9) we find at once that \\(g(f^{1},f^{2},\\cdots,f^{n})-g_{s}\\in\\mathfrak{X}^{i+1}\\)", "(mmd) Number Theory - Number Theory - An Introduction to Mathematics - Coppel.mmd-nilay-laurel-p357-358-FacebookAI_roberta-base.json": "For otherwise there would exist a sequence \\(\\Lambda_{k}\\) of lattices in \\(\\mathcal{F}\\) such that either \\(m(\\Lambda_{k})\\to 0\\) or \\(\\mathrm{d}(\\Lambda_{k})\\to\\infty\\), and clearly this sequence could have no convergent subsequence.\n\nWe now prove the fundamental _compactness theorem_ of Mahler (1946), which says that this necessary condition on \\(\\mathcal{F}\\) is also sufficient.\n\n**Proposition 22**: _If \\(\\{\\Lambda_{k}\\}\\) is a sequence of lattices in \\(\\mathbb{R}^{n}\\) such that_\n\n\\[m(\\Lambda_{k})\\geq\\rho^{2},\\ \\mathrm{d}(\\Lambda_{k})\\leq\\sigma\\quad\\text{for all $k$},\\]\n\n_where \\(\\rho,\\sigma\\) are positive constants, then the sequence \\(\\{\\Lambda_{k}\\}\\) certainly has a convergent subsequence._\n\n_Proof_ Let \\(V_{k}\\) denote the Voronoi cell of \\(\\Lambda_{k}\\). We show first that the ball \\(B_{\\rho/2}=\\{x\\in\\mathbb{R}^{n}:\\|x\\|\\leq\\rho/2\\}\\) is contained in every Voronoi cell \\(V_{k}\\). In fact if \\(\\|x\\|\\leq\\rho/2\\) then, for every nonzero \\(y\\in\\Lambda_{k}\\),\n\n\\[\\|x-y\\|\\geq\\|y\\|-\\|x\\|\\geq\\rho-\\rho/2=\\rho/2\\geq\\|x\\|,\\]\n\nand hence \\(x\\in V_{k}\\).\n\nLet \\(v_{k}\\) be a point of \\(V_{k}\\) which is furthest from the origin. Then \\(V_{k}\\) contains the convex hull \\(C_{k}\\) of the set \\(v_{k}\\cup B_{\\rho/2}\\). Since the volume of \\(V_{k}\\) is bounded above by \\(\\sigma\\), so also is the volume of \\(C_{k}\\). But this implies that the sequence \\(v_{k}\\) is bounded. Thus there exists \\(R>0\\) such that the ball \\(B_{R}\\) contains every Voronoi cell \\(V_{k}\\).\n\nBy Blaschke's selection principle, the sequence \\(\\{V_{k}\\}\\) has a subsequence \\(\\{V_{k_{v}}\\}\\) which converges in the Hausdorff metric to a compact convex set \\(V\\). Since \\(B_{\\rho/2}\\subseteq V\\), it follows from Proposition 20 that \\(\\Lambda_{k_{v}}\\to\\Lambda\\), where \\(\\Lambda\\) is a lattice with Voronoi cell \\(V\\). \\(\\Box\\)\n\nTo illustrate the utility of Mahler's compactness theorem, we now show that, as stated in Section 3, any compact symmetric convex set \\(K\\) with nonempty interior has a critical lattice.\n\nBy the definition of the critical determinant \\(\\Delta(K)\\), there exists a sequence \\(\\Lambda_{k}\\) of lattices with no nonzero points in the interior of \\(K\\) such that \\(\\mathrm{d}(\\Lambda_{k})\\to\\Delta(K)\\) as \\(k\\to\\infty\\). Since \\(K\\) contains a ball \\(B_{\\rho}\\) with radius \\(\\rho>0\\), we have \\(m(\\Lambda_{k})\\geq\\rho^{2}\\) for all \\(k\\). Hence, by Proposition 22, there is a subsequence \\(\\Lambda_{k_{v}}\\) which converges to a lattice \\(\\Lambda\\) as \\(v\\to\\infty\\). Since every point of \\(\\Lambda\\) is a limit of points of \\(\\Lambda_{k_{v}}\\), no nonzero point of \\(\\Lambda\\) lies in the interior of \\(K\\). Furthermore,\n\n\\[\\mathrm{d}(\\Lambda)=\\lim_{v\\to\\infty}\\mathrm{d}(\\Lambda_{k_{v}})=\\Delta(K),\\]\n\nand hence \\(\\Lambda\\) is a critical lattice for \\(K\\).\n\n## 7 Further Remarks\n\nThe geometry of numbers is treated more extensively in Cassels [11], Erdos _et al._[22] and Gruber and Lekkerkerker [27]. Minkowski's own account is available in [42].\n\nNumerous references to the earlier literature are given in Keller [34]. Lagarias [36] gives an overview of lattice theory. For a simple proof that the indicator function of a convex set is Riemann integrable, see Szabo [57].\n\nDiophantine approximation is studied in Cassels [12], Koksma [35] and Schmidt [50]. Minkowski's result that the discriminant of an algebraic number field other than \\(\\mathbb{Q}\\) has absolute value greater than 1 is proved in Narkiewicz [44], for example.\n\nMinkowski's theorem on successive minima is proved in Bambah _et al._[3]. For the results of Banaszczyk mentioned in SS3, see [4] and [5]. Sharp forms of Siegel's lemma are proved not only in Bombieri and Vaaler [7], but also in Matveev [40]. The result of Gillet and Soule appeared in [25]. Some interesting results and conjectures concerning the product \\(\\lambda(K)\\lambda(K^{*})\\) are described on pp. 425-427 of Schneider [51].\n\nAn algorithm of Lovasz, which first appeared in Lenstra, Lenstra and Lovasz [38], produces in finitely many steps a basis for a lattice \\(\\Lambda\\) in \\(\\mathbb{R}^{n}\\) which is'reduced'. Although the first vector of a reduced basis is in general not a minimal vector, it has square-norm at most \\(2^{n-1}m(\\Lambda)\\). This suffices for many applications and the algorithm has been used to solve a number of apparently unrelated computational problems, such as factoring polynomials in \\(\\mathbb{Q}[t]\\), integer linear programming and simultaneous Diophantine approximation. There is an account of the basis reduction algorithm in Schrijver [52]. The algorithmic geometry of numbers is surveyed in Kannan [33].\n\nMahler [39] has established an analogue of the geometry of numbers for formal Laurent series with coefficients from an arbitrary field \\(F\\), the roles of \\(\\mathbb{Z}\\), \\(\\mathbb{Q}\\) and \\(\\mathbb{R}\\) being taken by \\(F[t]\\), \\(F(t)\\) and \\(F((t))\\). In particular, Eichler [19] has shown that the Riemann-Roch theorem for algebraic functions may be thus derived by geometry of numbers arguments.\n\nThere is also a generalization of Minkowski's lattice point theorem to locally compact groups, with Haar measure taking the place of volume; see Chapter 2 (Lemma 1) of Weil [60].\n\nVoronoi _diagrams_ and their uses are surveyed in Aurenhammer [1]. Proofs of the basic properties of polytopes referred to in SS4 may be found in Brondsted [9] and Coppel [15]. Planar tilings are studied in detail in Grunbaum and Shephard [28].\n\nMathematical crystallography is treated in Schwarzenberger [53] and Engel [21]. For the physicist's point of view, see Burckhardt [10], Janssen [32] and Birman [6]. There is much theoretical information, in addition to tables, in [31].\n\nFor Bieberbach's theorems, see Vince [59], Charlap [13] and Milnor [41]. Various equivalent forms for the definitions of crystal and crystallographic group are given in Dolbilin _et al._[17]. It is shown in Charlap [13] that crystallographic groups may be abstractly characterized as groups containing a finitely generated maximal abelian torsion-free subgroup of finite index. (An abelian group is _torsion-free_ if only the identity element has finite order.) The fundamental group of a compact flat Riemannian manifold is a torsion-free crystallographic group and all torsion-free crystallographic groups may be obtained in this way. For these connections with differential geometry, see Wolf [61] and Charlap [13].\n\nIn more than 4 dimensions the complete enumeration of all crystallographic groups is no longer practicable. However, algorithms for deciding if two crystallographic groups are equivalent in some sense have been developed by Opgenorth _et al._[45].", "(mmd) All the Mathematics You Missed - Garrity.mmd-nilay-hafsah-p225-FacebookAI_roberta-base.json": "Here is a rapid fire summary of Galois Theory. We will associate to each one variable polynomial with rational coefficients a unique finite dimensional vector space over the rational numbers that is also a field extension of the rational numbers contained in the complex numbers. Namely, if \\(\\alpha_{1},\\ldots,\\alpha_{n}\\) are the roots of the polynomial \\(P(x)\\), the smallest field in the complex numbers that contains both the rationals and the roots \\(\\alpha_{1},\\ldots,\\alpha_{n}\\) is the desired vector space. We then look at all linear transformations from this vector space to itself, with the strong restriction that the linear transformation is also a field automorphism mapping each rational number toitself. This is such a strong restriction that there are only a finite number of such transformations, forming a finite group. Further, each such linear transformation will not only map each root of \\(P(x)\\) to another root but is actually determined by how it maps the roots to each other. Thus the finite group of these special linear transformations are a subgroup of the permutation group on \\(n\\) letters. The final deep result lies in showing that these finite groups determine properties about the roots.\n\nNow for some details. We assume that \\(P(x)\\) is irreducible in \\({\\bf Q}[x]\\), meaning that \\(P(x)\\) is not the product of any polynomials in \\({\\bf Q}[x]\\). Hence none of the roots \\(\\alpha_{i}\\) of \\(P(x)\\) can be rational numbers.\n\n**Definition 11.4.3**: _Let \\({\\bf Q}(\\alpha_{1},\\ldots,\\alpha_{n})\\) be the smallest subfield of \\({\\bf C}\\) containing both \\({\\bf Q}\\) and the roots \\(\\alpha_{1},\\ldots,\\alpha_{n}\\)._\n\n**Definition 11.4.4**: _Let \\(E\\) be a field extension of \\({\\bf Q}\\) but contained in \\({\\bf C}\\). We say \\(E\\) is a splitting field if there is a polynomial \\(P(x)\\in{\\bf Q}[x]\\) such that \\(E={\\bf Q}(\\alpha_{1},\\ldots,\\alpha_{n})\\), where \\(\\alpha_{1},\\ldots,\\alpha_{n}\\) are the roots in \\({\\bf C}\\) of \\(P(x)\\)._\n\nA splitting field \\(E\\) over the rational numbers \\({\\bf Q}\\) is in actual fact a vector space over \\({\\bf Q}\\). For example, the splitting field \\({\\bf Q}(\\sqrt{2})\\) is a two-dimensional vector space, since any element can be written uniquely as \\(a+b\\sqrt{2}\\), with \\(a,b\\in{\\bf Q}\\).\n\n**Definition 11.4.5**: _Let \\(E\\) be an extension field of \\({\\bf Q}\\). The group of automorphisms \\(G\\) of \\(E\\) over \\({\\bf Q}\\) is the set of all field automorphisms \\(\\sigma:E\\to E\\)._\n\nBy _field automorphism_ we mean a ring homomorphism from the field \\(E\\) to itself that is one-to-one, onto, maps unit to unit and whose inverse is a ring homomorphism. Note that field automorphisms of an extension field have the property that each rational number is mapped to itself (this is an exercise at the end of the chapter).\n\nSuch field automorphisms can be interpreted as linear transformations of \\(E\\) to itself. But not all linear transformations are field automorphisms, as will be seen in a moment.\n\nOf course, there is needed here, in a complete treatment, a lemma showing that this set of automorphisms actually forms a group.\n\n**Definition 11.4.6**: _Given an extension field \\(E\\) over \\({\\bf Q}\\) with group of automorphisms \\(G\\), the fixed field of \\(G\\) is the set \\(\\{e\\in E:\\sigma(e)=e\\), for all \\(\\sigma\\in G\\}\\)._\n\nNote that we are restricting attention to those field automorphisms that contain \\({\\bf Q}\\) in the fixed field. Further it can be shown that the fixed field is indeed a subfield of \\(E\\).", "(mmd) Complex Manifolds - Differential Analysis on Complex Manifolds - Wells.mmd-nilay-victoria-p73-75-FacebookAI_roberta-base.json": "then\n\n\\[D(e^{\\prime}_{\\sigma}) =\\sum_{v}\\theta_{v\\sigma}(fg)e^{\\prime}_{v}\\] \\[=\\sum_{v,\\rho}\\theta_{v\\sigma}(fg)g_{\\rho v}e_{\\rho},\\]\n\nand, on the other hand,\n\n\\[D\\big{(}\\sum_{\\rho}g_{\\rho\\sigma}e_{\\rho}\\big{)}=\\sum_{\\rho}dg_{\\rho\\sigma}e_{ \\rho}+\\sum_{\\rho,\\tau}g_{\\rho\\sigma}\\theta_{\\tau\\rho}e_{\\tau}.\\]\n\nBy comparing coefficients, we obtain\n\n\\[g\\theta(fg)=dg+\\theta(f)g. \\tag{1.15}\\]\n\nTake the exterior derivative of the matrix equation (1.15), obtaining\n\n\\[d\\theta(f)\\cdot g-\\theta(f)\\cdot dg=dg\\cdot\\theta(fg)+g\\cdot d\\theta(fg). \\tag{1.16}\\]\n\nAlso,\n\n\\[\\theta(fg)=g^{-1}dg+g^{-1}\\theta(f)g, \\tag{1.17}\\]\n\nand thus we obtain by substituting (1.17) into (1.16) an algebraic expression for \\(gd\\theta(fg)\\) in terms of the quantities \\(d\\theta(f),\\theta(f),dg,\\,g\\), and \\(g^{-1}\\). Then we can write\n\n\\[g[d\\theta(fg)+\\theta(fg)\\wedge\\theta(fg)] \\tag{1.18}\\]\n\nin terms of these same quantities Writing this out and simplifying, we find that (1.18) is the same as\n\n\\[[d\\theta(f)+\\theta(f)\\wedge\\theta(f)]g,\\]\n\nwhich proves part (b).\n\nQ.E.D.\n\n**Lemma 1.7:** \\([d+\\theta(f)][d+\\theta(f)]\\xi(f)=\\mathbf{\\Theta}(f)\\xi(f)\\)_._\n\n_Proof:_ By straightforward computation we have (deleting the notational dependence on \\(f\\))\n\n\\[(d+\\theta)(d+\\theta)\\xi =d^{2}\\xi+\\theta\\cdot d\\xi+d(\\theta\\cdot\\xi)+\\theta\\wedge\\theta\\cdot\\xi\\] \\[=\\theta\\cdot d\\xi+d\\theta\\cdot\\xi-\\theta\\cdot d\\xi+\\theta\\wedge \\theta\\cdot\\xi\\] \\[=d\\theta\\cdot\\xi+\\theta\\wedge\\theta\\cdot\\xi\\] \\[=\\mathbf{\\Theta}\\cdot\\xi.\\]\n\nQ.E.D.\n\nThe proof of the above lemma illustrates why we have taken care to see that the abstract operations and equations at the section level correspond, with respect to a local frame, to matrix operations and equations.\n\nWe now make the following definition.\n\n**Definition 1.8:** Let \\(D\\) be a connection in a vector bundle \\(E\\longrightarrow X\\). Then the _curvature_\\(\\mathbf{\\Theta}_{E}(D)\\) is defined to be that element \\(\\mathbf{\\Theta}\\in\\mathcal{E}^{2}(X,\\operatorname{Hom}(E,E))\\) such that the \\(\\mathbf{C}\\)-linear mapping\n\n\\[\\mathbf{\\Theta}:\\mathcal{E}(X,E)\\longrightarrow\\mathcal{E}^{2}(X,E)\\]\n\nhas the representation with respect to a frame\n\n\\[\\mathbf{\\Theta}(f)=\\mathbf{\\Theta}(D,f)=d\\theta(f)+\\theta(f)\\wedge\\theta(f).\\]\n\nWe see by Lemma 1.6(b) that \\(\\mathbf{\\Theta}_{E}(D)\\) is well defined, since \\(\\mathbf{\\Theta}(D,f)\\) satisfies the transformation property (1.13), which ensures that \\(\\mathbf{\\Theta}(D,f)\\) determines a global element in \\(\\mathcal{E}^{2}(X,\\operatorname{Hom}(E,E))\\).\n\n_Remark:_ It follows from the local definition of \\(\\mathbf{\\Theta}_{E}(D)\\) that the curvature is an \\(\\mathcal{E}(X)\\)-linear mapping\n\n\\[\\mathbf{\\Theta}:\\mathcal{E}(X,E)\\longrightarrow\\mathcal{E}^{2}(X,E),\\]\n\nand it is this linearity property that makes \\(\\mathbf{\\Theta}\\) into a tensor in the classical sense. Note that the transformation formula for \\(\\theta(f)\\) involves derivatives of the change of frames and that of course the connection \\(D\\) is not \\(\\mathcal{E}(X)\\)-linear. If we denote by \\(D_{z}\\xi\\) the natural contraction of \\(Z\\otimes D\\xi\\) for \\(Z\\in T(X)\\) and \\(\\xi\\in\\mathcal{E}(X,E)\\), then the classical curvature tensor \\(R(Z,W)=D_{Z}D_{W}-D_{W}D_{Z}-D_{[Z,W]}\\) defined from this affine connection agrees with \\(\\mathbf{\\Theta}(Z,W)\\in\\mathcal{E}(X,\\operatorname{Hom}(E,E))\\). This follows by an exterior algebra computation and (1.14), since for a frame \\(f\\) over \\(U,D\\xi(f)=d\\xi(f)+\\theta(f)\\wedge\\xi(f)\\) implies\n\n\\[D_{Z}\\xi(f)=Z\\xi(f)+\\theta(f)(Z)\\xi(f).\\]\n\nWe can now define the action of \\(D\\) on higher-order differential forms by setting\n\n\\[D\\xi(f)=d\\xi(f)+\\theta(f)\\wedge\\xi(f),\\]\n\nwhere \\(\\xi\\in\\mathcal{E}^{p}(X,E)\\). Thus\n\n\\[D:\\mathcal{E}^{p}(X,E)\\longrightarrow\\mathcal{E}^{p+1}(X,E)\\]\n\nif it is well defined. But we only have to check whether the image satisfies the transformation law (1.3') in order to see that the image of \\(D\\) is a well-defined \\(E\\)-valued \\((p+1)\\)-form. To check this, we see that\n\n\\[g[d\\xi(fg)+\\theta(fg)\\xi(fg)] =d(g\\xi(fg))-dg\\cdot\\xi(fg)\\] \\[\\qquad+[dg+\\theta(f)g]\\wedge g^{-1}\\xi(f)\\]\n\nfrom (1.3) and Lemma 1.6(a), which reduces to\n\n\\[d\\xi(f)+\\theta(f)\\wedge\\xi(f).\\]\n\nThus we have the extension of \\(D\\) to differential forms (\\(E\\)-valued) of higher order. This extension is known as _covariant differentiation_, and we have proved the following.\n\n**Proposition 1.9:**\\(D^{2}=\\mathbf{\\Theta}\\), as an operator mapping\n\n\\[\\mathcal{E}^{p}(X,E)\\longrightarrow\\mathcal{E}^{p+2}(X,E),\\ \\text{ where }\\ D^{2}=D\\circ D.\\]The only unproved part is for \\(p>0\\), but we observe that Lemma 1.7 is still valid in this case. Then the curvature is the obstruction to \\(D^{2}=0\\) and is therefore the obstruction that the sequence\n\n\\[\\mathcal{E}(X,\\,E){\\buildrel D\\over{\\longrightarrow}}\\mathcal{E}^{1}(X,\\,E){ \\buildrel D\\over{\\longrightarrow}}\\mathcal{E}^{2}(X,\\,E)\\longrightarrow\\cdots\\longrightarrow\\]\n\nbe a _complex_ (cf. Sec. 5 in Chap. IV).\n\nThe differential forms \\(\\mathcal{E}^{p}(X,\\,\\mbox{\\rm Hom}(E,\\,E))\\) are locally matrices of \\(p\\)-forms. We want to use this fact to define a Lie product on the algebra\n\n\\[\\mathcal{E}^{*}(X,\\mbox{\\rm Hom}(E,\\,E))=\\sum_{p}\\mathcal{E}^{p}(X,\\,\\mbox{\\rm Hom }(E,\\,E)).\\]\n\nWe proceed as follows. If \\(\\chi\\in\\mathcal{E}^{p}(X,\\,\\mbox{\\rm Hom}(E,\\,E))\\) and \\(f\\) is a frame for \\(E\\) over the open set \\(U\\), then we have seen before that\n\n\\[\\chi(f)\\in\\mathfrak{M}_{r}\\otimes_{\\mathbb{C}}\\mathcal{E}^{p}(U),\\]\n\nand thus if \\(\\psi\\in\\mathcal{E}^{q}(X,\\,\\mbox{\\rm Hom}(E,\\,E))\\), we define\n\n\\[[\\chi(f),\\,\\psi(f)]=\\chi(f)\\wedge\\psi(f)-(-1)^{pq}\\psi(f)\\wedge\\chi(f), \\tag{1.19}\\]\n\nwhere the right-hand side is matrix multiplication. If \\(g\\) is a change of frame, then by (1.13) we have\n\n\\[\\chi(fg)=g^{-1}\\chi(f)g\\]\n\n\\[\\psi(fg)=g^{-1}\\psi(f)g,\\]\n\nand thus\n\n\\[[\\chi(fg),\\,\\psi(fg)]=g^{-1}[\\chi(f),\\,\\psi(f)]g\\]\n\nby a straightforward substitution. Therefore the Lie bracket is well defined on \\(\\mathcal{E}^{*}(\\chi,\\,\\mbox{\\rm Hom}(E,\\,E))\\) and satisfies the Jacobi identity, making \\(\\mathcal{E}^{*}(X,\\,\\mbox{\\rm Hom}(E,\\,E))\\) into a Lie algebra (cf., e.g., Helgason [1]).\n\nSuppose that \\(E\\) is equipped with a connection \\(D\\) and that we let \\(\\theta(f),\\,\\Theta(f)\\) be the local connection and curvature forms with respect to some frame \\(f\\). Then we can prove a version of the _Bianchi identity_ in this context, for which we shall have use later.\n\n**Proposition 1.10:**\\(d\\,\\Theta(f)=[\\Theta(f),\\theta(f)]\\)_._\n\n_Proof:_ Letting \\(\\theta=\\theta(f)\\) and \\(\\Theta=\\Theta(f)\\), we have\n\n\\[\\Theta=d\\theta+\\theta\\wedge\\theta,\\]\n\nand thus\n\n\\[d\\Theta=d^{2}\\theta+d\\theta\\wedge\\theta-\\theta\\wedge d\\theta\\]\n\n\\[=d\\theta\\wedge\\theta-\\theta\\wedge d\\theta.\\]\n\nBut\n\n\\[[\\Theta,\\theta]=[d\\theta+\\theta\\wedge\\theta,\\theta]\\]\n\n\\[=d\\theta\\wedge\\theta+\\theta\\wedge\\theta\\wedge\\theta\\]\n\n\\[\\phantom{=}-(-1)^{2,1}(\\theta\\wedge d\\theta+\\theta\\wedge\\theta\\wedge\\theta)\\]\n\n\\[=d\\theta\\wedge\\theta-\\theta\\wedge d\\theta.\\]\n\nQ.E.D.", "(mmd) Number Theory - Number Theory - An Introduction to Mathematics - Coppel.mmd-nilay-laurel-p60-61-FacebookAI_roberta-base.json": "subgroup _generated_ by \\(S\\). Clearly \\(S\\subseteq\\langle S\\rangle\\) and \\(\\langle S\\rangle\\) is contained in every subgroup of \\(G\\) which contains \\(S\\).\n\nTwo elements \\(a\\), \\(b\\) of a group \\(G\\) are said to be _conjugate_ if \\(b=x^{-1}ax\\) for some \\(x\\in G\\). It is easy to see that conjugacy is an equivalence relation. For \\(a=a^{-1}aa\\), if \\(b=x^{-1}ax\\) then \\(a=(x^{-1})^{-1}bx^{-1}\\), and \\(b=x^{-1}ax,c=y^{-1}by\\) together imply \\(c=(xy)^{-1}axy\\). Consequently \\(G\\) may be partitioned into _conjugacy classes_, so that two elements of \\(G\\) are conjugate if and only if they belong to the same conjugacy class.\n\nFor any element \\(a\\) of a group \\(G\\), the set \\(N_{a}\\) of all elements of \\(G\\) which commute with \\(a\\),\n\n\\[N_{a}=\\{x\\in G\\colon xa=ax\\},\\]\n\nis closed under multiplication and inversion. Thus \\(N_{a}\\) is a subgroup of \\(G\\), called the _centralizer_ of \\(a\\) in \\(G\\).\n\nIf \\(y\\) and \\(z\\) lie in the same right coset of \\(N_{a}\\), so that \\(z=xy\\) for some \\(x\\in N_{a}\\), then \\(zy^{-1}a=azy^{-1}\\) and hence \\(y^{-1}ay=z^{-1}az\\). Conversely, if \\(y^{-1}ay=z^{-1}az\\), then \\(y\\) and \\(z\\) lie in the same right coset of \\(N_{a}\\). If \\(G\\) is finite, it follows that the number of elements in the conjugacy class containing \\(a\\) is equal to the number of right cosets of the subgroup \\(N_{a}\\), i.e. to the _index_ of the subgroup \\(N_{a}\\) in \\(G\\), and hence it divides the order of \\(G\\).\n\nTo conclude, we mention a simple way of creating new groups from given ones. Let \\(G\\), \\(G^{\\prime}\\) be groups and let \\(G\\times G^{\\prime}\\) be the set of all ordered pairs \\((a,a^{\\prime})\\) with \\(a\\in G\\) and \\(a^{\\prime}\\in G^{\\prime}\\). Then \\(G\\times G^{\\prime}\\) acquires the structure of a group if we define the product \\((a,a^{\\prime})\\cdot(b,b^{\\prime})\\) of \\((a,a^{\\prime})\\) and \\((b,b^{\\prime})\\) to be \\((ab,a^{\\prime}b^{\\prime})\\). Multiplication is clearly associative, \\((e,e^{\\prime})\\) is an identity element and \\((a^{-1},a^{\\prime-1})\\) is an inverse for \\((a,a^{\\prime})\\). The group thus constructed is called the _direct product_ of \\(G\\) and \\(G^{\\prime}\\), and is again denoted by \\(G\\times G^{\\prime}\\).\n\n## 8 Rings and Fields\n\nA nonempty set \\(R\\) is said to be a _ring_ if two binary operations, \\(+\\) (addition) and \\(\\cdot\\) (multiplication), are defined with the properties\n\n1. \\(R\\) is a commutative group under addition, with \\(0\\) (_zero_) as identity element and \\(-a\\) as inverse of \\(a\\);\n2. multiplication is associative: \\((ab)c=a(bc)\\) for all \\(a\\), \\(b\\), \\(c\\in R\\);\n3. there exists an identity element \\(1\\) (_one_) for multiplication: \\(a1=a=1a\\) for every \\(a\\in R\\);\n4. addition and multiplication are connected by the two distributive laws: \\[(a+b)c=(ac)+(bc),\\quad c(a+b)=(ca)+(cb)\\quad\\text{for all $a$, $b$, $c\\in R$}.\\]\n\nThe elements \\(0\\) and \\(1\\) are necessarily uniquely determined. If, in addition, multiplication is commutative:\n\n\\[ab=ba\\quad\\text{for all $a$, $b\\in R$},\\]\n\nthen \\(R\\) is said to be a _commutative_ ring. In a commutative ring either one of the two distributive laws implies the other.\n\nIt may seem inconsistent to require that addition is commutative, but not multiplication. However, the commutative law for addition is actually a consequence of the other axioms for a ring. For, by the first distributive law we have\n\n\\[(a+b)(1+1)=a(1+1)+b(1+1)=a+a+b+b,\\]\n\nand by the second distributive law\n\n\\[(a+b)(1+1)=(a+b)1+(a+b)1=a+b+a+b.\\]\n\nSince a ring is a group under addition, by comparing these two relations we obtain first\n\n\\[a+a+b=a+b+a\\]\n\nand then \\(a+b=b+a\\).\n\nAs examples, the set \\(\\mathbb{Z}\\) of all integers is a commutative ring, with the usual definitions of addition and multiplication, whereas if \\(n\\,>\\,1\\), the set \\(M_{n}(\\mathbb{Z})\\) of all \\(n\\,\\times\\,n\\) matrices with entries from \\(\\mathbb{Z}\\) is a noncommutative ring, with the usual definitions of matrix addition and multiplication.\n\nA very different example is the collection \\(\\mathcal{P}(X)\\) of all subsets of a given set \\(X\\). If we define the sum \\(A\\,+\\,B\\) of two subsets \\(A\\), \\(B\\) of \\(X\\) to be their _symmetric difference_, i.e. the set of all elements of \\(X\\) which are in either \\(A\\) or \\(B\\), but not in both:\n\n\\[A\\,+\\,B\\,=\\,(A\\cup B)\\backslash(A\\cap B)\\,=\\,(A\\cup B)\\cap(A^{\\rm c}\\cup B^{ \\rm c}),\\]\n\nand the product \\(AB\\) to be the set of all elements of \\(X\\) which are in both \\(A\\) and \\(B\\):\n\n\\[AB\\,=\\,A\\,\\cap\\,B,\\]\n\nit is not difficult to verify that \\(\\mathcal{P}(X)\\) is a commutative ring, with the empty set \\(\\emptyset\\) as identity element for addition and the whole set \\(X\\) as identity element for multiplication. For every \\(A\\,\\in\\mathcal{P}(X)\\), we also have\n\n\\[A\\,+\\,A\\,=\\emptyset,\\quad AA\\,=\\,A.\\]\n\nThe set operations are in turn determined by the ring operations:\n\n\\[A\\,\\cup\\,B\\,=\\,A\\,+\\,B\\,+\\,AB,\\quad A\\,\\cap\\,B\\,=\\,AB,\\quad A^{\\rm c}\\,=\\,A\\,+\\,X.\\]\n\nA ring \\(R\\) is said to be a _Boolean ring_ if \\(aa\\,=\\,a\\) for every \\(a\\,\\in\\,R\\). It follows that \\(a\\,+\\,a\\,=\\,0\\) for every \\(a\\,\\in\\,R\\), since\n\n\\[a\\,+\\,a\\,=\\,(a+a)(a+a)=a+a+a+a.\\]\n\nMoreover, a Boolean ring is commutative, since\n\n\\[a\\,+\\,b\\,=\\,(a+b)(a+b)=a+b+ab+ba\\]\n\nand \\(ba\\,=\\,-ba\\), by what we have already proved.\n\nFor an arbitrary set \\(X\\), any nonempty subset of \\(\\mathcal{P}(X)\\) which is closed under union, intersection and complementation can be given the structure of a Boolean ring in the", "(mmd) A Term of Commutative Algebra - Altman.mmd-victoriacochran-victoria-p18-FacebookAI_roberta-base.json": "## 3 Radicals\n\nTwo radicals of a ring are commonly used in Commutative Algebra: the Jacobson radical, which is the intersection of all maximal ideals, and the nilradical, which is the set of all nilpotent elements. Closely related to the nilradical is the radical of a subset. We define these three radicals, and discuss examples. In particular, we study local rings; a local ring has only one maximal ideal, which is then its Jacobson radical. We prove two important general results: _Prime Avoidance_, which states that, if an ideal lies in a finite union of primes, then it lies in one of them, and the _Scheinnullstellensatz_, which states that the nilradical of an ideal is equal to the intersection of all the prime ideals containing it.\n\n### Text\n\n**Definition (3.1)**.: Let \\(R\\) be a ring. Its (Jacobson) **radical**\\(\\operatorname{rad}(R)\\) is defined to be the intersection of all its maximal ideals.\n\n**Proposition (3.2)**.: _Let \\(R\\) be a ring, \\(\\mathfrak{a}\\) an ideal, \\(x\\in R\\), and \\(u\\in R^{\\times}\\). Then \\(x\\in\\operatorname{rad}(R)\\) if and only if \\(u-xy\\in R^{\\times}\\) for all \\(y\\in R\\). In particular, the sum of an element of \\(\\operatorname{rad}(R)\\) and a unit is a unit, and \\(\\mathfrak{a}\\subset\\operatorname{rad}(R)\\) if \\(1-\\mathfrak{a}\\subset R^{\\times}\\)._\n\n**Proof:** Assume \\(x\\in\\operatorname{rad}(R)\\). Given a maximal ideal \\(\\mathfrak{m}\\), suppose \\(u-xy\\in\\mathfrak{m}\\). Since \\(x\\in\\mathfrak{m}\\) too, also \\(u\\in\\mathfrak{m}\\), a contradiction. Thus \\(u-xy\\) is a unit by **(2.22)**. In particular, taking \\(y:=-1\\) yields \\(u+x\\in R^{\\times}\\).\n\nConversely, assume \\(x\\notin\\operatorname{rad}(R)\\). Then there is a maximal ideal \\(\\mathfrak{m}\\) with \\(x\\notin\\mathfrak{m}\\). So \\(\\langle x\\rangle+\\mathfrak{m}=R\\). Hence there exist \\(y\\in R\\) and \\(m\\in\\mathfrak{m}\\) such that \\(xy+m=u\\). Then \\(u-xy=m\\in\\mathfrak{m}\\). So \\(u-xy\\) is not a unit by **(2.22)**, or directly by **(1.4)**.\n\nIn particular, given \\(y\\in R\\), set \\(a:=u^{-1}xy\\). Then \\(u-xy=u(1-a)\\in R^{\\times}\\) if \\(1-a\\in R^{\\times}\\). Also \\(a\\in\\mathfrak{a}\\) if \\(x\\in\\mathfrak{a}\\). Thus the first assertion implies the last. \\(\\square\\)\n\n**Corollary (3.3)**.: _Let \\(R\\) be a ring, \\(\\mathfrak{a}\\) an ideal, \\(\\kappa\\colon R\\to R/\\mathfrak{a}\\) the quotient map. Assume \\(\\mathfrak{a}\\subset\\operatorname{rad}(R)\\). Then \\(\\operatorname{Idem}(\\kappa)\\) is injective._\n\n**Proof:** Given \\(e,e^{\\prime}\\in\\operatorname{Idem}(R)\\) with \\(\\kappa(e)=\\kappa(e^{\\prime})\\), set \\(x:=e-e^{\\prime}\\). Then\n\n\\[x^{3}=e^{3}-3e^{2}e^{\\prime}+3ee^{\\prime 2}-e^{\\prime 3}=e-e^{\\prime}=x.\\]\n\nHence \\(x(1-x^{2})=0\\). But \\(\\kappa(x)=0\\); so \\(x\\in\\mathfrak{a}\\). But \\(\\mathfrak{a}\\subset\\operatorname{rad}(R)\\). Hence \\(1-x^{2}\\) is a unit by **(3.2)**. Thus \\(x=0\\). Thus \\(\\operatorname{Idem}(\\kappa)\\) is injective. \\(\\square\\)\n\n**Definition (3.4)**.: A ring is called **local** if it has exactly one maximal ideal, and **semilocal** if it has at most finitely many maximal ideals.\n\nBy the **residue field** of a local ring \\(A\\), we mean the field \\(A/\\mathfrak{m}\\) where \\(\\mathfrak{m}\\) is the (unique) maximal ideal of \\(A\\).\n\n**Lemma (3.5)** (Nonunit Criterion).: _Let \\(A\\) be a ring, \\(\\mathfrak{n}\\) the set of nonunits. Then \\(A\\) is local if and only if \\(\\mathfrak{n}\\) is an ideal; if so, then \\(\\mathfrak{n}\\) is the maximal ideal._\n\n**Proof:** Every proper ideal \\(\\mathfrak{a}\\) lies in \\(\\mathfrak{n}\\) as \\(\\mathfrak{a}\\) contains no unit. So, if \\(\\mathfrak{n}\\) is an ideal, then it is a maximal ideal, and the only one. Thus \\(A\\) is local.\n\nConversely, assume \\(A\\) is local with maximal ideal \\(\\mathfrak{m}\\). Then \\(A-\\mathfrak{n}=A-\\mathfrak{m}\\) by **(2.22)**. So \\(\\mathfrak{n}=\\mathfrak{m}\\). Thus \\(\\mathfrak{n}\\) is an ideal. \\(\\square\\)"}