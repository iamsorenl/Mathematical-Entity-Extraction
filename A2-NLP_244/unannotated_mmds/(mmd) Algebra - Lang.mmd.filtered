## 4 CYCLIC GROUPS

The integers \(\mathbf{Z}\) form an additive group. We shall determine its subgroups. Let \(H\) be a subgroup of \(\mathbf{Z}\). If \(H\) is not trivial, let \(a\) be the smallest positive integer in \(H\). We contend that \(H\) consists of all elements \(na\), with \(n\in\mathbf{Z}\). To prove this, let \(y\in H\). There exist integers \(n\), \(r\) with \(0\leqq r<a\) such that

\[y=na+r.\]

Since \(H\) is a subgroup and \(r=y-na\), we have \(r\in H\), whence \(r=0\), and our assertion follows.

Let \(G\) be a group. We shall say that \(G\) is **cyclic** if there exists an element \(a\) of \(G\) such that every element \(x\) of \(G\) can be written in the form \(a^{n}\) for some \(n\in\mathbf{Z}\) (in other words, if the map \(f\colon\mathbf{Z}\to G\) such that \(f(n)=a^{n}\) is surjective). Such an element \(a\) of \(G\) is then called a **generator** of \(G\).

Let \(G\) be a group and \(a\in G\). The subset of all elements \(a^{n}\) (\(n\in\mathbf{Z}\)) is obviously a subgroup of \(G\), which is cyclic. If \(m\) is an integer such that \(a^{m}=e\) and \(m>0\) then we shall call \(m\) an **exponent** of \(a\). We shall say that \(m>0\) is an **exponent** of \(G\) if \(x^{m}=e\) for all \(x\in G\).

Let \(G\) be a group and \(a\in G\). Let \(f\colon\mathbf{Z}\to G\) be the homomorphism such that \(f(n)=a^{n}\) and let \(H\) be the kernel of \(f\). Two cases arise:

**1.** The kernel is trivial. Then \(f\) is an isomorphism of \(\mathbf{Z}\) onto the cyclic subgroup of \(G\) generated by \(a\), and this subgroup is infinite cyclic. If \(a\) generates \(G\), then \(G\) is cyclic. We also say that \(a\) has **infinite period**.

**2.** The kernel is not trivial. Let \(d\) be the smallest positive integer in the kernel. Then \(d\) is called the **period** of \(a\). If \(m\) is an integer such that \(a^{m}=e\) then \(m=ds\) for some integer \(s\). We observe that the elements \(e\), \(a\), \(\ldots\), \(a^{d-1}\) aredistinct. Indeed, if \(a^{r}=a^{s}\) with \(0\leqq r\), \(s\leqq d-1\), and say \(r\leqq s\), then \(a^{s-r}=e\). Since \(0\leqq s-r<d\) we must have \(s-r=0\). The cyclic subgroup generated by \(a\) has order \(d\). Hence by Proposition 2.2:

**Proposition 4.1.** _Let \(G\) be a finite group of order \(n>1\). Let \(a\) be an element of \(G\), \(a\neq e\). Then the period of \(a\) divides \(n\). If the order of \(G\) is a prime number \(p\), then \(G\) is cyclic and the period of any generator is equal to \(p\)._

Furthermore:

**Proposition 4.2.** _Let \(G\) be a cyclic group. Then every subgroup of \(G\) is cyclic. If \(f\) is a homomorphism of \(G\), then the image of \(f\) is cyclic._

_Proof._ If \(G\) is infinite cyclic, it is isomorphic to \(\mathbf{Z}\), and we determined above all subgroups of \(\mathbf{Z}\), finding that they are all cyclic. If \(f:G\to G^{\prime}\) is a homomorphism, and \(a\) is a generator of \(G\), then \(f(a)\) is obviously a generator of \(f(G)\), which is therefore cyclic, so the image of \(f\) is cyclic. Next let \(H\) be a subgroup of \(G\). We want to show \(H\) cyclic. Let \(a\) be a generator of \(G\). Then we have a surjective homomorphism \(f:\mathbf{Z}\to G\) such that \(f(n)=a^{n}\). The inverse image \(f^{-1}(H)\) is a subgroup of \(\mathbf{Z}\), and therefore equal to \(m\mathbf{Z}\) for some positive integer \(m\). Since \(f\) is surjective, we also have a surjective homomorphism \(m\mathbf{Z}\to H\). Since \(m\mathbf{Z}\) is cyclic (generated additively by \(m\)), it follows that \(H\) is cyclic, thus proving the proposition.

We observe that two cyclic groups of the same order \(m\) are isomorphic. Indeed, if \(G\) is cyclic of order \(m\) with generator \(a\), then we have a surjective homomorphism \(f:\mathbf{Z}\to G\) such that \(f(n)=a^{n}\), and if \(k\mathbf{Z}\) is the kernel, with \(k\) positive, then we have an isomorphism \(\mathbf{Z}/k\mathbf{Z}\approx G\), so \(k=m\). If \(u:G_{1}\to\mathbf{Z}/m\mathbf{Z}\) and \(v:G_{2}\to\mathbf{Z}/m\mathbf{Z}\) are isomorphisms of two cyclic groups with \(\mathbf{Z}/m\mathbf{Z}\), then \(v^{-1}\circ u:G_{1}\to G_{2}\) is an isomorphism.

**Proposition 4.3.**

* _An infinite cyclic group has exactly two generators_ (_if_ \(a\) _is a generator_, _then_ \(a^{-1}\) _is the only other generator_)._
* _Let_ \(G\) _be a finite cyclic group of order_ \(n\)_, and let_ \(x\) _be a generator. The set of generators of_ \(G\) _consists of those powers_ \(x^{\ast}\) _of_ \(x\) _such that_ \(v\) _is relatively prime to_ \(n\)_._
* _Let_ \(G\) _be a cyclic group, and let_ \(a,b\) _be two generators. Then there exists an automorphism of_ \(G\) _mapping a onto_ \(b\)_. Conversely, any automorphism of_ \(G\) _maps a on some generator of_ \(G\)_._
* _Let_ \(G\) _be a cyclic group of order_ \(n\)_. Let_ \(d\) _be a positive integer dividing_ \(n\)_. Then there exists a unique subgroup of_ \(G\) _of order_ \(d\)_._
* _Let_ \(G_{1}\)_,_ \(G_{2}\) _be cyclic of orders_ \(m\)_,_ \(n\) _respectively. If_ \(m\)_,_ \(n\) _are relatively prime then_ \(G_{1}\times G_{2}\) _is cyclic.__._
**(v)**: _Let_ \(G\) _be a finite abelian group. If_ \(G\) _is not cyclic, then there exists a prime_ \(p\) _and a subgroup of_ \(G\) _isomorphic to_ \(C\times C\)_, where_ \(C\) _is cyclic of order_ \(p\)_._

_Proof._ We leave the first three statements to the reader, and prove the others.

**(iv)** Let \(d\,|\,n\). Let \(m=n/d\). Let \(f\colon{\mathbf{Z}}\to G\) be a surjective homomorphism. Then \(f(m{\mathbf{Z}})\) is a subgroup of \(G\), and from the isomorphism \({\mathbf{Z}}/m{\mathbf{Z}}\to G/f(m{\mathbf{Z}})\) we conclude that \(f(m{\mathbf{Z}})\) has index \(m\) in \(G\), whence\(f(m{\mathbf{Z}})\) has order \(d\). Conversely, let \(H\) be a subgroup of order \(d\). Then \(f^{-1}(H)=m{\mathbf{Z}}\) for some positive integer \(m\), so \(H=f(m{\mathbf{Z}})\), \({\mathbf{Z}}/m{\mathbf{Z}}\approx G/H\), so \(n=md\), \(m=n/d\) and \(H\) is uniquely determined.

**(v)** Let \(A=\langle a\rangle\) and \(B=\langle b\rangle\) be cyclic groups of orders \(m\), \(n\), relatively prime. Consider the homomorphism \({\mathbf{Z}}\to A\,\times\,B\) such that \(k\mapsto(a^{k},\,b^{k})\). An element in its kernel must be divisible both by \(m\) and \(n\), hence by their product since \(m\), \(n\) are relatively prime. Conversely, it is clear that \(mn{\mathbf{Z}}\) is contained in the kernel, so the kernel is \(mn{\mathbf{Z}}\). The image of \({\mathbf{Z}}\to A\,\times\,B\) is surjective by the Chinese remainder theorem. This proves **(v)**. (A reader who does not know the Chinese remainder theorem can see a proof in the more general context of Chapter II, Theorem 2.2.)

**(vi)** This characterization of cyclic groups is an immediate consequence of the structure theorem which will be proved in SS8, because if \(G\) is not cyclic, then by Theorem 8.1 and **(v)** we are reduced to the case when \(G\) is a \(p\)-group, and by Theorem 8.2 there are at least two factors in the direct product (or sum) decomposition, and each contains a cyclic subgroup of order \(p\), whence \(G\) contains their direct product (or sum). Statement **(vi)** is, of course, easier to prove than the full structure theorem, and it is a good exercise for the reader to formulate the simpler arguments which yield **(vi)** directly.

**Note.** For the group of automorphisms of a cyclic group, see the end of Chapter II, SS2.

## 5 Operations of a group on a set

Let \(G\) be a group and let \(S\) be a set. An **operation** or an **action** of \(G\) on \(S\) is a homomorphism

\[\pi:G\to\operatorname{Perm}(S)\]

of \(G\) into the group of permutations of \(S\). We then call \(S\) a \(G\)**-set**. We denote the permutation associated with an element \(x\in G\) by \(\pi_{x}\). Thus the homomorphism is denoted by \(x\mapsto\pi_{x}\). Given \(s\in S\), the image of \(s\) under the permutation \(\pi_{x}\) is \(\pi_{x}(s)\). From such an operation we obtain a mapping

\[G\,\times\,S\to S,\]

## 26 Groups

which to each pair \((x,\,s)\) with \(x\in G\) and \(s\in S\) associates the element \(\pi_{x}(s)\). We often abbreviate the notation and write simply \(xs\) instead of \(\pi_{x}(s)\). With the simpler notation, we have the two properties:

_For all \(x,\,y\in G\) and \(s\in S\), we have \(x(ys)=(xy)s\)._

_If \(e\) is the unit element of \(G\), then \(es=s\) for all \(s\in S\)._

Conversely, if we are given a mapping \(G\times S\to S\), denoted by \((x,\,s)\mapsto xs\), satisfying these two properties, then for each \(x\in G\) the map \(s\mapsto xs\) is permutation of \(S\), which we then denote by \(\pi_{x}(s)\). Then \(x\mapsto\pi_{x}\) is a homomorphism of \(G\) into Perm(\(S\)). So an operation of \(G\) on \(S\) could also be defined as a mapping \(G\times S\to S\) satisfying the above two properties. The most important examples of representations of \(G\) as a group of permutations are the following.

**1. Conjugation.** For each \(x\in G\), let \(\mathbf{c}_{x}\): \(G\to G\) be the map such that \(\mathbf{c}_{x}(y)=xyx^{-1}\). Then it is immediately verified that the association \(x\mapsto\mathbf{c}_{x}\) is a homomorphism \(G\to\operatorname{Aut}(G)\), and so this map gives an operation of \(G\) on itself, called **conjugation**. The kernel of the homomorphism \(x\mapsto\mathbf{c}_{x}\) is a normal subgroup of \(G\), which consists of all \(x\in G\) such that \(xyx^{-1}=y\) for all \(y\in G\), i.e. all \(x\in G\) which commute with every element of \(G\). This kernel is called the **center** of \(G\). Automorphisms of \(G\) of the form \(\mathbf{c}_{x}\) are called **inner**.

To avoid confusion about the operation on the left, we don't write \(xy\) for \(\mathbf{c}_{x}(y)\). Sometimes, one writes

\[\mathbf{c}_{x^{-1}}(y)=x^{-1}yx=y^{x},\]

i.e. one uses an exponential notation, so that we have the rules

\[y^{(xz)}=(y^{x})^{z}\quad\text{and}\quad y^{e}=y\]

for all \(x\), \(y\), \(z\in G\). Similarly, \({}^{x}y=xyx^{-1}\) and \({}^{z}(xy)={}^{zx}y\).

We note that \(G\) also operates by conjugation on the set of subsets of \(G\). Indeed, let \(S\) be the set of subsets of \(G\), and let \(A\in S\) be a subset of \(G\). Then \(xAx^{-1}\) is also a subset of \(G\) which may be denoted by \(\mathbf{c}_{x}(A)\), and one verifies trivially that the map

\[(x,\,A)\mapsto xAx^{-1}\]

of \(G\times S\to S\) is an operation of \(G\) on \(S\). We note in addition that if \(A\) is a subgroup of \(G\) then \(xAx^{-1}\) is also a subgroup, so that \(G\) operates on the set of subgroups by conjugation.

If \(A\), \(B\) are two subsets of \(G\), we say that they are **conjugate** if there exists \(x\in G\) such that \(B=xAx^{-1}\).

## 2 Translation.

For each \(x\in G\) we define the translation \(T_{x}\): \(G\to G\) by \(T_{x}(y)=xy\). Then the map

\[(x,\,y)\mapsto xy=T_{x}(y)\]

defines an operation of \(G\) on itself. _Warning_: \(T_{x}\) is not a group-homomorphism! Only a permutation of \(G\).

Similarly, \(G\) operates by translation on the set of subsets, for if \(A\) is a subset of \(G\), then \(xA=T_{x}(A)\) is also a subset. If \(H\) is a subgroup of \(G\), then \(T_{x}(H)=xH\) is in general not a subgroup but a coset of \(H\), and hence we see that \(G\) operates by translation on the set of cosets of \(H\). We denote the set of left cosets of \(H\) by \(G/H\). Thus even though \(H\) need not be normal, \(G/H\) is a \(G\)-set. It has become customary to denote the set of _right_ cosets by \(H\backslash G\).

The above two representations of \(G\) as a group of permutations will be used frequently in the sequel. In particular, the representation by conjugation will be used throughout the next section, in the proof of the Sylow theorems.

## 3 Example from linear algebra

We assume the reader knows basic notions of linear algebra. Let \(k\) be a field and let \(V\) be a vector space over \(k\). Let \(G=GL(V)\) be the group of linear automorphisms of \(V\). For \(A\in G\) and \(v\in V\), the map \((A,\,v)\mapsto Av\) defines an operation of \(G\) on \(V\). Of course, \(G\) is a subgroup of the group of permutations \(\operatorname{Perm}(V)\). Similarly, let \(V=k^{n}\) be the vector space of (vertical) \(n\)-tuples of elements of \(k\), and let \(G\) be the group of invertible \(n\times n\) matrices with components in \(k\). Then \(G\) operates on \(k^{n}\) by \((A,\,X)\mapsto AX\) for \(A\in G\) and \(X\in k^{n}\).

Let \(S\), \(S^{\prime}\) be two \(G\)-sets, and \(f:S\to S^{\prime}\) a map. We say that \(f\) is a **morphism of \(G\)-sets**, or a \(G\)-**map**, if

\[f(xs)=xf(s)\]

for all \(x\in G\) and \(s\in S\). (We shall soon define categories, and see that \(G\)-sets form a category.)

We now return to the general situation, and consider a group operating on a set \(S\). Let \(s\in S\). The set of elements \(x\in G\) such that \(xs=s\) is obviously a subgroup of \(G\), called the **isotropy** group of \(s\) in \(G\), and denoted by \(G_{s}\).

When \(G\) operates on itself by conjugation, then the isotropy group of an element is none other than the normalizer of this element. Similarly, when \(G\) operates on the set of subgroups by conjugation, the isotropy group of a subgroup is again its normalizer.

Let \(G\) operate on a set \(S\). Let \(s\), \(s^{\prime}\) be elements of \(S\), and \(y\) an element of \(G\) such that \(ys=s^{\prime}\). Then

\[G_{s^{\prime}}=yG_{s}y^{-1}\]

Indeed, one sees at once that \(yG_{s}y^{-1}\) leaves \(s^{\prime}\) fixed. Conversely, if \(x^{\prime}s^{\prime}=s^{\prime}\) then \(x^{\prime}ys=ys\), so \(y^{-1}x^{\prime}y\in G_{s}\) and \(x^{\prime}\in yG_{s}y^{-1}\). Thus the isotropy groups of \(s\) and \(s^{\prime}\) are conjugate.

Let \(K\) be the kernel of the representation \(G\to\operatorname{Perm}(S)\). Then directly from the definitions, we obtain that

\[K=\bigcap_{s\in S}\ G_{s}=\text{intersection of all isotropy groups}.\]

## 28 Groups

An action or operation of \(G\) is said to be **faithful** if \(K=\{e\}\); that is, the kernel of \(G\to\operatorname{Perm}(S)\) is trivial. A **fixed point** of \(G\) is an element \(s\in S\) such that \(xs=s\) for all \(x\in G\) or in other words, \(G=G_{s}\).

Let \(G\) operate on a set \(S\). Let \(s\in S\). The subset of \(S\) consisting of all elements \(xs\) (with \(x\in G\)) is denoted by \(Gs\), and is called the **orbit** of \(s\) under \(G\). If \(x\) and \(y\) are in the same coset of the subgroup \(H=G_{s}\), then \(xs=ys\), and conversely (obvious). In this manner, we get a mapping

\[f\colon G/H\to S\]

given by \(f(xH)=xs\), and it is clear that this map is a morphism of \(G\)-sets. In fact, one sees at once that it induces a bijection of \(G/H\) onto the orbit \(Gs\). Consequently:

**Proposition 5.1.**_If \(G\) is a group operating on a set \(S\), and \(s\in S\), then the order of the orbit \(Gs\) is equal to the index \((G:G_{s})\)._

In particular, when \(G\) operates by conjugation on the set of subgroups, and \(H\) is a subgroup, then:

**Proposition 5.2.**_The number of conjugate subgroups to \(H\) is equal to the index of the normalizer of \(H\)._

**Example.** Let \(G\) be a group and \(H\) a subgroup of index \(2\). Then \(H\) is normal in \(G\).

_Proof._ Note that \(H\) is contained in its normalizer \(N_{H}\), so the index of \(N_{H}\) in \(G\) is \(1\) or \(2\). If it is \(1\), then we are done. Suppose it is \(2\). Let \(G\) operate by conjugation on the set of subgroups. The orbit of \(H\) has \(2\) elements, and \(G\) operates on this orbit. In this way we get a homomorphism of \(G\) into the group of permutations of \(2\) elements. Since there is one conjugate of \(H\) unequal to \(H\), then the kernel of our homomorphism is normal, of index \(2\), hence equal to \(H\), which is normal, a contradiction which concludes the proof.

For a generalization and other examples, see Lemma 6.7.

In general, an operation of \(G\) on \(S\) is said to be **transitive** if there is only one orbit.

**Examples.** The symmetric group \(S_{n}\) operates transitively on \(\{1,2,\ldots,n\}\). In Proposition 2.1 of Chapter VII, we shall see a non-trivial example of transitive action of a Galois group operating on the primes lying above a given prime in the ground ring. In topology, suppose we have a universal covering space \(p\colon X^{\prime}\to X\), where \(X\) is connected. Given \(x\in X\), the fundamental group \(\pi_{1}(X)\) operates transitively on the inverse image \(p^{-1}(x)\).

**Example.** Let \(\hat{\mathcal{G}}\) be the upper half-plane; that is, the set of complex numbers \(z=x+iy\) such that \(y>0\). Let \(G=SL_{2}(\mathbf{R})\) (\(2\times 2\) matrices with determinant \(1\)). For

\[\alpha=\begin{pmatrix}a&b\\ c&d\end{pmatrix}\in G\text{, we let }\alpha z=\frac{az+b}{cz+d}\text{.}\]

Readers will verify by brute force that this defines an operation of \(G\) on \(\hat{\mathcal{G}}\). The isotropy group of \(i\) is the group of matrices

\[\begin{pmatrix}\cos\ \theta&\sin\ \theta\\ -\sin\ \theta&\cos\ \theta\end{pmatrix}\quad\text{with }\theta\text{ real.}\]

This group is usually denoted by \(K\). The group \(G\) operates transitively. You can verify all these statements as easy exercises.

Let \(G\) operate on a set \(S\). Then two orbits of \(G\) are either disjoint or are equal. Indeed, if \(Gs_{1}\) and \(Gs_{2}\) are two orbits with an element \(s\) in common, then \(s=xs_{1}\) for some \(x\in G\), and hence \(Gs=Gs_{1}=Gs_{1}\). Similarly, \(Gs=Gs_{2}\). Hence \(S\) is the disjoint union of the distinct orbits, and we can write

\[S=\bigcup_{i\in I}Gs_{i}\qquad\text{(disjoint),}\quad\text{ also denoted }S=\coprod_{i\in I}Gs_{i}\text{,}\]

where \(I\) is some indexing set, and the \(s_{i}\) are elements of distinct orbits. If \(S\) is finite, this gives a decomposition of the order of \(S\) as a sum of orders of orbits, which we call the **orbit decomposition formula**, namely

\[\boxed{\text{card}(S)=\sum_{i\in I}(G:G_{s_{i}}).}\]

Let \(x\), \(y\) be elements of a group (or monoid) \(G\). They are said to **commute** if \(xy=yx\). If \(G\) is a group, the set of all elements \(x\in G\) which commute with all elements of \(G\) is a subgroup of \(G\) which we called the **center** of \(G\). Let \(G\) act on itself by conjugation. Then \(x\) is in the center if and only if the orbit of \(x\) is \(x\) itself, and thus has one element. In general, the order of the orbit of \(x\) is equal to the index of the normalizer of \(x\). Thus when \(G\) is a finite group, the above formula reads

\[\boxed{(G:1)=\sum_{x\in C}(G:G_{x})}\]

where \(C\) is a set of representatives for the distinct conjugacy classes, and the sum is taken over all \(x\in C\). This formula is also called the **class formula**.

## 30 GROUPS

The class formula and the orbit decomposition formula will be used systematically in the next section on Sylow groups, which may be viewed as providing examples for these formulas.

_Readers interested in Sylow groups may jump immediately to the next section. The rest of this section deals with special properties of the symmetric group, which may serve as examples of the general notions we have developed._

**The symmetric group.** Let \(S_{n}\) be the group of permutations of a set with \(n\) elements. This set may be taken to be the set of integers \(J_{n}=\{1,\,2,\ldots,\,n\}\). Given any \(\sigma\in S_{n}\), and any integer \(i\), \(1\leqq i\leqq n\), we may form the orbit of \(i\) under the cyclic group generated by \(\sigma\). Such an orbit is called a **cycle** for \(\sigma\), and may be written

\[[i_{1}i_{2}\,\cdots\,i_{r}],\qquad\mbox{so}\quad\sigma(i_{1})=i_{2},\ldots,\, \sigma(i_{r-1})=i_{r},\,\sigma(i_{r})=i_{1}.\]

Then \(\{1,\ldots,\,n\}\) may be decomposed into a disjoint union of orbits for the cyclic group generated by \(\sigma\), and therefore into disjoint cycles. Thus the effect of \(\sigma\) on \(\{1,\ldots,\,n\}\) is represented by a product of disjoint cycles.

**Example.** The cycle [132] represents the permutation \(\sigma\) such that

\[\sigma(1)=3,\qquad\sigma(3)=2,\quad\mbox{and}\quad\sigma(2)=1.\]

We have \(\sigma^{2}(1)=2\), \(\sigma^{3}(1)=1\). Thus \(\{1,3,2\}\) is the orbit of \(1\) under the cyclic group generated by \(\sigma\).

**Example.** In Exercise 38, one will see how to generate \(S_{n}\) by special types of generators. Perhaps the most important part of that exercise is that if \(n\) is prime, \(\sigma\) is an \(n\)-cycle and \(\tau\) is a transposition, then \(\sigma\), \(\tau\) generate \(S_{n}\). As an application in Galois theory, if one tries to prove that a Galois group is all of \(S_{n}\) (as a group of permutations of the roots), it suffices to prove that the Galois group contains an \(n\)-cycle and a transposition. See Example 6 of Chapter VI, SS2.

We want to associate a sign \(\pm 1\) to each permutation. We do this in the standard way. Let \(f\) be a function of \(n\) variables, say \(f:{\bf Z}^{n}\to{\bf Z}\), so we can evaluate \(f(x_{1},\ldots,\,x_{n})\). Let \(\sigma\) be a permutation of \(J_{n}\). We define the function \(\pi(\sigma)f\) by

\[\pi(\sigma)f(x_{1},\ldots,\,x_{n})=f(x_{\sigma(1)},\ldots,\,x_{\sigma(n)}).\]

Then for \(\sigma\), \(\tau\in S_{n}\) we have \(\pi(\sigma\tau)=\pi(\sigma)\pi(\tau)\). Indeed, we use the definition applied to the function \(g=\pi(\tau)f\) to get

\[\pi(\sigma)\pi(\tau)f(x_{1},\ldots,\,x_{n}) = (\pi(\tau)f)(x_{\sigma(1)},\ldots,\,x_{\sigma(n)})\] \[= f(x_{\sigma\tau(1)},\ldots,\,x_{\sigma\tau(n)})\] \[= \pi(\sigma)f(x_{1},\ldots,\,x_{n}).\]Since the identity in \(S_{n}\) operates as the identity on functions, it follows that we have obtained an operation of \(S_{n}\) on the set of functions. We shall write more simply _of_ instead of \(\pi(\sigma)f\). It is immediately verified that for two functions \(f\), \(g\) we have

\[\sigma(f+g)=\sigma f+\sigma g\quad\text{and}\quad\sigma(fg)=(\sigma f)(\sigma g).\]

If \(c\) is constant, then \(\sigma(cf)=c\sigma(f)\).

**Proposition 5.3.** _There exists a unique homomorphism \(\varepsilon\colon S_{n}\to\{\pm 1\}\) such that for every transposition \(\tau\) we have \(\varepsilon(\tau)=-1\)._

_Proof_. Let \(\Delta\) be the function

\[\Delta(x_{1},\ldots,x_{n})=\prod_{i<j}\,(x_{j}-x_{i}),\]

the product being taken for all pairs of integers \(i\), \(j\) satisfying \(1\leqq i<j\leqq n\). Let \(\tau\) be a transposition, interchanging the two integers \(r\) and \(s\). Say \(r<s\). We wish to determine

\[\tau\Delta(x_{1},\ldots,x_{n})=\prod_{i<j}\,(x_{\tau(j)}-x_{\tau(i)}).\]

For one factor involving \(j=s\), \(i=r\), we see that \(\tau\) changes the factor \((x_{s}-x_{r})\) to \(-(x_{s}-x_{r})\). All other factors can be considered in pairs as follows:

\[(x_{k}-x_{s})(x_{k}-x_{r})\quad\text{if $k>s$},\] \[(x_{s}-x_{k})(x_{k}-x_{r})\quad\text{if $r<k<s$},\] \[(x_{s}-x_{k})(x_{r}-x_{k})\quad\text{if $k<r$}.\]

Each one of these pairs remains unchanged when we apply \(\tau\). Hence we see that \(\tau\Delta=-\Delta\).

Let \(\varepsilon(\sigma)\) be the sign \(1\) or \(-1\) such that \(\sigma\Delta=\varepsilon(\sigma)\Delta\) for a permutation \(\sigma\). Since \(\pi(\sigma\tau)=\pi(\sigma)\pi(\tau)\), it follows at once that \(\varepsilon\) is a homomorphism, and the proposition is proved.

In particular, if \(\sigma=\tau_{1}\,\cdots\,\tau_{m}\) is a product of transpositions, then \(\varepsilon(\sigma)=(-1)^{m}\). As a matter of terminology, we call \(\sigma\)**even** if \(\varepsilon(\sigma)=1\), and **odd** if \(\varepsilon(\sigma)=-1\). The even permutations constitute the kernel of \(\varepsilon\), which is called the **alternating group**\(A_{n}\).

**Theorem 5.4.** _If \(n\geqq 5\) then \(S_{n}\) is not solvable._

_Proof_. We shall first prove that if \(H\), \(N\) are two subgroups of \(S_{n}\) such that \(N\subset H\) and \(N\) is normal in \(H\), if \(H\) contains every \(3\)-cycle, and if \(H/N\) is abelian, then \(N\) contains every \(3\)-cycle. To see this, let \(i,j\), \(k\), \(r\), \(s\) be five distinct integers in \(J_{n}\), and let \(\sigma=[ijk]\) and \(\tau=[krs]\). Then a direct computation gives their commutator

\[\sigma\tau\sigma^{-1}\tau^{-1}=[rki].\]

## 32 GROUPS

Since the choice of \(i,j,k,r,s\) was arbitrary, we see that the cycles \([rki]\) all lie in \(N\) for all choices of distinct \(r\), \(k\), \(i\), thereby proving what we wanted.

Now suppose that we have a tower of subgroups

\[S_{n}=H_{0}\supset H_{1}\supset H_{2}\supset\cdots\supset H_{m}=\{e\}\]

such that \(H_{v}\) is normal in \(H_{v-1}\) for \(v=1,\ldots,m\), and \(H_{v}/H_{v-1}\) is abelian. Since \(S_{n}\) contains every 3-cycle, we conclude that \(H_{1}\) contains every 3-cycle. By induction, we conclude that \(H_{m}=\{e\}\) contains every 3-cycle, which is impossible, thus proving the theorem.

**Remark concerning the sign \(\varepsilon(\sigma)\).**_A priori_, we defined the sign for a given \(n\), so we should write \(\varepsilon_{n}(\sigma)\). However, suppose \(n<m\). Then the restriction of \(\varepsilon_{m}\) to \(S_{n}\) (viewed as a permutation of \(J_{n}\) leaving the elements of \(J_{m}\) not in \(J_{n}\) fixed) gives a homomorphism satisfying the conditions of Proposition 5.3, so this restriction is equal to \(\varepsilon_{n}\). Thus \(A_{m}\cap S_{n}=A_{n}\).

Next we prove some properties of the alternating group.

(a) \(A_{n}\)_is generated by the \(3\)-cycles. Proof:_ Consider the product of two transpositions \([ij][rs]\). If they have an element in common, the product is either the identity or a 3-cycle. If they have no element in common, then

\[[ij][rs]=[ijr][jrs],\]

so the product of two transpositions is also a product of 3-cycles. Since an even permutation is a product of an even number of transpositions, we are done.

(b) _If \(n\geqq 5\), all \(3\)-cycles are conjugate in \(A_{n}\). Proof:_ If \(\gamma\) is a permutation, then for a cycle \([i_{1}\ldots i_{m}]\) we have

\[\gamma(i_{1}\ldots i_{m}]\gamma^{-1}=[\gamma(i_{1})\ldots\gamma(i_{m})].\]

Given 3-cycles \([ijk]\) and \([i^{\prime}j^{\prime}k^{\prime}]\) there is a permutation \(\gamma\) such that \(\gamma(i)=i^{\prime}\), \(\gamma(j)=j^{\prime}\), and \(\gamma(k)=k^{\prime}\). Thus two 3-cycles are conjugate in \(S_{n}\) by some element \(\gamma\). If \(\gamma\) is even, we are done. Otherwise, by assumption \(n\geqq 5\) there exist \(r\), \(s\) not equal to any one of the three elements \(i,j\), \(k\). Then \([rs]\) commutes with \([ijk]\), and we replace \(\gamma\) by \(\gamma(rs]\) to prove (b).

**Theorem 5.5.**_If \(n\geqq 5\) then the alternating group \(A_{n}\) is simple_.

_Proof_. Let \(N\) be a non-trivial normal subgroup of \(A_{n}\). We prove that \(N\) contains some 3-cycle, whence the theorem follows by (b). Let \(\sigma\in N\), \(\sigma\neq id\), be an element which has the maximal number of fixed points; that is, integers \(i\) such that \(\sigma(i)=i\). It will suffice to prove that \(\sigma\) is a 3-cycle or the identity. Decompose \(J_{n}\) into disjoint orbits of \(\langle\sigma\rangle\).Then some orbits have more than one element. Suppose all orbits have 2 elements (except for the fixed points). Since \(\sigma\) is even, there are at least two such orbits. On their union, \(\sigma\) is represented asa product of two transpositions \([ij][rs]\). Let \(k\neq i\), \(j\), \(r\), \(s\). Let \(\tau=[rsk]\). Let \(\sigma^{\prime}=\tau\sigma\tau^{-1}\sigma^{-1}\). Then \(\sigma^{\prime}\) is a product of a conjugate of \(\sigma\) and \(\sigma^{-1}\), so \(\sigma^{\prime}\in N\). But \(\sigma^{\prime}\) leaves \(i,j\) fixed, and any element \(t\in J_{n}\), \(t\neq i,j\), \(r\), \(s\), \(k\) left fixed by \(\sigma\) is also fixed by \(\sigma^{\prime}\), so \(\sigma^{\prime}\) has more fixed points than \(\sigma\), contradicting our hypothesis.

So we are reduced to the case when at least one orbit of \(\langle\sigma\rangle\) has \(\geqq 3\) elements, say \(i,j\), \(k\), \(\ldots\). If \(\sigma\) is not the 3-cycle \([ijk]\), then \(\sigma\) must move at least two other elements of \(J_{n}\), otherwise \(\sigma\) is an odd permutation \([ijkr]\) for some \(r\in J_{n}\), which is impossible. Then let \(\sigma\) move \(r\), \(s\) other than \(i\), \(j\), \(k\), and let \(\tau=[krs]\). Let \(\sigma^{\prime}\) be the commutator as before. Then \(\sigma^{\prime}\in N\) and \(\sigma^{\prime}(i)=i\), and all fixed points of \(\sigma\) are also fixed points of \(\sigma^{\prime}\) whence \(\sigma^{\prime}\) has more fixed points than \(\sigma\), a contradiction which proves the theorem.

**Example.** For \(n=4\), the group \(A_{4}\) is not simple. As an exercise, show that \(A_{4}\) contains a unique subgroup of order 4, which is not cyclic, and which is normal. This subgroup is also normal in \(S_{4}\). Write down explicitly its elements as products of transpositions.

## 6 Sylow subgroups

Let \(p\) be a prime number. By a \(p\)**-group**, we mean a finite group whose order is a power of \(p\) (i.e. \(p^{n}\) for some integer \(n\geqq 0\)). Let \(G\) be a finite group and \(H\) a subgroup. We call \(H\) a \(p\)**-subgroup** of \(G\) if \(H\) is a \(p\)-group. We call \(H\) a \(p\)**-Sylow** subgroup if the order of \(H\) is \(p^{n}\) and if \(p^{n}\) is the highest power of \(p\) dividing the order of \(G\). We shall prove below that such subgroups always exist. For this we need a lemma.

**Lemma 6.1.** _Let \(G\) be a finite abelian group of order \(m\), let \(p\) be a prime number dividing \(m\). Then \(G\) has a subgroup of order \(p\)._

_Proof_. We first prove by induction that if \(G\) has exponent \(n\) then the order of \(G\) divides some power of \(n\). Let \(b\in G\), \(b\neq 1\), and let \(H\) be the cyclic subgroup generated by \(b\). Then the order of \(H\) divides \(n\) since \(b^{n}=1\), and \(n\) is an exponent for \(G/H\). Hence the order of \(G/H\) divides a power of \(n\) by induction, and consequently so does the order of \(G\) because

\[(G:1)=(G:H)(H:1).\]

Let \(G\) have order divisible by \(p\). By what we have just seen, there exists an element \(x\) in \(G\) whose period is divisible by \(p\). Let this period be \(ps\) for some integer \(s\). Then \(x^{s}\neq 1\) and obviously \(x^{s}\) has period \(p\), and generates a subgroup of order \(p\), as was to be shown.

[MISSING_PAGE_FAIL:49]

_._
* _All_ \(p\)_-Sylow subgroups are conjugate._
* _The number of_ \(p\)_-Sylow subgroups of_ \(G\) _is_ \(\equiv\)1 mod \(p\)_._

_Proof_. Let \(P\) be a \(p\)-Sylow subgroup of \(G\). Suppose first that \(H\) is contained in the normalizer of \(P\). We prove that \(H\subset P\). Indeed, \(HP\) is then a subgroup of the normalizer, and \(P\) is normal in \(HP\). But

\[(HP:P)\,=\,(H:H\,\cap\,P),\]

so if \(HP\neq P\), then \(HP\) has order a power of \(p\), and the order is larger than \(\#(P)\), contradicting the hypothesis that \(P\) is a Sylow group. Hence \(HP=P\) and \(H\subset P\).

Next, let \(S\) be the set of all conjugates of \(P\) in \(G\). Then \(G\) operates on \(S\) by conjugation. Since the normalizer of \(P\) contains \(P\), and has therefore index prime to \(p\), it follows that \(\#(S)\) is not divisible by \(p\). Now let \(H\) be any \(p\)-subgroup. Then \(H\) also acts on \(S\) by conjugation. By Lemma 6.3(a), we know that \(H\) cannot have 0 fixed points. Let \(Q\) be a fixed point. By definition this means that \(H\) is contained in the normalizer of \(Q\), and hence by the first part of the proof, that \(H\subset Q\), which proves the first part of the theorem. The second part follows immediately by taking \(H\) to be a \(p\)-Sylow group, so \(\#(H)=\#(Q)\), whence \(H=Q\). In particular, when \(H\) is a \(p\)-Sylow group, we see that \(H\) has only one fixed point, so that **(iii)** follows from Lemma 6.3(b). This proves the theorem.

**Theorem 6.5**. : _Let \(G\) be a finite \(p\)-group. Then \(G\) is solvable. If its order is \(>1\), then \(G\) has a non-trivial center._

_Proof_. The first assertion follows from the second, since if \(G\) has center \(Z\), and we have an abelian tower for \(G/Z\) by induction, we can lift this abelian tower to \(G\) to show that \(G\) is solvable. To prove the second assertion, we use the class equation

\[(G:1)\,=\,\mbox{card}(Z)\,+\,\sum\,(G:G_{x}),\]

the sum being taken over certain \(x\) for which \((G:G_{x})\neq 1\). Then \(p\) divides \((G:1)\) and also divides every term in the sum, so that \(p\) divides the order of the center, as was to be shown.

**Corollary 6.6**. : _Let \(G\) be a \(p\)-group which is not of order \(1\). Then there exists a sequence of subgroups_

\[\{e\}\,=\,G_{0}\,\subset\,G_{1}\,\subset\,G_{2}\,\subset\,\cdots\,\subset\,G_ {n}\,=\,G\]

_such that \(G_{i}\) is normal in \(G\) and \(G_{i+1}/G_{i}\) is cyclic of order \(p\)._

_Proof_. Since \(G\) has a non-trivial center, there exists an element \(a\neq e\) in the center of \(G\), and such that \(a\) has order \(p\). Let \(H\) be the cyclic group generated by \(a\). By induction, if \(G\neq H\), we can find a sequence of subgroups as stated above in the factor group \(G/H\). Taking the inverse image of this tower in \(G\) gives us the desired sequence in \(G\).

We now give some examples to show how to put some of the group theory together.

**Lemma 6.7.** _Let \(G\) be a finite group and let \(p\) be the smallest prime dividing the order of \(G\). Let \(H\) be a subgroup of index \(p\). Then \(H\) is normal._

_Proof._ Let \(N(H)=N\) be the normalizer of \(H\). Then \(N=G\) or \(N=H\). If \(N=G\) we are done. Suppose \(N=H\). Then the orbit of \(H\) under conjugation has \(p=(G:H)\) elements, and the representation of \(G\) on this orbit gives a homomorphism of \(G\) into the symmetric group on \(p\) elements, whose order is \(p!\). Let \(K\) be the kernel. Then \(K\) is the intersection of the isotropy groups, and the isotropy group of \(H\) is \(H\) by assumption, so \(K\subset H\). If \(K\neq H\), then from

\[(G:K)\,=\,(G:H)(H:K)\,=\,p(H:K),\]

and the fact that only the first power of \(p\) divides \(p!\), we conclude that some prime dividing \((p\,-\,1)!\) also divides \((H:K)\), which contradicts the assumption that \(p\) is the smallest prime dividing the order of \(G\), and proves the lemma.

**Proposition 6.8.** _Let \(p\), \(q\) be distinct primes and let \(G\) be a group of order \(pq\). Then \(G\) is solvable._

_Proof._ Say \(p<q\). Let \(Q\) be a Sylow subgroup of order \(q\). Then \(Q\) has index \(p\), so by the lemma, \(Q\) is normal and the factor group has order \(p\). But a group of prime order is cyclic, whence the proposition follows.

**Example.** Let \(G\) be a group of order 35. We claim that \(G\) is cyclic.

_Proof._ Let \(H_{7}\) be the Sylow subgroup of order 7. Then \(H_{7}\) is normal by Lemma 6.7. Let \(H_{5}\) be a 5-Sylow subgroup, which is of order 5. Then \(H_{5}\) operates by conjugation on \(H_{7}\), so we get a homomorphism \(H_{5}\to\operatorname{Aut}(H_{7})\). But \(\operatorname{Aut}(H_{7})\) is cyclic of order 6, so \(H_{5}\to\operatorname{Aut}(H_{7})\) is trivial, so every element of \(H_{5}\) commutes with elements of \(H_{7}\). Let \(H_{5}=\langle x\rangle\) and \(H_{7}=\langle y\rangle\). Then \(x\), \(y\) commute with each other and with themselves, so \(G\) is abelian, and so \(G\) is cyclic by Proposition 4.3(v).

**Example.** The techniques which have been developed are sufficient to treat many cases of the above types. For instance every group of order \(<60\) is solvable, as you will prove in Exercise 27.

## 7 Direct sums and free abelian groups

Let \(\{A_{i}\}_{i\in I}\) be a family of abelian groups. We define their **direct sum**

\[A\,=\,\bigoplus_{i\in I}\,A_{i}\]

to be the subset of the direct product \(\prod A_{i}\) consisting of all families \((x_{i})_{i\in I}\) with \(x_{i}\in A_{i}\) such that \(x_{i}=0\) for all but a finite number of indices \(i\). Then it is clear that \(A\) is a subgroup of the product. For each index \(j\in I\), we map

\[\lambda_{j}\colon A_{j}\to A\]

by letting \(\lambda_{j}(x)\) be the element whose \(j\)-th component is \(x\), and having all other components equal to \(0\). Then \(\lambda_{i}\) is an injective homomorphism.

**Proposition 7.1.** _Let \(\{f_{i}\colon A_{i}\to B\}\) be a family of homomorphisms into an abelian group \(B\). Let \(A=\bigoplus A_{i}\). There exists a unique homomorphism_

\[f\colon A\to B\enspace.\]

_such that \(f\,{\raise 1.0pt\hbox{$\circ$}\kern-1.0pt}\,\,\lambda_{j}=f_{j}\) for all \(j\)._

_Proof_. We can define a map \(f\colon A\to B\) by the rule

\[f((x_{i})_{i\,\in\,I})=\sum_{i\,\in\,I}f_{i}(x_{i}).\]

The sum on the right is actually finite since all but a finite number of terms are \(0\). It is immediately verified that our map \(f\) is a homomorphism. Furthermore, we clearly have \(f\,{\raise 1.0pt\hbox{$\circ$}\kern-1.0pt}\,\,\lambda_{j}(x)=f_{j}(x)\) for each \(j\) and each \(x\,\in\,A_{j}\). Thus \(f\) has the desired commutativity property. It is also clear that the map \(f\) is uniquely determined, as was to be shown.

The property expressed in Proposition 7.1 is called the **universal property** of the direct sum. Cf. SS11.

**Example.** Let \(A\) be an abelian group, and let \(\{A_{i}\}_{i\in\,I}\) be a family of subgroups. Then we get a homomorphism

\[\bigoplus_{i\in\,I}A_{i}\to A\quad\text{such that}\quad(x_{i})\,\mapsto\,\sum x _{i}.\]

Theorem 8.1 will provide an important specific application.

Let \(A\) be an abelian group and \(B\), \(C\) subgroups. If \(B\,+\,C\,=\,A\) and \(B\,\cap\,C\,=\,\{0\}\) then the map

\[B\,\times\,C\to A\]

given by \((x,\,y)\,{\mapsto}\,x\,+\,y\) is an isomorphism (as we already noted in the non-commutative case). Instead of writing \(A=B\,\times\,C\) we shall write

\[A\,=\,B\,\oplus\,C\]

and say that \(A\) is the **direct sum** of \(B\) and \(C\). We use a similar notation for the direct sum of a finite number of subgroups \(B_{1},\ldots,\,B_{n}\) such that

\[B_{1}\,+\,\cdots\,+\,B_{n}=A\]

and

\[B_{i\,+\,1}\cap(B_{1}\,+\,\cdots\,+\,B_{i})=0.\]In that case we write

\[A=B_{1}\oplus\cdots\oplus B_{n}.\]

Let \(A\) be an abelian group. Let \(\{e_{i}\}\) (\(i\in I\)) be a family of elements of \(A\). We say that this family is a **basis** for \(A\) if the family is not empty, and if every element of \(A\) has a unique expression as a linear combination

\[x=\sum x_{i}e_{i}\]

with \(x_{i}\in\mathbf{Z}\) and almost all \(x_{i}=0\). Thus the sum is actually a finite sum. An abelian group is said to be **free** if it has a basis. If that is the case, it is immediate that if we let \(Z_{i}=\mathbf{Z}\) for all \(i\), then \(A\) is isomorphic to the direct sum

\[A\approx\bigoplus_{i\in I}Z_{i}.\]

Next let \(S\) be a set. We shall define the free abelian group generated by \(S\) as follows. Let \(\mathbf{Z}\langle S\rangle\) be the set of all maps \(\varphi:S\to\mathbf{Z}\) such that \(\varphi(x)=0\) for almost all \(x\in S\). Then \(\mathbf{Z}\langle S\rangle\) is an abelian group (addition being the usual addition of maps). If \(k\) is an integer and \(x\) is an element of \(S\), we denote by \(k\cdot x\) the map \(\varphi\) such that \(\varphi(x)=k\) and \(\varphi(y)=0\) if \(y\neq x\). Then it is obvious that every element \(\varphi\) of \(\mathbf{Z}\langle S\rangle\) can be written in the form

\[\varphi=k_{1}\cdot x_{1}+\cdots+k_{n}\cdot x_{n}\]

for some integers \(k_{i}\) and elements \(x_{i}\in S\) (\(i=1,\ldots,n\)), all the \(x_{i}\) being distinct. Furthermore, \(\varphi\)_admits a unique such expression_, because if we have

\[\varphi=\sum_{x\in S}k_{x}\cdot x=\sum_{x\in S}k^{\prime}_{x}\cdot x\]

then

\[0=\sum_{x\in S}(k_{x}-k^{\prime}_{x})\cdot x,\]

whence \(k^{\prime}_{x}=k_{x}\) for all \(x\in S\).

We map \(S\) into \(\mathbf{Z}\langle S\rangle\) by the map \(f_{S}=f\) such that \(f(x)=1\cdot x\). It is then clear that \(f\) is injective, and that \(f(S)\) generates \(\mathbf{Z}\langle S\rangle\). If \(g:S\to B\) is a mapping of \(S\) into some abelian group \(B\), then we can define a map

\[g_{\bullet}:\mathbf{Z}\langle S\rangle\to B\]

such that

\[g_{\bullet}\left(\sum_{x\in S}k_{x}\cdot x\right)=\sum_{x\in S}k_{x}g(x).\]

This map is a homomorphism (trivial) and we have \(g_{\bullet}\circ f=g\) (also trivial). It is the only homomorphism which has this property, for any such homomorphism \(g_{\bullet}\) must be such that \(g_{\bullet}(1\cdot x)=g(x)\).

It is customary to identify \(S\) in \(\mathbb{Z}\langle S\rangle\), and we sometimes omit the dot when we write \(k_{x}x\) or a sum \(\sum k_{x}x\).

_If \(\lambda:S\to S^{\prime}\) is a mapping of sets_, _there is a unique homomorphism \(\bar{\lambda}\) making the following diagram commutative_:

In fact, \(\bar{\lambda}\) is none other than \((f_{S^{\prime}}\circ\lambda)_{\bullet}\), with the notation of the preceding paragraph. The proof of this statement is left as a trivial exercise.

We shall denote \(\mathbb{Z}\langle S\rangle\) also by \(F_{\text{ab}}(S)\), and call \(F_{\text{ab}}(S)\) the **free abelian group generated by \(S\)**. We call elements of \(S\) its **free generators**.

As an exercise, show that every abelian group \(A\) is a factor group of a free abelian group \(F\). If \(A\) is finitely generated, show that one can select \(F\) to be finitely generated also.

If the set \(S\) above consists of \(n\) elements, then we say that the free abelian group \(F_{\text{ab}}(S)\) is the free abelian group on \(n\) generators. If \(S\) is the set of \(n\) letters \(x_{1},\ldots,x_{n}\), we say that \(F_{\text{ab}}(S)\) is the free abelian group with free generators \(x_{1},\ldots,x_{n}\).

An abelian group is **free** if and only if it is isomorphic to a free abelian group \(F_{\text{ab}}(S)\) for some set \(S\). Let \(A\) be an abelian group, and let \(S\) be a basis for \(A\). Then it is clear that \(A\) is isomorphic to the free abelian group \(F_{\text{ab}}(S)\).

As a matter of notation, if \(A\) is an abelian group and \(T\) a subset of elements of \(A\), we denote by \(\langle T\rangle\) the subgroup generated by the elements of \(T\), i.e., the smallest subgroup of \(A\) containing \(T\).

**Example. The Grothendieck group.** Let \(M\) be a commutative monoid, written additively. There exists a commutative group \(K(M)\) and a monoid-homomorphism

\[\gamma:M\to K(M)\]

having the following universal property. If \(f:M\to A\) is a homomorphism into an abelian group \(A\), then there exists a unique homomorphism \(f_{\bullet}\): \(K(M)\to A\) making the following diagram commutative:

_Proof._ Let \(F_{\text{ab}}(M)\) be the free abelian group generated by \(M\). We denote the generator of \(F_{\text{ab}}(M)\) corresponding to an element \(x\in M\) by \([x]\). Let \(B\) be the subgroup generated by all elements of type

\[[x+y]-[x]-[y]\]\(\quad\)

## 40 groups

where \(x\), \(y\in M\). We let \(K(M)=F_{\rm ab}(M)/B\), and let

\[\gamma:M\to K(M)\]

be the map obtained by composing the injection of \(M\) into \(F_{\rm ab}(M)\) given by \(x\mapsto[x]\), and the canonical map

\[F_{\rm ab}(M)\to F_{\rm ab}(M)/B.\]

It is then clear that \(\gamma\) is a homomorphism, and satisfies the desired universal property.

The universal group \(K(M)\) is called the **Grothendieck group**.

We shall say that the **cancellation law** holds in \(M\) if, whenever \(x\), \(y\), \(z\in M\), and \(x\,+\,z\,=\,y\,+\,z\), we have \(x\,=\,y\).

We then have an important criterion when the universal map \(\gamma\) above is injective:

_If the cancellation law holds in \(M\)_, _then the canonical map \(\gamma\) of \(M\) into its Grothendieck group is injective._

_Proof._ This is essentially the same proof as when one constructs the negative integers from the natural numbers. We consider pairs \((x,y)\) with \(x\), \(y\in M\) and say that \((x,y)\) is equivalent to \((x^{\prime},y^{\prime})\) if \(y\,+\,x^{\prime}\,=\,x\,+\,y^{\prime}\). We define addition of pairs componentwise. Then the equivalence classes of pairs form a group, whose \(0\) element is the class of \((0,0)\) [or the class of \((x,\,x)\) for any \(x\in M\)]. The negative of an element \((x,\,y)\) is \((y,\,x)\). We have a homomorphism

\[x\mapsto{\rm class\ of\ }(0,\,x)\]

which is injective, as one sees immediately by applying the cancellation law. Thus we have constructed a homomorphism of \(M\) into a group, which is injective. It follows that the universal homomorphism must also be injective.

**Examples.** See the example of projective modules in Chapter III, SS4. For a relatively fancy context, see: K. Kato, Logarithmic structures of Fontaine-Illusie, _Algebraic Geometry, Analysis and Number Theory, Proc. JAMI Conference_, J. Igusa (Ed.), Johns Hopkins Press (1989) pp. 195-224.

Given an abelian group \(A\) and a subgroup \(B\), it is sometimes desirable to find a subgroup \(C\) such that \(A\,=\,B\oplus\,C\). The next lemma gives us a condition under which this is true.

**Lemma 7.2.**_Let \(A\stackrel{{ f}}{{\to}}A^{\prime}\) be a surjective homomorphism of abelian groups, and assume that \(A^{\prime}\) is free. Let \(B\) be the kernel of \(f\). Then there exists a subgroup \(C\) of \(A\) such that the restriction of \(f\) to \(C\) induces an isomorphism of \(C\) with \(A^{\prime}\), and such that \(A\,=\,B\oplus\,C\)._

_Proof._ Let \(\{x^{\prime}_{i}\}_{i\,\in\,I}\) be a basis of \(A^{\prime}\), and for each \(i\,\in\,I\), let \(x_{i}\) be an element of \(A\) such that \(f(x_{i})=x^{\prime}_{i}\). Let \(C\) be the subgroup of \(A\) generated by all elements \(x_{i}\), \(i\,\in\,I\). If we have a relation

\[\sum_{i\,\in\,I}n_{i}x_{i}\,=\,0\]with integers \(n_{i}\), almost all of which are equal to 0, then applying \(f\) yields

\[0=\sum_{i\in I}n_{i}\,f(x_{i})=\sum_{i\in I}n_{i}\,x_{i}^{\prime},\]

whence all \(n_{i}=0\). Hence our family \(\{x_{i}\}_{i\in I}\) is a basis of \(C\). Similarly, one sees that if \(z\in C\) and \(f(z)=0\) then \(z=0\). Hence \(B\cap C=0\). Let \(x\in A\). Since \(f(x)\in A^{\prime}\) there exist integers \(n_{i}\), \(i\in I\), such that

\[f(x)=\sum_{i\in I}n_{i}\,x_{i}^{\prime}.\]

Applying \(f\) to \(x-\sum_{i\in I}n_{i}\,x_{i}\), we find that this element lies in the kernel of \(f\), say

\[x-\sum_{i\in I}n_{i}\,x_{i}=\,b\in B.\]

From this we see that \(x\in B+C\), and hence finally that \(A=B\oplus C\) is a direct sum, as contended.

**Theorem 7.3.** _Let \(A\) be a free abelian group, and let \(B\) be a subgroup. Then \(B\) is also a free abelian group, and the cardinality of a basis of \(B\) is \(\leqq\) the cardinality of a basis for \(A\). Any two bases of \(B\) have the same cardinality._

_Proof._ We shall give the proof only when \(A\) is finitely generated, say by a basis \(\{x_{1},\ldots,x_{n}\}\) (\(n\geqq 1\)), and give the proof by induction on \(n\). We have an expression of \(A\) as direct sum:

\[A=\,{\bf Z}x_{1}\,\oplus\,\cdots\oplus\,{\bf Z}x_{n}.\]

Let \(f\colon A\to{\bf Z}x_{1}\) be the projection, i.e. the homomorphism such that

\[f(m_{1}\,x_{1}+\,\cdots+\,m_{n}\,x_{n})=m_{1}\,x_{1}\]

whenever \(m_{i}\in{\bf Z}\). Let \(B_{1}\) be the kernel of \(f|B\). Then \(B_{1}\) is contained in the free subgroup \(\langle x_{2},\ldots,x_{n}\rangle\). By induction, \(B_{1}\) is free and has a basis with \(\leqq n-1\) elements. By the lemma, there exists a subgroup \(C_{1}\) isomorphic to a subgroup of \({\bf Z}x_{1}\) (namely the image of \(f|B\)) such that

\[B=\,B_{1}\oplus C_{1}.\]

Since \(f(B)\) is either 0 or infinite cyclic, i.e. free on one generator, this proves that \(B\) is free.

(When \(A\) is not finitely generated, one can use a similar transfinite argument. See Appendix 2, SS2, the example after Zorn's Lemma.)

We also observe that our proof shows that there exists at least one basis of \(B\) whose cardinality is \(\leqq n\). We shall therefore be finished when we prove the last statement, that any two bases of \(B\) have the same cardinality. Let \(S\) be one basis, with a finite number of elements \(m\). Let \(T\) be another basis, and suppose that \(T\) has at least \(r\) elements. It will suffice to prove that \(r\leqq m\) (onecan then use symmetry). Let \(p\) be a prime number. Then \(B/pB\) is a direct sum of cyclic groups of order \(p\), with \(m\) terms in the sum. Hence its order is \(p^{m}\). Using the basis \(T\) instead of \(S\), we conclude that \(B/pB\) contains an \(r\)-fold product of cyclic groups of order \(p\), whence \(p^{r}\leqq p^{m}\), and \(r\leqq m\), as was to be shown. (Note that we did not assume a priori that \(T\) was finite.)

The number of elements in a basis of a free abelian group \(A\) will be called the rank of \(A\).

